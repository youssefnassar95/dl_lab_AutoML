{"cells":[{"cell_type":"markdown","metadata":{"id":"qM6T-ZeStIGn"},"source":["# NASLib tutorial and intro to exercise"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/My\\ Drive/NasLib/NASLib\n","!pip install virtualenv\n","!virtualenv venv\n","!source venv/bin/activate\n","!pip install --upgrade pip setuptools wheel\n","!pip install -e .\n","!pip install jupyter gdown\n","!source scripts/download_data.sh nb201 cifar10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sFYHWOMQtYyf","executionInfo":{"status":"ok","timestamp":1653323317225,"user_tz":-120,"elapsed":179658,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"7aafbe07-18d9-42e5-c919-6146e4cb51ff"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/NasLib/NASLib\n","Collecting virtualenv\n","  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 22.8 MB/s \n","\u001b[?25hRequirement already satisfied: six<2,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (1.15.0)\n","Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (4.11.3)\n","Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv) (3.7.0)\n","Collecting platformdirs<3,>=2\n","  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n","Collecting distlib<1,>=0.3.1\n","  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n","\u001b[K     |████████████████████████████████| 461 kB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->virtualenv) (4.2.0)\n","Installing collected packages: platformdirs, distlib, virtualenv\n","Successfully installed distlib-0.3.4 platformdirs-2.5.2 virtualenv-20.14.1\n","created virtual environment CPython3.7.13.final.0-64 in 19782ms\n","  creator CPython3Posix(dest=/content/drive/My Drive/NasLib/NASLib/venv, clear=False, no_vcs_ignore=False, global=False)\n","  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n","    added seed packages: pip==22.0.4, setuptools==62.1.0, wheel==0.37.1\n","  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Using cached pip-22.1.1-py3-none-any.whl (2.1 MB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Using cached setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools, pip\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed pip-22.1.1 setuptools-62.3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/drive/MyDrive/NasLib/NASLib\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (1.4.2)\n","Collecting iopath>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (0.8.9)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (4.64.0)\n","Collecting yacs>=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting ConfigSpace\n","  Downloading ConfigSpace-0.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (0.29.30)\n","Requirement already satisfied: hyperopt==0.1.2 in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (0.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (3.13)\n","Collecting numpy==1.17.5\n","  Downloading numpy-1.17.5-cp37-cp37m-manylinux1_x86_64.whl (20.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn==0.23.0\n","  Downloading scikit_learn-0.23.0-cp37-cp37m-manylinux1_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fvcore\n","  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (3.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (1.3.5)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (3.6.4)\n","Collecting pytest-cov\n","  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n","Collecting codecov\n","  Downloading codecov-2.1.12-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: coverage in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (3.7.1)\n","Collecting keras==2.3.1\n","  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.8/377.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (2.2.3)\n","Collecting ngboost==0.3.7\n","  Downloading ngboost-0.3.7-py3-none-any.whl (28 kB)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (0.90)\n","Collecting emcee==2.2.1\n","  Downloading emcee-2.2.1.tar.gz (24 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pybnn\n","  Downloading pybnn-0.0.5.tar.gz (22 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pyro-ppl==1.4.0\n","  Downloading pyro_ppl-1.4.0-py3-none-any.whl (573 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.4/573.4 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow==1.15.4\n","  Downloading tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from naslib==0.0.1) (2.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->naslib==0.0.1) (1.15.0)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->naslib==0.0.1) (4.1.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->naslib==0.0.1) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.2->naslib==0.0.1) (0.16.0)\n","Collecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->naslib==0.0.1) (3.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->naslib==0.0.1) (1.1.2)\n","Collecting lifelines<0.29,>=0.25\n","  Downloading lifelines-0.27.0-py3-none-any.whl (349 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.1/349.1 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.4.0->naslib==0.0.1) (3.3.0)\n","Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pyro-ppl==1.4.0->naslib==0.0.1) (1.11.0+cu113)\n","Collecting pyro-api>=0.1.1\n","  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0->naslib==0.0.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.0->naslib==0.0.1) (1.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (1.1.0)\n","Collecting tensorflow-estimator==1.15.1\n","  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.4/503.4 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (3.17.3)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (0.37.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (1.0.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (1.14.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (1.46.1)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->naslib==0.0.1) (0.8.1)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->naslib==0.0.1) (4.2.0)\n","Requirement already satisfied: requests>=2.7.9 in /usr/local/lib/python3.7/dist-packages (from codecov->naslib==0.0.1) (2.23.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace->naslib==0.0.1) (3.0.9)\n","Collecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->naslib==0.0.1) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->naslib==0.0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->naslib==0.0.1) (2022.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pybnn->naslib==0.0.1) (0.12.0+cu113)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (1.11.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (21.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (62.3.2)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (8.13.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (1.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (0.7.1)\n","Collecting pytest\n","  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coverage[toml]>=5.2.1\n","  Downloading coverage-6.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.7/208.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (2.0.1)\n","Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (4.11.3)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (1.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest->naslib==0.0.1) (21.3)\n","Collecting pytest\n","  Downloading pytest-7.1.1-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-7.1.0-py3-none-any.whl (297 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-7.0.0-py3-none-any.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.7/280.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.6/280.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.2.3-py3-none-any.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.5/280.5 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.2.2-py3-none-any.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.2.1-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.9/279.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.2.0-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.6/279.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.1.2-py3-none-any.whl (272 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.4/272.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.1.1-py3-none-any.whl (272 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.2/272.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.1.0-py3-none-any.whl (272 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.0.2-py3-none-any.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.8/270.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.0.1-py3-none-any.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.6/270.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-6.0.0-py3-none-any.whl (270 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.6/270.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.1/248.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.4.2-py3-none-any.whl (247 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.4/247.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.7/246.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.4.0-py3-none-any.whl (247 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.3.5-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.2/235.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.3.4-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.3/235.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.3.3-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.5/234.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.3.1-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.3.0-py3-none-any.whl (233 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.7/233.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.2.4-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.2.3-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.2.2-py3-none-any.whl (227 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.2.1-py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.2.0-py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.1.3-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.1/224.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.1.2-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.1.1-py3-none-any.whl (223 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.1.0-py3-none-any.whl (223 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.0.1-py3-none-any.whl (221 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.8/221.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-5.0.0-py3-none-any.whl (221 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.8/221.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.11-py2.py3-none-any.whl (231 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.10-py2.py3-none-any.whl (231 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.9-py2.py3-none-any.whl (231 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.1/231.1 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.8-py2.py3-none-any.whl (230 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.5/230.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.7-py2.py3-none-any.whl (230 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.4/230.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.6-py2.py3-none-any.whl (230 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.2/230.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.5-py2.py3-none-any.whl (230 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.4-py2.py3-none-any.whl (229 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.3-py2.py3-none-any.whl (229 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.2-py2.py3-none-any.whl (229 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.1-py2.py3-none-any.whl (229 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading pytest-4.6.0-py2.py3-none-any.whl (229 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.8/229.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of pytest-cov to determine which version is compatible with other requirements. This could take a while.\n","Collecting pytest-cov\n","  Downloading pytest_cov-2.12.1-py2.py3-none-any.whl (20 kB)\n","Collecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Collecting pytest-cov\n","  Downloading pytest_cov-2.12.0-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.11.1-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.11.0-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.10.1-py2.py3-none-any.whl (19 kB)\n","  Downloading pytest_cov-2.10.0-py2.py3-none-any.whl (19 kB)\n","  Downloading pytest_cov-2.9.0-py2.py3-none-any.whl (19 kB)\n","Collecting autograd-gamma>=0.3\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2\n","  Downloading formulaic-0.3.4-py3-none-any.whl (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines<0.29,>=0.25->ngboost==0.3.7->naslib==0.0.1) (1.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.9->codecov->naslib==0.0.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.9->codecov->naslib==0.0.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.9->codecov->naslib==0.0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.9->codecov->naslib==0.0.1) (2.10)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->naslib==0.0.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->naslib==0.0.1) (3.3.7)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1->naslib==0.0.1) (1.5.2)\n","Collecting interface-meta<2.0.0,>=1.2.0\n","  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Collecting scipy\n","  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest->naslib==0.0.1) (3.8.0)\n","Building wheels for collected packages: emcee, gast, fvcore, pybnn, autograd-gamma\n","  Building wheel for emcee (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emcee: filename=emcee-2.2.1-py3-none-any.whl size=29594 sha256=e447f1fbaf9439b15b914ff08895c3a3121bb99f93d40ffc9ffc50820746cb7a\n","  Stored in directory: /root/.cache/pip/wheels/e5/a8/f9/786e27aeae8bc4dbf2b22f1d0055098c3a00c307689894c26f\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7538 sha256=80375b9f811db78594191bb2c3150e34752f4795cdfc71ba60a7e4a29d1b6a8b\n","  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61263 sha256=aa7c3c0b6c6af6eb905711fd11af92d07b952e12cd1463a679e79e29810e89b7\n","  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n","  Building wheel for pybnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pybnn: filename=pybnn-0.0.5-py3-none-any.whl size=33970 sha256=4f5d6077afc87c30c794ce8b5d306119b7af954b817340eee5f2e9e77930ee3b\n","  Stored in directory: /root/.cache/pip/wheels/84/76/b4/9846298ff48fb12f6a787468843522e022fed6c40fe7058fa8\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4032 sha256=a8ef939644aa29b1343daeed5bff4f1491ec7bf5d294051179a49d69d37a8971\n","  Stored in directory: /root/.cache/pip/wheels/9f/01/ee/1331593abb5725ff7d8c1333aee93a50a1c29d6ddda9665c9f\n","Successfully built emcee gast fvcore pybnn autograd-gamma\n","Installing collected packages: tensorflow-estimator, pyro-api, pyyaml, portalocker, numpy, interface-meta, gast, coverage, yacs, scipy, pytest-cov, iopath, emcee, codecov, tensorboard, scikit-learn, pyro-ppl, pybnn, keras-applications, fvcore, formulaic, ConfigSpace, autograd-gamma, tensorflow, lifelines, keras, ngboost, naslib\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: coverage\n","    Found existing installation: coverage 3.7.1\n","    Uninstalling coverage-3.7.1:\n","      Successfully uninstalled coverage-3.7.1\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.8.0\n","    Uninstalling tensorboard-2.8.0:\n","      Successfully uninstalled tensorboard-2.8.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n","    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n","      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.8.0\n","    Uninstalling keras-2.8.0:\n","      Successfully uninstalled keras-2.8.0\n","  Running setup.py develop for naslib\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.0 which is incompatible.\n","xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.17.5 which is incompatible.\n","xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.17.5 which is incompatible.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n","tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.17.5 which is incompatible.\n","kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.17.5 which is incompatible.\n","kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.4 which is incompatible.\n","jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.17.5 which is incompatible.\n","jax 0.3.8 requires numpy>=1.19, but you have numpy 1.17.5 which is incompatible.\n","imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.0 which is incompatible.\n","datascience 0.10.6 requires coverage==3.7.1, but you have coverage 6.4 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","coveralls 0.5 requires coverage<3.999,>=3.6, but you have coverage 6.4 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed ConfigSpace-0.5.0 autograd-gamma-0.5.0 codecov-2.1.12 coverage-6.4 emcee-2.2.1 formulaic-0.3.4 fvcore-0.1.5.post20220512 gast-0.2.2 interface-meta-1.3.0 iopath-0.1.9 keras-2.3.1 keras-applications-1.0.8 lifelines-0.27.0 naslib ngboost-0.3.7 numpy-1.17.5 portalocker-2.4.0 pybnn-0.0.5 pyro-api-0.1.2 pyro-ppl-1.4.0 pytest-cov-2.9.0 pyyaml-6.0 scikit-learn-0.23.0 scipy-1.7.3 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1 yacs-0.1.8\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (1.0.0)\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter) (7.7.0)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.6.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter) (4.10.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.2.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.3.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter) (3.6.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter) (5.4.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter) (1.1.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter) (2.6.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (1.5.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (4.10.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.7.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.6.0)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (2.11.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (5.0.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.8.4)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (1.8.0)\n","Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (22.3.0)\n","Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (2.1.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (62.3.2)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.8.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter) (2.8.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (2.15.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.2.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter) (21.3)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter) (0.7.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter) (5.7.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter) (21.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter) (4.11.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter) (4.2.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter) (0.18.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->qtpy>=2.0.1->qtconsole->jupyter) (3.0.9)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter) (3.8.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mdataset = cifar10\n","search_space = nb201\n","cifar10 exists\n"]}]},{"cell_type":"markdown","metadata":{"id":"85edtQIntIGo"},"source":["[NASLib](https://github.com/automl/NASLib) is framework that was built in order to facilitate neural architecture search (NAS) research and development. Please refer to the slides and to the [NAS survey paper](https://arxiv.org/abs/1808.05377) for more details. At the high-level NASLib consists of 4 main building blocks which (can) interact with each other:\n","- search spaces (cell search space, hierarchical, ...)\n","- optimizers (one-shot/weight-sharing optimizers, black-box optimizers)\n","- predictors (performance estimators that given an architecture as input, output its performance)\n","- evaluators (run the architecture search loop and the final network training pipeline)\n","\n","**NOTE: NASLib is currently under development. This exercise is meant to be beneficial for both students and the NASLib developers. In case of any issues or bugs please contact us and we will try to fix those. If you are interested in working to extend the library please contact Arber.**"]},{"cell_type":"markdown","metadata":{"id":"k9cYXsVItIGp"},"source":["![naslib-overview.png](attachment:naslib-overview.png)"]},{"cell_type":"markdown","metadata":{"id":"JAV1Oy75tIGp"},"source":["## Installation and setup "]},{"cell_type":"markdown","metadata":{"id":"8ZDva_extIGq"},"source":["To setup your environment and install NASLib follow these steps:\n","```\n","git clone -b dllab22 https://github.com/automl/NASLib/\n","cd NASLib\n","conda create -n naslib_exercises python=3.7\n","conda activate naslib_exercises\n","pip install --upgrade pip setuptools wheel\n","pip install -e .\n","pip install jupyter gdown\n","source scripts/download_data.sh nb201 cifar10\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"325s6lBVtIGq"},"source":["## Cell search spaces in NASLib "]},{"cell_type":"markdown","metadata":{"id":"54LDganKtIGr"},"source":["The search space representation is of primary importance for NASLib in ensuring that optimizers and search spaces can be combined in a variety of ways. The predominant way of representing NAS search spaces is the directed acyclic graph (DAG). \n","In order to accomplish the aforementioned functionality of search spaces and computational graphs, we inherit in our basic graph classes from both [PyTorch](https://pytorch.org/) and [NetworkX](https://github.com/networkx/networkx). The latter is a well-maintained and tested Python package for graph creation and manipulation, where node and edge attributes can be arbitrary Python objects. This framework allows us to represent multiple layers of graphs on top of the computational graph, allowing us to treat nodes and edges both as primitive operations (e.g. convolution), but also nested graph-structures such as a DARTS cell, to create e.g. macro architectures of stacked cells. NetworkX allows to easily construct the search space via `add_node`, `remove_node`, `add_edge`, `remove_edge`, or traverse the topologically sorted graph in the forward pass of the PyTorch module using `networkx.algorithms.dag.topological_sort`."]},{"cell_type":"markdown","metadata":{"id":"qihVAV3atIGr"},"source":["### Case study: NAS-Bench-201"]},{"cell_type":"markdown","metadata":{"id":"YtAtrWmItIGs"},"source":["[The NAS-Bench-201](https://openreview.net/forum?id=HJxyZkBKDr) is a tabular benchmark, i.e. a benchmark where you can simply query (already has been trained) the performance and other metrics of a specific architecture in the search space given that as an input. Its search space consists of a single normal cell which is replicated multiple times in a macro architecture interleaved by manually defined resnet-like reduction cells. The cell topology is fixed in the cell and consists of:\n","- 1 input, 2 intermediate and 1 output node;\n","- a summation operation on each of the intermediate and output nodes;\n","- 5 operation choices in each of the edges connecting 2 nodes\n","    - 'none'\n","    - 'skip_connect'\n","    - 'nor_conv_1x1'\n","    - 'nor_conv_3x3'\n","    - 'avg_pool_3x3'\n","    \n","For an example on how this search space is defined using the NASLib terminology, refer  [here](https://github.com/automl/NASLib/blob/predictors/naslib/search_spaces/nasbench201/graph.py)."]},{"cell_type":"markdown","metadata":{"id":"GZ1iq0QitIGt"},"source":["![nb201.png](attachment:nb201.png)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GS13I9AZtIGt","executionInfo":{"status":"ok","timestamp":1653323409809,"user_tz":-120,"elapsed":11791,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4c3e4fe-69a0-4694-a685-870c1ba4e455"},"outputs":[{"output_type":"stream","name":"stderr","text":["Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`\n","Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`\n","Update function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`\n"]}],"source":["from naslib.search_spaces import NasBench201SearchSpace as NB201\n","\n","# instantiate the search space object\n","search_space = NB201()"]},{"cell_type":"markdown","metadata":{"id":"-uXEdnCUtIGu"},"source":["## Black-box optimizers in NASLib"]},{"cell_type":"markdown","metadata":{"id":"2Jtvy-1vtIGv"},"source":["After learning about the search space object, now we can add the other component of NAS: the NAS optimizer which you will use to search for an optimal architecture in that search space. A search space graph object can be interpreted in different ways depending on the type of optimizer being used. Here is the point where the search space and optimizer objects interact by parsing information from each other. "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2S7xw-altIGv","executionInfo":{"status":"ok","timestamp":1653323446467,"user_tz":-120,"elapsed":1973,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"bc495ab7-114e-4712-9649-42331260a21c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(config_file='/content/drive/MyDrive/NasLib/NASLib/naslib/benchmarks/nas_predictors/discrete_config.yaml', dist_backend='nccl', dist_url='tcp://127.0.0.1:8888', eval_only=False, gpu=None, model_path=None, multiprocessing_distributed=False, opts=[], rank=0, resume=False, seed=0, world_size=1)\n"]}],"source":["# import some utilities and parse the configuration file\n","import logging\n","\n","from naslib.utils import utils, setup_logger, get_dataset_api\n","\n","# This will read the parameters from the default yaml configuration file, which in this \n","# case is located in NASLib/naslib/benchmarks/nas_predictors/discrete_config.yaml.\n","# You do not have to change this but you can play around with its parameters.\n","config = utils.get_config_from_args(config_type=\"nas_predictor\")\n","utils.set_seed(config.seed)\n","utils.log_args(config)\n","\n","logger = setup_logger(config.save + \"/log.log\")\n","logger.setLevel(logging.INFO)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yD8oPelJtIGv","executionInfo":{"status":"ok","timestamp":1653323500342,"user_tz":-120,"elapsed":26564,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d635b1b-063f-4cc5-826f-29fda8a7840c"},"outputs":[{"output_type":"stream","name":"stdout","text":["device: cpu\n","device: cpu\n","device: cpu\n","device: cpu\n","device: cpu\n","device: cpu\n"]}],"source":["from naslib.optimizers import RegularizedEvolution as RE\n","\n","# instantiate the optimizer object using the configuration file parameters\n","optimizer = RE(config)"]},{"cell_type":"markdown","metadata":{"id":"VmWrNmw7tIGw"},"source":["After parsing the configuration file and instantiating the NAS optimizer and search space objects, we have to adapt the search space based on the optimizer type. \n","A black-box optimizer such as Random Search will sample single architectures using the `sample_random_architecture` method of the search space object (e.g. by sampling one operation at each graph edge from the operation choices in NAS-Bench-201) throughout the optimization process.\n","On the other hand most one-shot optimizers, such as [DARTS](https://arxiv.org/abs/1806.09055), will interpret a set of operation choices on an edge as a `MixedOp` and assign an appropriate number of architectural weights (between 0 and 1, such that the sum is 1) to the outputs of each operation in order to obtain the continuous relaxation. "]},{"cell_type":"markdown","metadata":{"id":"Ocn_VkRktIGw"},"source":["Download the NAS-Bench-201 data from https://drive.google.com/file/d/17EBlTidimMaGrb3fE0APbljJl-ocgfs4/view?usp=sharing and place it in `NASLib/naslib/data/`. Alternatively run ```source scripts/download_data.sh nb201 cifar10```\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"1X5y7_3FtIGw","executionInfo":{"status":"ok","timestamp":1653323612205,"user_tz":-120,"elapsed":26829,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}}},"outputs":[],"source":["# this will load the NAS-Bench-201 data (architectures and their accuracy, runtime, etc).\n","dataset_api = get_dataset_api(config.search_space, config.dataset)\n","\n","# adapt the search space to the optimizer type\n","optimizer.adapt_search_space(search_space, dataset_api=dataset_api)"]},{"cell_type":"markdown","metadata":{"id":"wNaDeanftIGw"},"source":["## Running the search"]},{"cell_type":"markdown","metadata":{"id":"75545_qltIGw"},"source":["Now the only step left is to run the search. Fro this we will use the `Trainer` object in NASLib:"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPgT7zJStIGx","executionInfo":{"status":"ok","timestamp":1653323620471,"user_tz":-120,"elapsed":2647,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"76afa24c-cf08-45e0-e0e8-1a0b3fbefab3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[05/23 16:33:39 nl.defaults.trainer]: \u001b[0mparam size = 0.000000MB\n"]}],"source":["from naslib.defaults.trainer import Trainer\n","\n","# since the optimizer has parsed the information of the search space, we do not need to pass the search\n","# space object to the trainer when instantiating it.\n","trainer = Trainer(optimizer, config, lightweight_output=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1lOMRQutIGx","executionInfo":{"status":"ok","timestamp":1653323655243,"user_tz":-120,"elapsed":29687,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"9652e72d-db31-4118-ec84-783f28da7c18"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[05/23 16:33:45 nl.defaults.trainer]: \u001b[0mStart training\n","\u001b[32m[05/23 16:33:45 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/23 16:33:46 nl.search_spaces.core.graph]: \u001b[0mUpdate function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/23 16:33:46 nl.search_spaces.core.graph]: \u001b[0mUpdate function could not be veryfied. Be cautious with the setting of `private_edge_data` in `update_edges()`\n","\u001b[32m[05/23 16:33:46 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 1\n","\u001b[32m[05/23 16:33:46 nl.defaults.trainer]: \u001b[0mEpoch 0, Anytime results: {'cifar10-valid': {'train_losses': [1.933049173965454, 1.6435673345184325, 1.5047246058654786, 1.3834531283569336, 1.286956615371704, 1.1839038812637328, 1.1257015887069701, 1.0640545072746277, 1.008200834274292, 0.9675810929870605, 0.9294775085449218, 0.8978886487960815, 0.8689233894729614, 0.835043701877594, 0.8149485078430175, 0.7993172987365723, 0.7647924902915955, 0.7442652308464051, 0.7303601633262634, 0.7206139094543457, 0.700282748222351, 0.689298511505127, 0.671164067955017, 0.659271063709259, 0.6536657622528076, 0.644965997467041, 0.6267636371994019, 0.6300651649665833, 0.6204490633773804, 0.6097293877315522, 0.6010741853713989, 0.5971751938438415, 0.5914653929138184, 0.5821332813644409, 0.5756466757678985, 0.5765612985229492, 0.5747497636222839, 0.5639631831932068, 0.5726355790519715, 0.5540831290435791, 0.544603844833374, 0.538719157447815, 0.5455957692337036, 0.5412485385322571, 0.5337968168449402, 0.5338672785758972, 0.5202459384346009, 0.5235530172157288, 0.5228768538284302, 0.5111833030891418, 0.5069599935722351, 0.4985576431465149, 0.5061389976501465, 0.5057560344696045, 0.4975048216819763, 0.4996471509456635, 0.49808415460586547, 0.48002091426849364, 0.4895668503761291, 0.47426448446273806, 0.47582018551826477, 0.4727789403152466, 0.4713308194351196, 0.4654431737613678, 0.4631043137359619, 0.4602999722862244, 0.46426936804771424, 0.45147063561439515, 0.4586259645652771, 0.4530562820339203, 0.4525101449012756, 0.44904636945724485, 0.4421387914657593, 0.44143003540992737, 0.43449196798324585, 0.429807522983551, 0.4321302970981598, 0.42644655586242675, 0.42557577180862427, 0.4184540640449524, 0.4111059604167938, 0.41888580284118654, 0.4107645316886902, 0.4032634139728546, 0.3989506572628021, 0.40599107765197756, 0.4013190036678314, 0.4004554117488861, 0.39978235445976257, 0.3918292625141144, 0.38755730080604556, 0.3802079680633545, 0.37822834414482115, 0.3721178003501892, 0.36796443832397463, 0.3624983962631226, 0.3639153636550903, 0.3588394504070282, 0.3580660499668121, 0.35965268224716185, 0.3529567024803162, 0.34759018639564515, 0.3482636020565033, 0.3410040765285492, 0.34433123145103456, 0.3332363390350342, 0.3343586909866333, 0.33191886186599734, 0.32960432033538817, 0.3258754188966751, 0.3183572149848938, 0.31825309366226195, 0.31322453734397887, 0.3127961633872986, 0.3112921525478363, 0.3073782663154602, 0.305751911945343, 0.2877358784770966, 0.29309685286521914, 0.28946088859558106, 0.2847796403694153, 0.2818057761096954, 0.2738027645301819, 0.2745120370388031, 0.2675325034427643, 0.25867299350261685, 0.25669949093818667, 0.25210444190979003, 0.2556096069812775, 0.24657657341957093, 0.2538064208316803, 0.24273306458473207, 0.23724620116710662, 0.23558641786575318, 0.22658208312988282, 0.22561613562583924, 0.2175565439891815, 0.2160201839542389, 0.2115384543132782, 0.2083314898300171, 0.20276337226867674, 0.19796098860263825, 0.19677157368183135, 0.18868987060546874, 0.18665040482521056, 0.1838897520160675, 0.16965494362831116, 0.1692909675502777, 0.16223212686538696, 0.16421128366708757, 0.15417879284381866, 0.15248106106758116, 0.15179483103752137, 0.14301283118724822, 0.13277943490028382, 0.1390109401512146, 0.1331410027551651, 0.13165652403831482, 0.1251206089258194, 0.12002688515186309, 0.11082318178653718, 0.11014242079257965, 0.10549740042209625, 0.10062637070178986, 0.09586149839639664, 0.09223287776947021, 0.09235902231693267, 0.0871694572353363, 0.07851553828954697, 0.07523862042188645, 0.07313915983438492, 0.07498600163459777, 0.0686159856414795, 0.06791985613346099, 0.06255743339061737, 0.060810287736654284, 0.05605678023815155, 0.051493860071897504, 0.05079198920726776, 0.04651469718694687, 0.04590114063620567, 0.04247044575214386, 0.042684141470193865, 0.04604436099410057, 0.03932782050609589, 0.040091955519914624, 0.03989724842786789, 0.03675567040979862, 0.03643383831262589, 0.03524160267472267, 0.03457283695936203, 0.03541027491092682, 0.03261254559040069, 0.031013704183101655, 0.03276500719666481, 0.03511530919075012, 0.03020550874441862, 0.0300822855424881, 0.03165007179617882, 0.03257577588319779], 'eval_losses': [1.853276103477478, 1.9825896265411378, 1.7628808596038819, 1.4096657558441161, 1.4998609498214721, 1.383873239364624, 1.7190013084411622, 1.262677116317749, 1.3637014740371705, 1.2649028635406494, 1.4128168886947632, 1.3575548432922364, 1.1706336224746705, 1.4476164538574219, 1.085583380355835, 1.4277293459320068, 1.845134800338745, 1.1361894588470458, 1.7432173997497558, 1.047818994617462, 1.0644127959823608, 1.2358372732162475, 0.7923082675361633, 1.8984723958587646, 1.227219734992981, 1.2374632009124755, 1.8372280381774901, 3.3594971089172363, 1.8625118659973146, 1.4339509927368164, 1.194370693397522, 0.8332742945289612, 0.9140051091003418, 1.284939202232361, 0.9161269886398316, 1.3480814905166627, 1.0398822765731812, 1.2605186191177369, 0.8410207567596436, 0.9902118959808349, 0.7680131269073487, 1.2281337160491943, 1.0896810879898071, 0.8184736426544189, 0.8645902954673768, 1.7687164207839965, 0.8077349285507203, 1.207072050819397, 1.085643136177063, 0.9497915023803711, 1.2137908243942261, 1.0207273559761048, 1.5429754879379272, 0.8329608443450928, 0.8357771710777283, 0.7830682307052612, 1.1425826570892335, 0.7564472578811645, 0.87835656539917, 1.4388655133819581, 1.4618375290679932, 0.8127754815483094, 0.9564275854301453, 1.4416781497192384, 1.1074947327041627, 0.9531717235565186, 0.8289349126243591, 1.2754418816375732, 1.1349834226608277, 1.7311271363067626, 0.8819717637634278, 0.933219065990448, 0.784826379699707, 0.8595322378540039, 0.7136831183815002, 1.2118772090911865, 0.6783367133140564, 0.8996105028533935, 1.4115132711029053, 0.8072059643936157, 1.142419045753479, 0.7940620897483825, 0.878292625541687, 1.0021474601745606, 0.7369408583450318, 0.8604336462402343, 0.8097284167098999, 0.8572968395805359, 0.7299011550521851, 0.8498886232185364, 1.0990450579833984, 0.9377336064529419, 1.596045492286682, 0.7873356300163269, 0.9096064290618896, 0.8921308458900452, 0.847033512058258, 0.8047578199577331, 0.7195415874481201, 0.7557898583221435, 0.792297578868866, 0.6501456667709351, 1.2255437806701661, 0.7569386186790467, 0.8863202992630005, 0.6395072632789612, 0.7113047681808472, 0.6376822698974609, 0.7149502280426026, 0.686346060962677, 0.6167438936614991, 1.1942690195083618, 0.8190234329223632, 0.6529788191604614, 0.6655721626281739, 1.0146758702278138, 0.6935151036643982, 0.7063728413581848, 0.6997902191543579, 0.6693120042610169, 0.7805671958732605, 0.7888907621002197, 0.7633749666404724, 0.8210488289070129, 0.5793331812858582, 0.6228814896965027, 0.9085615486526489, 0.6486815407371521, 0.7352733605957031, 0.6726218161964417, 0.729565166721344, 0.7221049830436707, 0.6092571593093872, 0.9904315916442871, 0.7177288776016235, 0.8044267671012878, 0.7301563682746888, 0.5891368518066407, 0.6938168054580689, 0.6769888493728637, 0.6718026449966431, 0.6439840829849243, 0.6875117469215393, 0.692921744556427, 0.625256512184143, 0.6981553867149353, 0.636772664604187, 0.6946889575767518, 0.5836456839847565, 0.6240633099842071, 0.5985315733528137, 0.6856615443611145, 0.5918414127731323, 0.5658171324920654, 0.6106313031578064, 0.5521215028190612, 0.649893540172577, 0.5895428963470459, 0.5434328539276123, 0.597798399181366, 0.5711516212654114, 0.5831282989120483, 0.5978009645080566, 0.5461356635665894, 0.5734788090133667, 0.5795820503044128, 0.6116492777252197, 0.5694089279842377, 0.568785023059845, 0.5618854899406434, 0.5635403636169434, 0.5830152307128906, 0.5711482059288024, 0.5568729959487915, 0.5673009009170532, 0.5674946151924133, 0.5650128768253326, 0.5699412359237671, 0.5753453620719909, 0.5744260936355591, 0.5668122173500061, 0.5662241883659362, 0.5645727476119995, 0.5703306195449829, 0.55752571767807, 0.5635156677246094, 0.5574384237861634, 0.5620425259971619, 0.5665751437950134, 0.5677274066352844, 0.5643322320556641, 0.5647553562068939, 0.560993676662445, 0.5646405374145508, 0.5617116917800903, 0.5623938551521301, 0.5640535704803467, 0.5687453405570984, 0.5678173172187805, 0.5599888938522339, 0.5531601202487946], 'train_acc1es': [26.715999996337892, 38.55199999389649, 44.867999986572265, 49.551999997558596, 52.93199998535156, 57.03999998657227, 59.395999986572264, 61.803999990234374, 63.77599999511719, 65.5080000024414, 66.80799999023438, 68.05600001464843, 69.10000000732421, 70.80000001953125, 71.12400000976562, 71.73999997802734, 72.99600001708984, 74.06800000244141, 74.50400000732422, 74.81999999511719, 75.55599999267578, 75.58799998779297, 76.3640000024414, 76.87199998535156, 77.36799999023438, 77.53200000732421, 78.02399999755859, 78.13200000488281, 78.47199998291016, 78.72400001464844, 78.85999998291015, 79.03199999023437, 79.55599997314454, 79.72399998535157, 79.68400001220704, 79.78799999267578, 79.82000001708984, 80.31599997314453, 79.54799997558594, 80.78799997070313, 80.95199999511719, 81.33600001220704, 80.94, 81.30399999755859, 81.52799998779297, 81.34800001953126, 82.10399998291015, 81.69999999267579, 81.85199998779296, 82.32399998535156, 82.25200001953125, 82.668, 82.43999998291015, 82.53599997802735, 82.84800000244141, 82.42, 82.71199998291016, 83.21999997558594, 82.968, 83.38799997558594, 83.34000001220703, 83.65999997070313, 83.54800001464844, 83.93199997070313, 83.74000000976562, 84.13199997070312, 83.65600000976562, 84.11200001220703, 84.13999999267578, 84.26400001953125, 84.1080000024414, 84.47599998291015, 84.58799998046875, 84.64400001220703, 84.67999997070312, 85.06400001708984, 84.86800000488282, 85.21999998779297, 85.27600001220704, 85.3680000024414, 85.48799999755859, 85.21999997558594, 85.69999997314453, 85.91600000488282, 86.0920000048828, 85.91999997070313, 86.156, 86.09200001953126, 85.9760000048828, 86.31199998535156, 86.44800001953125, 86.69600001220704, 86.56, 87.04, 87.24000001953125, 87.21600001220703, 87.17199999511719, 87.2360000024414, 87.49999999755859, 87.61200001464844, 87.8880000024414, 88.02400000732422, 87.86000001464843, 87.99199998779297, 87.80399999267578, 88.28000001464844, 88.24800000488281, 88.35599999267578, 88.45199997070313, 88.64799998046875, 88.68399999755859, 88.9880000048828, 88.83599997314452, 88.99999999023437, 89.11599999755859, 89.39600000244141, 89.10799998535157, 90.0199999975586, 89.63599999023438, 89.7720000024414, 90.09999999267578, 90.0320000024414, 90.39999998291016, 90.22399998046875, 90.52799999023438, 90.91599999023437, 90.91599999267578, 91.01999998779297, 91.03999997314453, 91.40399998779297, 91.05199998291016, 91.46799998779296, 91.79999998291015, 91.61199999511719, 92.19599998291015, 92.1319999975586, 92.37599997314453, 92.32799998779296, 92.47999999267579, 92.64799997070313, 92.92399998291016, 93.14799999023438, 93.08800001708984, 93.30799998046875, 93.28399997070312, 93.53199998535156, 93.95999998535156, 94.15199997314453, 94.27999999267578, 94.18800001708985, 94.63999997802735, 94.72400001953125, 94.64800001953125, 94.86399997314453, 95.37199997802735, 95.25599998046874, 95.43599997802734, 95.28400001708984, 95.60800001220703, 95.74800001953125, 96.18000000976562, 96.15999998046875, 96.49200001464844, 96.61599997070313, 96.72800000976562, 96.84000001220703, 96.86400001708985, 97.03600000976563, 97.47200000976562, 97.50800000732421, 97.54000000976562, 97.62400001220703, 97.65200001220703, 97.76400000976562, 98.01600000732422, 98.02800000976562, 98.15200001464844, 98.39200000488282, 98.38400000732422, 98.50800001464843, 98.6040000048828, 98.7080000048828, 98.7320000048828, 98.55600000976563, 98.8360000048828, 98.82000000976562, 98.80400000488281, 98.91600000244141, 98.91600000244141, 98.99200000488281, 99.0000000048828, 99.02400000488281, 99.0960000024414, 99.18800000732422, 99.09200000244141, 99.01200000976563, 99.112, 99.23200000244141, 99.16400000244141, 99.116], 'eval_acc1es': [29.95599999511719, 34.831999998168946, 37.55999999755859, 48.356000002441405, 47.83199999633789, 50.7039999975586, 46.04000000366211, 55.82000000732422, 53.639999989013674, 56.139999998779295, 54.5159999987793, 55.676, 60.82399999267578, 54.960000001220706, 65.24799999267579, 56.69599999633789, 50.200000009765624, 63.07199999267578, 56.228000008544925, 64.50000001220702, 66.18799998535157, 60.80799998901367, 72.28399999511718, 49.7599999987793, 62.191999989013674, 59.923999995117185, 54.55200000854492, 36.352000009765625, 52.251999990234374, 60.30799999633789, 64.57999997558593, 71.59600000976563, 69.63200000732422, 62.28000001708985, 70.32799997558594, 60.78399998046875, 67.55999997802735, 63.82799997802734, 72.32399997070313, 67.67599997802735, 74.74799998779297, 63.70799998291016, 67.71199999511718, 73.57600001220703, 71.36000001708985, 52.228000006103514, 73.23599998291016, 63.84400001953125, 66.46399999633789, 70.40799999267578, 65.94399998046875, 68.784, 62.70000001464844, 72.89199997314454, 73.664, 74.50399999511718, 66.22000000244141, 75.77200001953125, 73.03599999755859, 62.29600000732422, 58.65999998657227, 73.96799997558594, 71.82800000732422, 62.524000002441404, 69.23200001464843, 71.10799997314453, 73.82799998535157, 64.84399999267578, 64.89600000732422, 57.97199999389648, 72.56400001953125, 71.7919999951172, 74.75599999755859, 73.2719999975586, 77.16000000976562, 65.59999998046875, 77.82399997314454, 71.83200001220703, 64.51599999023438, 74.01600001708984, 67.71999997314452, 75.51200001708985, 73.58000000976563, 70.11599997070313, 75.7039999975586, 73.46000000488282, 74.50800000488282, 73.21599998291016, 77.988, 73.65199999755859, 68.84399997314453, 72.25199998291015, 59.984000002441405, 76.34800000244141, 71.31600000732422, 74.85599999023438, 74.28000000488281, 74.60399999267578, 77.16400000732422, 76.48799999267578, 75.96399999267578, 79.26799998535157, 64.36800000976562, 76.85599998535156, 73.66799998291016, 79.89199998046875, 79.176, 79.89600000732422, 78.06400001464844, 78.42799998535156, 81.04399997558593, 67.30000001953125, 76.20800000732422, 79.68799998779296, 79.75999998046875, 72.96399999023437, 79.08399999267579, 78.97599998046876, 79.23599997314453, 79.13999998291015, 77.816, 76.524, 78.06000001708985, 76.54799998535157, 81.57199997314453, 81.24400001220702, 75.27599999023437, 80.54399998535156, 79.052, 80.38000000488282, 78.8920000024414, 79.83199997558594, 81.53199997802734, 73.84000001953125, 79.89199997314454, 77.56800000488282, 79.63599997558593, 82.38400001464844, 80.96399997070313, 81.15199998291016, 81.20000001953125, 81.72800000976562, 81.13199997558594, 81.27199998291016, 82.62000001220703, 80.55200000732422, 82.01999997070313, 81.62399997314454, 83.62000000488281, 82.81199999267578, 83.42400001708984, 81.61600001708985, 83.80799997802734, 84.21600000488282, 83.50800001708984, 84.52799999023438, 82.46399999267578, 83.76400000488282, 84.95200001464843, 83.99600001953125, 84.69599999755859, 84.68400001953125, 84.36400001708985, 85.46400000244141, 85.20000000976563, 85.02399997070313, 84.59599997070312, 85.32000000732423, 85.34799999755859, 85.65200000976563, 85.86000000732422, 85.70000000732422, 85.7479999975586, 85.96800001953125, 85.9560000024414, 86.10400001708985, 86.11999999023438, 86.18800001220703, 86.18400001220704, 86.39200000488282, 86.2840000024414, 86.5279999975586, 86.35200000976562, 86.324, 86.61999998291016, 86.59199997314452, 86.82, 86.6919999975586, 86.73199998291015, 86.67199999023437, 86.77600000732421, 86.76800000976563, 86.73600000976562, 86.776, 86.80400001708985, 86.78800000732421, 86.70799999755859, 86.7280000024414, 86.69600001220704, 86.74800001708985, 86.81], 'cost_info': {'flops': 19.57953, 'params': 0.157306, 'latency': 0.01700269443946972, 'train_time': 9.658029774824778}}}\n","\u001b[32m[05/23 16:33:46 nl.defaults.trainer]: \u001b[0mEpoch 0 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:33:46 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:46 nl.defaults.trainer]: \u001b[0mEpoch 1 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:33:46 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:47 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 3\n","\u001b[32m[05/23 16:33:47 nl.defaults.trainer]: \u001b[0mEpoch 2 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:33:47 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:47 nl.defaults.trainer]: \u001b[0mEpoch 3 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:33:47 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:47 nl.defaults.trainer]: \u001b[0mEpoch 4 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:47 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:47 nl.defaults.trainer]: \u001b[0mEpoch 5 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:47 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:48 nl.defaults.trainer]: \u001b[0mEpoch 6 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:48 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:48 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 8\n","\u001b[32m[05/23 16:33:48 nl.defaults.trainer]: \u001b[0mEpoch 7 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:48 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:48 nl.defaults.trainer]: \u001b[0mEpoch 8 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:48 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:49 nl.defaults.trainer]: \u001b[0mEpoch 9 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:49 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:49 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 11\n","\u001b[32m[05/23 16:33:49 nl.defaults.trainer]: \u001b[0mEpoch 10 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:49 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:49 nl.defaults.trainer]: \u001b[0mEpoch 11 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:49 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:49 nl.defaults.trainer]: \u001b[0mEpoch 12 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:49 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:50 nl.defaults.trainer]: \u001b[0mEpoch 13 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:50 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:50 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 15\n","\u001b[32m[05/23 16:33:50 nl.defaults.trainer]: \u001b[0mEpoch 14 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:50 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:50 nl.defaults.trainer]: \u001b[0mEpoch 15 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:50 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:51 nl.defaults.trainer]: \u001b[0mEpoch 16, Anytime results: {'cifar10-valid': {'train_losses': [1.7726301501464843, 1.2632741512680055, 1.0350315731430053, 0.9116640870666504, 0.8138554672622681, 0.7384605021095276, 0.6771002819061279, 0.6386288579177857, 0.5977942006492615, 0.566234061164856, 0.5407228638648987, 0.5169966495037079, 0.5059799674415588, 0.49211094816207884, 0.47442392370224, 0.4547991913414001, 0.45366372842788694, 0.44375011929512026, 0.4291874082946777, 0.4207805109882355, 0.4070393644332886, 0.4128223983192444, 0.3933644982147217, 0.3912780677032471, 0.39287704973220827, 0.37701327048301697, 0.3703632626247406, 0.36252842462539675, 0.3545865700340271, 0.36439799418449403, 0.35175954774856566, 0.352374792804718, 0.3494409676837921, 0.34050146408081056, 0.33357596693992614, 0.3253499046516418, 0.3226811494445801, 0.32070203971862793, 0.32613728584289553, 0.3122583133125305, 0.31861459453582763, 0.29858239007949827, 0.3031420729446411, 0.29814767778396606, 0.30188757351875306, 0.2935050654029846, 0.2895284996509552, 0.29574748558044434, 0.28127229190826414, 0.2788175543785095, 0.2840972238445282, 0.27199181344032286, 0.27290838750839236, 0.26574461709022523, 0.27254494309425353, 0.2622075592327118, 0.2729633536148071, 0.2605763591194153, 0.258357668504715, 0.23966920917510987, 0.2618053030633926, 0.25782158448696135, 0.24394119193077088, 0.2535585989665985, 0.2447747621011734, 0.239952808508873, 0.24004719898223878, 0.23840140478134156, 0.24016718745708465, 0.23675682633399964, 0.22616518263816834, 0.21403014478683471, 0.22661552424430847, 0.22467548847675323, 0.20833352692604065, 0.21816086867809295, 0.21417523289680482, 0.21433385649681092, 0.20875024881839752, 0.20629779204368592, 0.1999822235584259, 0.20519787709236145, 0.1970332114267349, 0.19073082847595216, 0.19611911709308624, 0.1894867743396759, 0.19472460577487946, 0.17954142199993134, 0.17535858225107193, 0.18349442404270172, 0.17372775327205658, 0.17052123005867004, 0.17219759708881377, 0.1724909539937973, 0.16931497011661528, 0.16221350789546968, 0.1642095751476288, 0.1597701438188553, 0.15603769296169281, 0.15719229858636857, 0.15613695202350616, 0.14955226908683777, 0.14637396189451218, 0.14552984980583192, 0.1412839818239212, 0.14201841655254363, 0.14395703977823257, 0.13532956699371337, 0.12968134902000428, 0.1280316431903839, 0.1239628472828865, 0.11874924341201783, 0.12164036078929902, 0.11990649643421174, 0.1160284399986267, 0.11443230902433395, 0.11033453067302704, 0.10941301799297333, 0.10761771523952485, 0.10543239567756653, 0.09001801859736443, 0.10175345405340194, 0.09055124494314194, 0.08845513292551041, 0.08165875105142593, 0.08407168956756592, 0.08406028326034545, 0.08446159843683243, 0.08083324142694473, 0.07214234795331954, 0.07961240248322488, 0.07521961565852166, 0.07206464721918106, 0.06412235758781433, 0.05742816984653473, 0.06045057648539543, 0.05137665984988213, 0.049202715791463854, 0.049984927271604536, 0.04855161390900612, 0.047922370524406434, 0.043593682114481926, 0.039393371309041976, 0.03481456549406051, 0.03561475551605225, 0.03113965147972107, 0.027730674822330475, 0.03230222392678261, 0.02651573492050171, 0.027377016479969023, 0.022964896864891053, 0.022539460213184356, 0.023155455704927445, 0.020795817275047302, 0.019449235087633132, 0.016223811691999435, 0.015722117793262005, 0.014958812029063701, 0.012903136225938796, 0.011836160101294518, 0.010960419072806836, 0.011182013713121414, 0.010827825953662395, 0.009900919553041457, 0.008297104788422584, 0.0077525005152821545, 0.006521991423070431, 0.006128952867686749, 0.006098052520677447, 0.005712904340922833, 0.00588519031316042, 0.004925194225162268, 0.0043670635037124155, 0.004761073724329472, 0.0037600692857801916, 0.004550940673947334, 0.004170487490743399, 0.004020287989675998, 0.004145785541385412, 0.003908578156679869, 0.003949201945364475, 0.003207805385775864, 0.003279204101189971, 0.003943141021057963, 0.0038551958274841308, 0.0034629081816226243, 0.0034469756795093417, 0.0031426940720528365, 0.0034230355936288835, 0.0032149739553034304, 0.003457264813706279, 0.0033051802176237107, 0.003482307368069887, 0.003406692513898015, 0.0032044207777082922, 0.0028920193284004926, 0.003023021241724491, 0.0034502618987113237, 0.003478339290767908, 0.0033523044963926075], 'eval_losses': [2.164647883682251, 1.6545580722427369, 1.4628006410598755, 1.1600808632278443, 1.3669910679244994, 0.9744308032226563, 0.9985012427902221, 0.9576312366867066, 0.8076681733703613, 0.8454236519622803, 0.9638540901184082, 0.7826630718803406, 1.104512394886017, 0.7641541923141479, 0.6548123612785339, 0.9922218333053588, 0.8117137370300292, 1.2596006659698487, 0.8352864991950989, 0.7102846459007263, 0.948417996635437, 0.6667930041122436, 0.6735515013122558, 0.6765720962524414, 0.6404460549545288, 0.5868661316299438, 0.8539215717697144, 0.671702494392395, 1.013946421394348, 0.7828061346626282, 0.6231124632453918, 0.9472909074783326, 0.9412059941101074, 0.7917986108016968, 0.6953180638313293, 0.5138192662715911, 0.6458280938911438, 0.5993597709274292, 0.6608743241500854, 0.5610510663795472, 0.9400737268257141, 0.9475615718841552, 0.6772247442245484, 0.7058313579368591, 0.6999283320236206, 0.7601127938270569, 0.5406990502738953, 0.6744494660568238, 0.657445820388794, 0.6360727245140075, 0.602183510017395, 0.6638840437507629, 0.5764787740898132, 0.7622425645637512, 0.6026571141052246, 0.6648900294494628, 0.8960332232666015, 0.6581889182662964, 0.6574881332015992, 0.764426356048584, 0.5661938891410828, 0.5509537802505493, 0.6939318278503418, 0.8738080065155029, 0.8335734016609192, 0.5141450018692016, 0.5745392135429382, 0.8005889149475097, 0.5406961914157867, 0.5273537969589234, 0.7863380772590637, 0.5588566858005524, 0.6890827312850952, 0.6057677677345276, 0.5635084333992004, 0.6811963825798034, 0.61648023935318, 1.012724828414917, 0.6362171352672576, 0.600728142566681, 0.8946510879516602, 0.6929350837135315, 0.7718009796142579, 0.6391929166984558, 0.5173586741065979, 0.5696404926109314, 0.696883238658905, 0.5419068127822876, 0.5304592200279236, 0.49453839639663694, 0.6299375939750671, 0.5407747402286529, 0.5964672617912292, 0.6953459352493286, 0.4981718883323669, 0.5146202296638489, 0.6263791172599793, 0.4971261043357849, 0.541742048034668, 0.5074004801368713, 0.5106167580413818, 0.5403941158676148, 0.4952197231388092, 0.5036902098464966, 0.5564737716388702, 0.6205085544586182, 0.5223774889564514, 0.636497908191681, 0.5072039118480682, 0.5414098038864136, 0.577336726436615, 0.6121881593322754, 0.5503580962467194, 0.5647501354217529, 0.5259331694030762, 0.5857357997512818, 0.6622110190010071, 0.5913814347076416, 0.5286097303771973, 0.6344818830299378, 0.5167601127433776, 0.5717268344116211, 0.503782015247345, 0.5718589818191528, 0.5040748626327515, 0.5289617172050476, 0.5618893656158447, 0.6697765984916687, 0.4896399263381958, 0.5026871321678161, 0.5995179688262939, 0.5867765543365479, 0.6022817820549011, 0.5503802780532837, 0.5891882818222046, 0.5659550923728943, 0.5393634149551392, 0.4725204941082001, 0.5599682631874084, 0.49285970909118654, 0.4587254029464722, 0.5250094151496887, 0.4481734387016296, 0.5108769823455811, 0.46357153235435483, 0.46746708969116213, 0.5047348567390442, 0.5160715837097168, 0.4970678808498383, 0.47975242698669435, 0.46656886087417604, 0.4607551993751526, 0.4550916090297699, 0.4969077893257141, 0.45320259128570556, 0.4825685316467285, 0.4614853197288513, 0.4551181153869629, 0.4619613722896576, 0.4459185376644135, 0.4371619209480286, 0.43250919277191163, 0.4586801371669769, 0.4258842087650299, 0.4228464393901825, 0.43363750972747805, 0.424913526930809, 0.42323920888900757, 0.43190860176086426, 0.4162640994262695, 0.4204883956050873, 0.42004101861953735, 0.41806100769519805, 0.41835685523986815, 0.4199794206905365, 0.4170577170944214, 0.4155419568443298, 0.4160143413925171, 0.4168384044075012, 0.4160309219741821, 0.4137410012769699, 0.4120999512767792, 0.41584254943847654, 0.4088985359096527, 0.41060246324539185, 0.4111568983078003, 0.4107550534629822, 0.415529646282196, 0.413400959815979, 0.41062481578826904, 0.41101011686325073, 0.4162301109313965, 0.41249493049621583, 0.411628330783844, 0.4098601459789276, 0.41143245264053346, 0.41225017765045163, 0.413348842458725, 0.41110972929000855, 0.41610408491134643, 0.4268304099082947], 'train_acc1es': [33.06400000732422, 53.84400000122071, 62.50399999267578, 67.13199997314453, 70.876, 73.9, 76.27199998535156, 77.71199999755859, 79.13600000976562, 80.49200001464844, 81.03199999023437, 81.96000001953125, 82.45600001708985, 82.82399997802735, 83.49999999023437, 84.28000000244141, 84.20799997070313, 84.70000001220703, 85.17199997802734, 85.36399999023438, 85.78799997558593, 85.72800000488282, 86.34800000244141, 86.48400000488282, 86.36799999267578, 87.00000000244141, 87.13600001708984, 87.4, 87.644, 87.2879999975586, 87.82800001464844, 87.57200001708985, 87.85599999511719, 88.41599999511719, 88.52000001464843, 88.6, 88.87599998535157, 88.7480000024414, 88.6, 89.07200001708985, 88.96, 89.72399999023438, 89.648, 89.4799999975586, 89.31999997802734, 89.83199999511719, 89.99199998779297, 89.57999998046876, 90.09199999511719, 90.32799999511718, 89.94399998291016, 90.49999999755859, 90.60799999267579, 90.68799997802735, 90.72399999023438, 90.81200000732422, 90.4119999975586, 90.97999999267579, 90.916, 91.71199998046875, 90.89999998291016, 91.09199997314452, 91.5200000024414, 91.10399998291015, 91.51999998779297, 91.52399999023437, 91.75599998779298, 91.45199998779297, 91.81999997558594, 91.63199999511718, 92.27999998291016, 92.4799999975586, 92.10799997070312, 92.08799997558594, 92.76399999511719, 92.51199998779298, 92.64799997558593, 92.59199999511719, 92.53599998046874, 92.73999997558593, 92.94399999755859, 92.86399997802734, 93.09999997558593, 93.384, 93.01599997802734, 93.29999999267578, 93.23600001220703, 93.95200001464843, 93.88000001708984, 93.61599997558594, 93.92800001953125, 94.21199997558594, 94.00399997070312, 93.98399998046875, 94.18399997314454, 94.36399998046875, 94.32399999267578, 94.55599997558593, 94.58799998046875, 94.58800001708984, 94.55999997802735, 94.78800001708984, 95.09600000732422, 95.01199997070313, 95.12400001953125, 95.02399998046874, 95.06800001953125, 95.40399997070313, 95.43999997314454, 95.70799997314454, 95.76000000732422, 96.04800001220703, 95.77599997802734, 95.87600001220703, 96.02800000976562, 96.09200001220704, 96.17599997314453, 96.31600001953124, 96.32400001708984, 96.41200000976562, 97.02400000976563, 96.47600001220704, 97.00800000976562, 96.90800001464844, 97.25600000488281, 97.16400001220703, 97.16800001220703, 97.08800000488282, 97.33600000976563, 97.62000000488281, 97.27200000732422, 97.5920000048828, 97.59600000976563, 97.96800000488281, 98.12399997070312, 98.02800000488281, 98.3680000024414, 98.48000000488281, 98.34400000488282, 98.4640000048828, 98.46800001953125, 98.66000000488282, 98.73200001220704, 98.98000000488281, 98.99200000732422, 99.08400000488281, 99.21600000732421, 99.05600000732422, 99.25600000732422, 99.19600000488282, 99.3880000024414, 99.3760000024414, 99.34800000732422, 99.3800000024414, 99.45600000488281, 99.58400000732422, 99.60400000244141, 99.568, 99.704, 99.73200000244141, 99.72, 99.736, 99.768, 99.824, 99.828, 99.868, 99.912, 99.92, 99.9, 99.89600000244141, 99.9040000024414, 99.936, 99.948, 99.96, 99.968, 99.952, 99.96, 99.976, 99.956, 99.952, 99.968, 99.976, 99.988, 99.956, 99.956, 99.976, 99.972, 99.984, 99.984, 99.968, 99.964, 99.9840000024414, 99.972, 99.976, 99.988, 99.98, 99.992, 99.964, 99.948, 99.964], 'eval_acc1es': [33.344, 43.964000007324216, 54.803999992675784, 62.55600000732422, 57.4680000012207, 66.68399998046876, 64.57600001220703, 68.19200000976562, 72.40000000488281, 72.42400000732422, 70.71599999267578, 73.48400000488282, 66.98400001953125, 74.51200001953126, 78.53599998046874, 68.46400000976563, 74.052, 65.61199998535156, 73.72800000488282, 77.83199999023438, 70.62000001708985, 78.69999998779296, 78.70799997314454, 78.82799999023437, 79.01999998291015, 80.87199997314453, 75.85199998291016, 77.97600001464843, 70.88799999023438, 75.66, 80.45199999267578, 74.11199998535156, 72.39599997070313, 77.23999998779297, 78.49599997558593, 83.26400001953125, 79.86799997314453, 80.86399997314453, 79.84799997558594, 82.13999998291015, 73.98399999267578, 73.21199997070312, 80.00399998046875, 79.31999999023438, 78.55999999023437, 77.32799999023437, 82.14400001464844, 79.76000001953125, 79.46400000244141, 81.29999999023437, 82.09999997558593, 80.80400001464844, 81.46400001953126, 78.54799998046875, 81.27199997558594, 80.28799999267578, 74.4479999975586, 80.75999997070312, 79.66399997314453, 79.67200000976563, 82.46000001464844, 82.94800001220703, 79.46399999267578, 75.77600001953125, 76.55199999267577, 84.17200001708984, 82.84399997558593, 78.06400000732422, 83.29600001708984, 83.88400001708985, 78.0999999975586, 83.05200001464844, 80.34799997802735, 81.83599998779297, 83.07200001953125, 80.64800001953125, 81.63599998046875, 73.6560000024414, 81.51600001708984, 82.86799997314453, 76.00400000488281, 80.75200001953125, 78.76799999023437, 81.66799997314453, 85.23600000488281, 83.28000000244141, 80.49600001953125, 84.19600001464843, 84.69199997314453, 85.31199997070313, 81.82000001953125, 84.21600001464844, 83.71600001953125, 82.01599997802734, 85.52800000976562, 85.24399997314453, 82.19999997314453, 85.89200000488282, 84.30400001708985, 85.43999997802734, 84.89200001708984, 84.336, 85.76800000244141, 85.12800001708985, 84.37600001220703, 82.62800001464844, 85.66399999755859, 82.81599997802735, 85.33999999755859, 85.16799997070312, 84.60400001464843, 83.93600000732422, 84.82, 85.06800001708984, 85.49600001464843, 84.53200001220704, 82.67200001953125, 84.89600001708985, 85.56400000488281, 83.27999997802735, 85.84800001953126, 85.16400000488281, 86.22400001464844, 85.64800001953125, 87.1240000024414, 85.80799998046875, 84.71599999511719, 83.96000000488282, 87.04799999023437, 87.37999999267578, 84.604, 85.54000000488281, 85.18399997314454, 85.95200000976563, 85.15999997070313, 85.824, 86.804, 88.17199999267578, 86.368, 87.824, 88.35999999511719, 86.96399997070313, 88.5159999975586, 87.6240000024414, 88.36799999267578, 88.30399997802735, 87.97200000976562, 87.88800001708984, 88.056, 88.57599998779297, 88.68000000976562, 88.64799999023438, 89.184, 88.39599999267578, 89.404, 88.8519999975586, 89.16799998291016, 89.32399999023437, 89.30799998291016, 89.74399999023437, 89.86, 89.80799999511719, 89.1800000024414, 90.05999998535157, 89.9839999975586, 89.90399997314454, 90.14799997558593, 90.14799998779297, 90.0959999975586, 90.15999999267578, 90.16799998535156, 90.41599998535156, 90.28799997314454, 90.27599999511719, 90.31999998046875, 90.45599999023437, 90.37599998535157, 90.30799998779297, 90.49999997802735, 90.35199997558594, 90.33600001708984, 90.42799999023437, 90.31999998779297, 90.43999998535156, 90.34399998779297, 90.39599998779296, 90.44399999267578, 90.3839999951172, 90.38799999023438, 90.35599999267578, 90.43999998291015, 90.30399997802735, 90.36399998291016, 90.38799999023438, 90.45199999023437, 90.35599999511719, 90.35999999023437, 90.36000001708985, 90.42799998046875, 90.2959999975586, 90.21], 'cost_info': {'flops': 54.96897, 'params': 0.400346, 'latency': 0.02005649867810701, 'train_time': 10.839458545049032}}}\n","\u001b[32m[05/23 16:33:51 nl.defaults.trainer]: \u001b[0mEpoch 16 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:51 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:51 nl.defaults.trainer]: \u001b[0mEpoch 17 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:51 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:51 nl.defaults.trainer]: \u001b[0mEpoch 18 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:51 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:51 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 20\n","\u001b[32m[05/23 16:33:51 nl.defaults.trainer]: \u001b[0mEpoch 19 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:51 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:52 nl.defaults.trainer]: \u001b[0mEpoch 20 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:52 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:52 nl.defaults.trainer]: \u001b[0mEpoch 21 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:52 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:53 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 23\n","\u001b[32m[05/23 16:33:53 nl.defaults.trainer]: \u001b[0mEpoch 22 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:53 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:53 nl.defaults.trainer]: \u001b[0mEpoch 23 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:53 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:53 nl.defaults.trainer]: \u001b[0mEpoch 24 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:53 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:53 nl.defaults.trainer]: \u001b[0mEpoch 25 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:53 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:54 nl.defaults.trainer]: \u001b[0mEpoch 26 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:54 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:54 nl.optimizers.discrete.re.optimizer]: \u001b[0mPopulation size 28\n","\u001b[32m[05/23 16:33:54 nl.defaults.trainer]: \u001b[0mEpoch 27 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:54 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:54 nl.defaults.trainer]: \u001b[0mEpoch 28 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:54 nl.optimizers.discrete.re.optimizer]: \u001b[0mStart sampling architectures to fill the population\n","\u001b[32m[05/23 16:33:54 nl.defaults.trainer]: \u001b[0mEpoch 29 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:55 nl.defaults.trainer]: \u001b[0mEpoch 30 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:55 nl.defaults.trainer]: \u001b[0mEpoch 31 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:55 nl.defaults.trainer]: \u001b[0mEpoch 32 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:56 nl.defaults.trainer]: \u001b[0mEpoch 33 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:56 nl.defaults.trainer]: \u001b[0mEpoch 34, Anytime results: {'cifar10-valid': {'train_losses': [1.7726301501464843, 1.2632741512680055, 1.0350315731430053, 0.9116640870666504, 0.8138554672622681, 0.7384605021095276, 0.6771002819061279, 0.6386288579177857, 0.5977942006492615, 0.566234061164856, 0.5407228638648987, 0.5169966495037079, 0.5059799674415588, 0.49211094816207884, 0.47442392370224, 0.4547991913414001, 0.45366372842788694, 0.44375011929512026, 0.4291874082946777, 0.4207805109882355, 0.4070393644332886, 0.4128223983192444, 0.3933644982147217, 0.3912780677032471, 0.39287704973220827, 0.37701327048301697, 0.3703632626247406, 0.36252842462539675, 0.3545865700340271, 0.36439799418449403, 0.35175954774856566, 0.352374792804718, 0.3494409676837921, 0.34050146408081056, 0.33357596693992614, 0.3253499046516418, 0.3226811494445801, 0.32070203971862793, 0.32613728584289553, 0.3122583133125305, 0.31861459453582763, 0.29858239007949827, 0.3031420729446411, 0.29814767778396606, 0.30188757351875306, 0.2935050654029846, 0.2895284996509552, 0.29574748558044434, 0.28127229190826414, 0.2788175543785095, 0.2840972238445282, 0.27199181344032286, 0.27290838750839236, 0.26574461709022523, 0.27254494309425353, 0.2622075592327118, 0.2729633536148071, 0.2605763591194153, 0.258357668504715, 0.23966920917510987, 0.2618053030633926, 0.25782158448696135, 0.24394119193077088, 0.2535585989665985, 0.2447747621011734, 0.239952808508873, 0.24004719898223878, 0.23840140478134156, 0.24016718745708465, 0.23675682633399964, 0.22616518263816834, 0.21403014478683471, 0.22661552424430847, 0.22467548847675323, 0.20833352692604065, 0.21816086867809295, 0.21417523289680482, 0.21433385649681092, 0.20875024881839752, 0.20629779204368592, 0.1999822235584259, 0.20519787709236145, 0.1970332114267349, 0.19073082847595216, 0.19611911709308624, 0.1894867743396759, 0.19472460577487946, 0.17954142199993134, 0.17535858225107193, 0.18349442404270172, 0.17372775327205658, 0.17052123005867004, 0.17219759708881377, 0.1724909539937973, 0.16931497011661528, 0.16221350789546968, 0.1642095751476288, 0.1597701438188553, 0.15603769296169281, 0.15719229858636857, 0.15613695202350616, 0.14955226908683777, 0.14637396189451218, 0.14552984980583192, 0.1412839818239212, 0.14201841655254363, 0.14395703977823257, 0.13532956699371337, 0.12968134902000428, 0.1280316431903839, 0.1239628472828865, 0.11874924341201783, 0.12164036078929902, 0.11990649643421174, 0.1160284399986267, 0.11443230902433395, 0.11033453067302704, 0.10941301799297333, 0.10761771523952485, 0.10543239567756653, 0.09001801859736443, 0.10175345405340194, 0.09055124494314194, 0.08845513292551041, 0.08165875105142593, 0.08407168956756592, 0.08406028326034545, 0.08446159843683243, 0.08083324142694473, 0.07214234795331954, 0.07961240248322488, 0.07521961565852166, 0.07206464721918106, 0.06412235758781433, 0.05742816984653473, 0.06045057648539543, 0.05137665984988213, 0.049202715791463854, 0.049984927271604536, 0.04855161390900612, 0.047922370524406434, 0.043593682114481926, 0.039393371309041976, 0.03481456549406051, 0.03561475551605225, 0.03113965147972107, 0.027730674822330475, 0.03230222392678261, 0.02651573492050171, 0.027377016479969023, 0.022964896864891053, 0.022539460213184356, 0.023155455704927445, 0.020795817275047302, 0.019449235087633132, 0.016223811691999435, 0.015722117793262005, 0.014958812029063701, 0.012903136225938796, 0.011836160101294518, 0.010960419072806836, 0.011182013713121414, 0.010827825953662395, 0.009900919553041457, 0.008297104788422584, 0.0077525005152821545, 0.006521991423070431, 0.006128952867686749, 0.006098052520677447, 0.005712904340922833, 0.00588519031316042, 0.004925194225162268, 0.0043670635037124155, 0.004761073724329472, 0.0037600692857801916, 0.004550940673947334, 0.004170487490743399, 0.004020287989675998, 0.004145785541385412, 0.003908578156679869, 0.003949201945364475, 0.003207805385775864, 0.003279204101189971, 0.003943141021057963, 0.0038551958274841308, 0.0034629081816226243, 0.0034469756795093417, 0.0031426940720528365, 0.0034230355936288835, 0.0032149739553034304, 0.003457264813706279, 0.0033051802176237107, 0.003482307368069887, 0.003406692513898015, 0.0032044207777082922, 0.0028920193284004926, 0.003023021241724491, 0.0034502618987113237, 0.003478339290767908, 0.0033523044963926075], 'eval_losses': [2.164647883682251, 1.6545580722427369, 1.4628006410598755, 1.1600808632278443, 1.3669910679244994, 0.9744308032226563, 0.9985012427902221, 0.9576312366867066, 0.8076681733703613, 0.8454236519622803, 0.9638540901184082, 0.7826630718803406, 1.104512394886017, 0.7641541923141479, 0.6548123612785339, 0.9922218333053588, 0.8117137370300292, 1.2596006659698487, 0.8352864991950989, 0.7102846459007263, 0.948417996635437, 0.6667930041122436, 0.6735515013122558, 0.6765720962524414, 0.6404460549545288, 0.5868661316299438, 0.8539215717697144, 0.671702494392395, 1.013946421394348, 0.7828061346626282, 0.6231124632453918, 0.9472909074783326, 0.9412059941101074, 0.7917986108016968, 0.6953180638313293, 0.5138192662715911, 0.6458280938911438, 0.5993597709274292, 0.6608743241500854, 0.5610510663795472, 0.9400737268257141, 0.9475615718841552, 0.6772247442245484, 0.7058313579368591, 0.6999283320236206, 0.7601127938270569, 0.5406990502738953, 0.6744494660568238, 0.657445820388794, 0.6360727245140075, 0.602183510017395, 0.6638840437507629, 0.5764787740898132, 0.7622425645637512, 0.6026571141052246, 0.6648900294494628, 0.8960332232666015, 0.6581889182662964, 0.6574881332015992, 0.764426356048584, 0.5661938891410828, 0.5509537802505493, 0.6939318278503418, 0.8738080065155029, 0.8335734016609192, 0.5141450018692016, 0.5745392135429382, 0.8005889149475097, 0.5406961914157867, 0.5273537969589234, 0.7863380772590637, 0.5588566858005524, 0.6890827312850952, 0.6057677677345276, 0.5635084333992004, 0.6811963825798034, 0.61648023935318, 1.012724828414917, 0.6362171352672576, 0.600728142566681, 0.8946510879516602, 0.6929350837135315, 0.7718009796142579, 0.6391929166984558, 0.5173586741065979, 0.5696404926109314, 0.696883238658905, 0.5419068127822876, 0.5304592200279236, 0.49453839639663694, 0.6299375939750671, 0.5407747402286529, 0.5964672617912292, 0.6953459352493286, 0.4981718883323669, 0.5146202296638489, 0.6263791172599793, 0.4971261043357849, 0.541742048034668, 0.5074004801368713, 0.5106167580413818, 0.5403941158676148, 0.4952197231388092, 0.5036902098464966, 0.5564737716388702, 0.6205085544586182, 0.5223774889564514, 0.636497908191681, 0.5072039118480682, 0.5414098038864136, 0.577336726436615, 0.6121881593322754, 0.5503580962467194, 0.5647501354217529, 0.5259331694030762, 0.5857357997512818, 0.6622110190010071, 0.5913814347076416, 0.5286097303771973, 0.6344818830299378, 0.5167601127433776, 0.5717268344116211, 0.503782015247345, 0.5718589818191528, 0.5040748626327515, 0.5289617172050476, 0.5618893656158447, 0.6697765984916687, 0.4896399263381958, 0.5026871321678161, 0.5995179688262939, 0.5867765543365479, 0.6022817820549011, 0.5503802780532837, 0.5891882818222046, 0.5659550923728943, 0.5393634149551392, 0.4725204941082001, 0.5599682631874084, 0.49285970909118654, 0.4587254029464722, 0.5250094151496887, 0.4481734387016296, 0.5108769823455811, 0.46357153235435483, 0.46746708969116213, 0.5047348567390442, 0.5160715837097168, 0.4970678808498383, 0.47975242698669435, 0.46656886087417604, 0.4607551993751526, 0.4550916090297699, 0.4969077893257141, 0.45320259128570556, 0.4825685316467285, 0.4614853197288513, 0.4551181153869629, 0.4619613722896576, 0.4459185376644135, 0.4371619209480286, 0.43250919277191163, 0.4586801371669769, 0.4258842087650299, 0.4228464393901825, 0.43363750972747805, 0.424913526930809, 0.42323920888900757, 0.43190860176086426, 0.4162640994262695, 0.4204883956050873, 0.42004101861953735, 0.41806100769519805, 0.41835685523986815, 0.4199794206905365, 0.4170577170944214, 0.4155419568443298, 0.4160143413925171, 0.4168384044075012, 0.4160309219741821, 0.4137410012769699, 0.4120999512767792, 0.41584254943847654, 0.4088985359096527, 0.41060246324539185, 0.4111568983078003, 0.4107550534629822, 0.415529646282196, 0.413400959815979, 0.41062481578826904, 0.41101011686325073, 0.4162301109313965, 0.41249493049621583, 0.411628330783844, 0.4098601459789276, 0.41143245264053346, 0.41225017765045163, 0.413348842458725, 0.41110972929000855, 0.41610408491134643, 0.4268304099082947], 'train_acc1es': [33.06400000732422, 53.84400000122071, 62.50399999267578, 67.13199997314453, 70.876, 73.9, 76.27199998535156, 77.71199999755859, 79.13600000976562, 80.49200001464844, 81.03199999023437, 81.96000001953125, 82.45600001708985, 82.82399997802735, 83.49999999023437, 84.28000000244141, 84.20799997070313, 84.70000001220703, 85.17199997802734, 85.36399999023438, 85.78799997558593, 85.72800000488282, 86.34800000244141, 86.48400000488282, 86.36799999267578, 87.00000000244141, 87.13600001708984, 87.4, 87.644, 87.2879999975586, 87.82800001464844, 87.57200001708985, 87.85599999511719, 88.41599999511719, 88.52000001464843, 88.6, 88.87599998535157, 88.7480000024414, 88.6, 89.07200001708985, 88.96, 89.72399999023438, 89.648, 89.4799999975586, 89.31999997802734, 89.83199999511719, 89.99199998779297, 89.57999998046876, 90.09199999511719, 90.32799999511718, 89.94399998291016, 90.49999999755859, 90.60799999267579, 90.68799997802735, 90.72399999023438, 90.81200000732422, 90.4119999975586, 90.97999999267579, 90.916, 91.71199998046875, 90.89999998291016, 91.09199997314452, 91.5200000024414, 91.10399998291015, 91.51999998779297, 91.52399999023437, 91.75599998779298, 91.45199998779297, 91.81999997558594, 91.63199999511718, 92.27999998291016, 92.4799999975586, 92.10799997070312, 92.08799997558594, 92.76399999511719, 92.51199998779298, 92.64799997558593, 92.59199999511719, 92.53599998046874, 92.73999997558593, 92.94399999755859, 92.86399997802734, 93.09999997558593, 93.384, 93.01599997802734, 93.29999999267578, 93.23600001220703, 93.95200001464843, 93.88000001708984, 93.61599997558594, 93.92800001953125, 94.21199997558594, 94.00399997070312, 93.98399998046875, 94.18399997314454, 94.36399998046875, 94.32399999267578, 94.55599997558593, 94.58799998046875, 94.58800001708984, 94.55999997802735, 94.78800001708984, 95.09600000732422, 95.01199997070313, 95.12400001953125, 95.02399998046874, 95.06800001953125, 95.40399997070313, 95.43999997314454, 95.70799997314454, 95.76000000732422, 96.04800001220703, 95.77599997802734, 95.87600001220703, 96.02800000976562, 96.09200001220704, 96.17599997314453, 96.31600001953124, 96.32400001708984, 96.41200000976562, 97.02400000976563, 96.47600001220704, 97.00800000976562, 96.90800001464844, 97.25600000488281, 97.16400001220703, 97.16800001220703, 97.08800000488282, 97.33600000976563, 97.62000000488281, 97.27200000732422, 97.5920000048828, 97.59600000976563, 97.96800000488281, 98.12399997070312, 98.02800000488281, 98.3680000024414, 98.48000000488281, 98.34400000488282, 98.4640000048828, 98.46800001953125, 98.66000000488282, 98.73200001220704, 98.98000000488281, 98.99200000732422, 99.08400000488281, 99.21600000732421, 99.05600000732422, 99.25600000732422, 99.19600000488282, 99.3880000024414, 99.3760000024414, 99.34800000732422, 99.3800000024414, 99.45600000488281, 99.58400000732422, 99.60400000244141, 99.568, 99.704, 99.73200000244141, 99.72, 99.736, 99.768, 99.824, 99.828, 99.868, 99.912, 99.92, 99.9, 99.89600000244141, 99.9040000024414, 99.936, 99.948, 99.96, 99.968, 99.952, 99.96, 99.976, 99.956, 99.952, 99.968, 99.976, 99.988, 99.956, 99.956, 99.976, 99.972, 99.984, 99.984, 99.968, 99.964, 99.9840000024414, 99.972, 99.976, 99.988, 99.98, 99.992, 99.964, 99.948, 99.964], 'eval_acc1es': [33.344, 43.964000007324216, 54.803999992675784, 62.55600000732422, 57.4680000012207, 66.68399998046876, 64.57600001220703, 68.19200000976562, 72.40000000488281, 72.42400000732422, 70.71599999267578, 73.48400000488282, 66.98400001953125, 74.51200001953126, 78.53599998046874, 68.46400000976563, 74.052, 65.61199998535156, 73.72800000488282, 77.83199999023438, 70.62000001708985, 78.69999998779296, 78.70799997314454, 78.82799999023437, 79.01999998291015, 80.87199997314453, 75.85199998291016, 77.97600001464843, 70.88799999023438, 75.66, 80.45199999267578, 74.11199998535156, 72.39599997070313, 77.23999998779297, 78.49599997558593, 83.26400001953125, 79.86799997314453, 80.86399997314453, 79.84799997558594, 82.13999998291015, 73.98399999267578, 73.21199997070312, 80.00399998046875, 79.31999999023438, 78.55999999023437, 77.32799999023437, 82.14400001464844, 79.76000001953125, 79.46400000244141, 81.29999999023437, 82.09999997558593, 80.80400001464844, 81.46400001953126, 78.54799998046875, 81.27199997558594, 80.28799999267578, 74.4479999975586, 80.75999997070312, 79.66399997314453, 79.67200000976563, 82.46000001464844, 82.94800001220703, 79.46399999267578, 75.77600001953125, 76.55199999267577, 84.17200001708984, 82.84399997558593, 78.06400000732422, 83.29600001708984, 83.88400001708985, 78.0999999975586, 83.05200001464844, 80.34799997802735, 81.83599998779297, 83.07200001953125, 80.64800001953125, 81.63599998046875, 73.6560000024414, 81.51600001708984, 82.86799997314453, 76.00400000488281, 80.75200001953125, 78.76799999023437, 81.66799997314453, 85.23600000488281, 83.28000000244141, 80.49600001953125, 84.19600001464843, 84.69199997314453, 85.31199997070313, 81.82000001953125, 84.21600001464844, 83.71600001953125, 82.01599997802734, 85.52800000976562, 85.24399997314453, 82.19999997314453, 85.89200000488282, 84.30400001708985, 85.43999997802734, 84.89200001708984, 84.336, 85.76800000244141, 85.12800001708985, 84.37600001220703, 82.62800001464844, 85.66399999755859, 82.81599997802735, 85.33999999755859, 85.16799997070312, 84.60400001464843, 83.93600000732422, 84.82, 85.06800001708984, 85.49600001464843, 84.53200001220704, 82.67200001953125, 84.89600001708985, 85.56400000488281, 83.27999997802735, 85.84800001953126, 85.16400000488281, 86.22400001464844, 85.64800001953125, 87.1240000024414, 85.80799998046875, 84.71599999511719, 83.96000000488282, 87.04799999023437, 87.37999999267578, 84.604, 85.54000000488281, 85.18399997314454, 85.95200000976563, 85.15999997070313, 85.824, 86.804, 88.17199999267578, 86.368, 87.824, 88.35999999511719, 86.96399997070313, 88.5159999975586, 87.6240000024414, 88.36799999267578, 88.30399997802735, 87.97200000976562, 87.88800001708984, 88.056, 88.57599998779297, 88.68000000976562, 88.64799999023438, 89.184, 88.39599999267578, 89.404, 88.8519999975586, 89.16799998291016, 89.32399999023437, 89.30799998291016, 89.74399999023437, 89.86, 89.80799999511719, 89.1800000024414, 90.05999998535157, 89.9839999975586, 89.90399997314454, 90.14799997558593, 90.14799998779297, 90.0959999975586, 90.15999999267578, 90.16799998535156, 90.41599998535156, 90.28799997314454, 90.27599999511719, 90.31999998046875, 90.45599999023437, 90.37599998535157, 90.30799998779297, 90.49999997802735, 90.35199997558594, 90.33600001708984, 90.42799999023437, 90.31999998779297, 90.43999998535156, 90.34399998779297, 90.39599998779296, 90.44399999267578, 90.3839999951172, 90.38799999023438, 90.35599999267578, 90.43999998291015, 90.30399997802735, 90.36399998291016, 90.38799999023438, 90.45199999023437, 90.35599999511719, 90.35999999023437, 90.36000001708985, 90.42799998046875, 90.2959999975586, 90.21], 'cost_info': {'flops': 54.96897, 'params': 0.400346, 'latency': 0.02005649867810701, 'train_time': 10.839458545049032}}}\n","\u001b[32m[05/23 16:33:56 nl.defaults.trainer]: \u001b[0mEpoch 34 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:33:56 nl.defaults.trainer]: \u001b[0mEpoch 35 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:56 nl.defaults.trainer]: \u001b[0mEpoch 36 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:57 nl.defaults.trainer]: \u001b[0mEpoch 37 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:57 nl.defaults.trainer]: \u001b[0mEpoch 38 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:57 nl.defaults.trainer]: \u001b[0mEpoch 39 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:57 nl.defaults.trainer]: \u001b[0mEpoch 40 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:58 nl.defaults.trainer]: \u001b[0mEpoch 41 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:58 nl.defaults.trainer]: \u001b[0mEpoch 42 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:59 nl.defaults.trainer]: \u001b[0mEpoch 43 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:59 nl.defaults.trainer]: \u001b[0mEpoch 44 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:59 nl.defaults.trainer]: \u001b[0mEpoch 45 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:33:59 nl.defaults.trainer]: \u001b[0mEpoch 46 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:00 nl.defaults.trainer]: \u001b[0mEpoch 47 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:00 nl.defaults.trainer]: \u001b[0mEpoch 48 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:00 nl.defaults.trainer]: \u001b[0mEpoch 49 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:00 nl.defaults.trainer]: \u001b[0mEpoch 50 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:01 nl.defaults.trainer]: \u001b[0mEpoch 51 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:01 nl.defaults.trainer]: \u001b[0mEpoch 52 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:02 nl.defaults.trainer]: \u001b[0mEpoch 53, Anytime results: {'cifar10-valid': {'train_losses': [1.7569053060531616, 1.2664795138931275, 1.0398911100578307, 0.9061412560462951, 0.8145561787033081, 0.7282953679084778, 0.6751605457687377, 0.6325034687423706, 0.594797575340271, 0.5714447735023499, 0.5462822461795807, 0.5183249447441101, 0.5060108277034759, 0.4860454574871063, 0.47330892276763914, 0.45837394062042236, 0.4454547724342346, 0.4367031452178955, 0.4227136728191376, 0.4114862308216095, 0.4085151299095154, 0.4044977221775055, 0.38876685503959657, 0.38440722067832944, 0.3794570953273773, 0.3773342935180664, 0.36700300178527834, 0.370111882314682, 0.35280171340942384, 0.3534411968040466, 0.34880874015808105, 0.3392093047142029, 0.33516052363395693, 0.33190925087928774, 0.3343107649898529, 0.3237089006614685, 0.3215712014198303, 0.3171178406906128, 0.30574725152015686, 0.31025762138366697, 0.30747290229797364, 0.29834707723617554, 0.29427569427490236, 0.29449756768226626, 0.29159496780872346, 0.29581981219291686, 0.2777541013431549, 0.28210052105903627, 0.2820353820800781, 0.2740921457147598, 0.2777707223701477, 0.27363268907546995, 0.27083577856063845, 0.2679726627254486, 0.25681533714294436, 0.2701511300086975, 0.2552899360322952, 0.25207480679512023, 0.2520826415157318, 0.25758047731399536, 0.23979794030189513, 0.24494134342193605, 0.2434393112182617, 0.23536221855163575, 0.22918426724910737, 0.23721468706130983, 0.22874721122741698, 0.22816264547348022, 0.2232528401231766, 0.22619380402088166, 0.2239677005815506, 0.21510418560028077, 0.2157858929157257, 0.2110674531555176, 0.2087889788532257, 0.21243365513324738, 0.20813079245567323, 0.20389643756866455, 0.19675868477344513, 0.19769202645778655, 0.19059690853595734, 0.19251479341506958, 0.18629339147090912, 0.19223606120109557, 0.18190774082660674, 0.19243542908668518, 0.1761055871105194, 0.17961711973190309, 0.17529628326892852, 0.17030297406196596, 0.16327535594940185, 0.1726509228181839, 0.163730563454628, 0.16315957696914674, 0.15815423311471938, 0.15503937411785126, 0.16293003674030304, 0.15117002528190612, 0.13990541839122772, 0.15702265500068666, 0.1439029846382141, 0.14200549327373505, 0.13383040287971495, 0.1406310504436493, 0.1364821756696701, 0.1288030527639389, 0.1294026828765869, 0.12637779561519621, 0.12131864381313325, 0.125661949262619, 0.12044794710159301, 0.11840331094264984, 0.11663053024053574, 0.11261456810951233, 0.11047457273960114, 0.1045703645825386, 0.1094984476852417, 0.10084918767690658, 0.10446519842624664, 0.09294993334293365, 0.09034513345956803, 0.08801165543079376, 0.08451360163211823, 0.07844458384990692, 0.08243906379699707, 0.08179043726205826, 0.07237742782592774, 0.07404884174466134, 0.07023863109588623, 0.06873067468523979, 0.07019079623937607, 0.06733777047038078, 0.06257209670066834, 0.0591178988468647, 0.053110786118507385, 0.057006341593265536, 0.054067337636947634, 0.048774153035879134, 0.04665558832645416, 0.05043800618171692, 0.042935804923176765, 0.03886122808098793, 0.03610275668859482, 0.03468259646952152, 0.029686471796035768, 0.03174582464873791, 0.029260967531204225, 0.023907402811050416, 0.026981608538627626, 0.0215273837184906, 0.022613820883035658, 0.02012240275144577, 0.016215642614364624, 0.017552341111302376, 0.016573177622407675, 0.014351837279200554, 0.015186065632998944, 0.013720216526985168, 0.012305273621082306, 0.009820013044774532, 0.009034747025966645, 0.008558783235102892, 0.008558888110518456, 0.007024007311463356, 0.006049726008176804, 0.006208703562021255, 0.0055816052811592815, 0.005483860322833062, 0.005120645933151245, 0.004940851823240519, 0.004379023199342191, 0.004500048578828573, 0.003829212036281824, 0.0034377170379459856, 0.003725832347124815, 0.0036780160421878098, 0.003731304369196296, 0.0033510872841253877, 0.00363513479270041, 0.00350781282491982, 0.0033855385491251945, 0.0032582418429851533, 0.0029350116714835168, 0.003581193818822503, 0.0029704603014886377, 0.0025494210241734983, 0.003201259375065565, 0.0027124761680141093, 0.0028953837013989685, 0.0030145811362564563, 0.0028955158534646032, 0.0027816221611201763, 0.0028242863665521147, 0.0024912390230596064, 0.0025807611463963985, 0.0028283434772491457, 0.0026745883461833002, 0.002818832339346409, 0.0026991494470089672, 0.002995031623542309], 'eval_losses': [1.5692320011138916, 1.692255509376526, 1.259640083770752, 1.0358222034072877, 1.1081641393280028, 0.898577421207428, 0.8860601475715637, 0.7382295448493957, 0.813926875, 0.888411948184967, 0.7486177971839905, 0.7528334671783448, 0.9931170081329346, 0.8498606488990784, 0.6512779799270629, 0.7387924125480652, 0.8116760023117066, 0.7299716124153137, 0.6730028191947937, 0.6996099607467652, 0.6411852591514587, 0.9248606335830688, 0.6231177605438233, 0.890373495979309, 0.5836540268135071, 0.6635516252326965, 0.9188884570503235, 0.6369978741645813, 0.8734158744049072, 0.7266159543991089, 0.6872789871215821, 0.813729638004303, 0.6383802032470703, 0.7549205728912354, 0.6218803883171081, 0.700077579498291, 0.6347955551338196, 0.6381415802383423, 0.7855197314834594, 0.6381312977790833, 0.6686823948478698, 0.7025910236167908, 0.6351864266395569, 0.6211878901100159, 0.61226732421875, 0.7281109514617919, 0.6917098893928528, 0.816404071598053, 0.6148451482582092, 0.7654599810791015, 0.6374987333869934, 0.6595930378913879, 0.5458997198104858, 0.7432138886642456, 0.5766457987594604, 0.6001726524925232, 0.7027325080490112, 0.7266061331176757, 0.6104864811897278, 0.5152941138839722, 0.5384895776557922, 0.4726872467136383, 0.5839475108337402, 0.6504479524230957, 0.6767966947555542, 0.8578970531463623, 0.5744328165435791, 0.5219236636161804, 0.7383748282051087, 0.48225053327560424, 0.634156963005066, 0.5497831882286072, 0.6862307289505005, 0.9092927713394166, 0.5589307807159424, 0.6638886155891418, 0.733991358089447, 0.555501425113678, 0.6120970909118653, 0.516873232345581, 0.8179938382148743, 0.5805805414962768, 0.6991592945671081, 0.6539873460960388, 0.5709471417427063, 0.6375534070968628, 0.5402056052017212, 0.6883054086875916, 0.5828042843151092, 0.6054750591659546, 0.566019707660675, 0.9152434265327454, 0.4966023212528229, 0.6784646076965332, 0.5414937542724609, 0.49248072995185854, 0.5574530310726166, 0.6342940159797669, 0.624105606880188, 0.754045444278717, 0.5569883807754517, 0.469898601732254, 0.5703178303909302, 0.5973637752342225, 0.5329736370658874, 0.5648937179946899, 0.5659561194038392, 0.5896530161857605, 0.5579477121353149, 0.6534712743759156, 0.5268841871261597, 0.6428838219451904, 0.6437939745140075, 0.48700583701133726, 0.5503930351448059, 0.6020848330116272, 0.4981022983932495, 0.46053907823562623, 0.4978150617599487, 0.6112286166381836, 0.4818751058101654, 0.4703215942335129, 0.5539687369918823, 0.5854696180915833, 0.5198580288219452, 0.5484057223129273, 0.6158625351619721, 0.5792768238639832, 0.5337661961746216, 0.5886052313423157, 0.54467154712677, 0.473427551279068, 0.4816957168865204, 0.5139731049251557, 0.550352405872345, 0.4698507158279419, 0.5226176941871643, 0.48719725017547605, 0.48560441466331483, 0.4822244606876373, 0.5956338468170166, 0.5404972162437439, 0.46963005029678345, 0.5527439107131958, 0.513271921749115, 0.4574300882911682, 0.4538339582061768, 0.47028755069732664, 0.42532012575149536, 0.4283977487182617, 0.4530713115692139, 0.4484299855709076, 0.46192191455841064, 0.4623718216705322, 0.47747744750022886, 0.4378578797149658, 0.44730199337005616, 0.4541953098487854, 0.4522034854507446, 0.4571830992126465, 0.4335714791870117, 0.427637976436615, 0.4394387770175934, 0.4353127297210693, 0.4287326905155182, 0.4174875314235687, 0.4283384783363342, 0.4249683612442017, 0.41909786179065706, 0.42239480409622193, 0.4236892115879059, 0.42108781467437745, 0.4160034220790863, 0.41670239393234254, 0.41843662134170534, 0.417412882938385, 0.4146304425907135, 0.420097362241745, 0.4165667124938965, 0.4135247115325928, 0.41516472861289977, 0.4136860141944885, 0.41217745824813845, 0.4159237167835236, 0.4151900646591187, 0.40994485832214356, 0.41669623952865603, 0.41205567766189577, 0.412605232963562, 0.41245238943099977, 0.41567705671310423, 0.41590032676696775, 0.41446701001167296, 0.4119553282356262, 0.412061138677597, 0.41358045135498045, 0.4162572134208679, 0.41225020356655123, 0.4152240486907959, 0.4137391041278839, 0.4160864718437195], 'train_acc1es': [32.86799998901367, 53.528000007324216, 62.39199997558594, 67.29599998291016, 70.92000001464844, 74.30399999511718, 76.35999998046876, 77.848, 79.05599998046875, 80.1439999975586, 81.26000001464844, 82.17599997314453, 82.22800001953125, 83.21200000488281, 83.74799997314453, 84.37599997314453, 84.82800001464844, 84.876, 85.21999999755859, 85.7, 85.77600000976562, 85.996, 86.67199998779297, 86.66000000244141, 86.87199999023437, 86.84000000488281, 87.42, 87.04400001708984, 87.7240000024414, 87.8480000048828, 87.74400000244141, 87.99199999511718, 88.35999999023437, 88.55199999511719, 88.55599998291015, 88.90799999755859, 88.88800000976562, 89.06000000488281, 89.30399998535157, 89.13599999511719, 89.29199999267578, 89.60800000488281, 89.7960000024414, 89.87599999511718, 89.94799998535156, 89.63200000976562, 90.468, 90.25999999511718, 90.17599998535157, 90.48399998046875, 90.256, 90.44799997070312, 90.67999998535156, 90.6239999975586, 90.95999999511719, 90.47199998779297, 91.05199999023438, 91.09199997802735, 91.31599998291016, 90.99999998535156, 91.65999999511719, 91.24399998046874, 91.51199998535157, 91.91599999267578, 92.03999997558594, 91.8519999975586, 92.0359999951172, 92.12000000488281, 92.23599998291016, 92.03199997558593, 92.15999997070313, 92.61599998779297, 92.39999999267579, 92.65599999023438, 92.66399997802735, 92.43599998779297, 92.73199998291015, 92.84399999267578, 92.98399998046875, 93.02399998291015, 93.29599997558594, 93.41199997802734, 93.61199997314453, 93.29599999023438, 93.79199998779296, 93.40799998046874, 94.04799997070313, 93.87199997314453, 93.85599998046875, 94.07199997314453, 94.29999997802734, 94.05999997558594, 94.37600001708985, 94.50799997314454, 94.46400000976563, 94.61200001464844, 94.27999997558594, 94.87199997070313, 95.18399997314454, 94.59999999023438, 95.19599997070313, 95.13599997314454, 95.35199997314453, 95.17599997558594, 95.31999997070312, 95.41199998291016, 95.57199998046875, 95.63600001464843, 95.59200001220704, 95.77999998046874, 95.89200001953125, 95.85599997314453, 95.98400001953125, 96.16800001464844, 96.29600001953125, 96.37200001220702, 96.30799997314453, 96.54400001464843, 96.46000001220703, 96.76799997070313, 97.09200001464843, 97.06399997558594, 97.15600001464844, 97.43200001464844, 97.29599997070312, 97.24400001464844, 97.59199997314452, 97.59600000732422, 97.64000000976563, 97.7280000024414, 97.64400001464844, 97.79200000732422, 97.98000001220703, 98.0720000024414, 98.28400001708984, 98.12800000244141, 98.21600000976562, 98.49200000976562, 98.50400001220703, 98.41600000976563, 98.56800000488282, 98.8600000048828, 98.85200000488281, 98.98800000244141, 99.08400000488281, 99.05600000244141, 99.12800000244141, 99.29600000488281, 99.18800000488281, 99.38800000732422, 99.39200000488282, 99.42000000488281, 99.60800000732422, 99.5080000024414, 99.536, 99.65200000488281, 99.592, 99.6560000024414, 99.732, 99.796, 99.7760000024414, 99.82, 99.816, 99.884, 99.9120000024414, 99.90800000244141, 99.892, 99.9000000024414, 99.928, 99.916, 99.948, 99.924, 99.972, 99.968, 99.964, 99.948, 99.964, 99.968, 99.952, 99.948, 99.96, 99.96, 99.984, 99.948, 99.984, 99.992, 99.964, 99.992, 99.964, 99.972, 99.976, 99.98, 99.984, 100.0, 99.988, 99.984, 99.984, 99.976, 99.976, 99.968], 'eval_acc1es': [41.03999999633789, 45.6880000012207, 57.227999998779296, 63.77199999023438, 62.38399999267578, 69.82399997558593, 70.60799998779297, 74.79199998046874, 72.80800001708984, 71.01599999267579, 75.71999997314452, 75.15999998046875, 66.86, 73.90399999511719, 78.76, 75.73600001708985, 75.01999998779297, 75.94400000976563, 77.948, 77.128, 78.49600001708984, 72.59999999023438, 80.14000001953124, 73.75600000976563, 81.30800001464844, 79.14799998779297, 73.75999998779297, 79.24399997802735, 74.55199998291016, 77.89599998779296, 78.79199999267578, 76.60399999023437, 80.02399997802735, 77.98399999511719, 80.54399998046875, 79.12399997070312, 80.11199997314453, 80.28399998779297, 77.16000000976562, 80.31199998535156, 79.8320000024414, 77.94800001464844, 80.63600001953125, 81.14799997802734, 80.65599997558594, 78.70799999511719, 78.72399998046875, 76.936, 81.69599998291015, 77.57199997558594, 81.30400001708985, 79.71199998779296, 83.00000000976563, 77.47599997070313, 82.50400001708984, 81.89600000732422, 79.752, 79.09599998046875, 81.71599998046875, 83.59599997070312, 83.55599997558593, 85.29599999267577, 82.30799997070312, 80.79200001953124, 81.04400001708984, 76.46000000976562, 82.97600000732422, 83.59599997802735, 78.57199999511718, 84.72800001220703, 80.96799999267579, 83.05199997070312, 80.77600001708984, 76.216, 82.832, 80.96800001953125, 80.05599998779297, 83.77200001220703, 81.68400001953125, 84.48800001953126, 77.98399998291016, 83.22799998535156, 80.58000000732422, 81.33599997802735, 83.29599999267577, 81.66000000244141, 83.95999998046875, 80.91999997070313, 82.90400001220704, 82.87600001220703, 83.94000000488282, 76.33599997802735, 85.28800000976563, 82.06400001708984, 84.24800001708985, 85.172, 84.23200000732422, 82.84000001708985, 82.76000001464844, 81.17599998535157, 84.16000000976562, 86.372, 84.9600000024414, 84.12800000732422, 85.32800001220703, 84.59600001708985, 84.35600000488282, 83.8560000024414, 85.38000000488282, 82.80400000732422, 85.43200001953124, 83.46800001708985, 82.72400001708985, 86.5519999975586, 85.53200000976562, 84.38800000976562, 86.41200000732422, 87.2719999975586, 86.27199997070312, 84.31200000488282, 87.14799998535156, 87.47599998779297, 86.25200000488282, 85.28400001220703, 86.26399999511719, 85.78000000976563, 84.824, 85.95600001220703, 86.45600000976563, 85.24800000732422, 86.38800000488281, 87.76399998046875, 87.66399999267578, 87.2159999975586, 86.19599999755859, 88.30799998291016, 87.296, 87.94799997802734, 88.15599998779297, 88.10799999267579, 86.59999999023438, 87.43599999023438, 88.64800001953125, 87.35200001464844, 87.81599999267578, 89.0279999975586, 89.04400000244141, 88.91199998291016, 89.42000000244141, 89.656, 89.24799999511718, 89.55599997802734, 89.372, 89.47599999511719, 89.17199998291015, 89.66400001220703, 89.89199999511719, 89.48799999267578, 89.65199999755859, 89.83199998779297, 90.0359999951172, 90.30799998779297, 89.94800000732423, 90.18799999755859, 90.49599998535156, 90.62399997070312, 90.38799998779297, 90.52000001220703, 90.73199998046876, 90.52799997558594, 90.53999998779297, 90.57599998779297, 90.80000001953125, 90.69999998291016, 90.7639999975586, 90.70399998046875, 90.82399999267578, 90.71599997070312, 90.76800000244141, 90.77599998291015, 90.85599998291016, 90.77599998291015, 90.75999998291016, 90.77999998535157, 90.83199998535156, 90.79599998046875, 90.80399999267578, 90.77599999023437, 90.73599999511718, 90.79199999023437, 90.78400001220703, 90.8, 90.76799998291015, 90.80399999023437, 90.81999998535156, 90.81999998535156, 90.78799999267578, 90.84400001708984, 90.78799999511719, 90.79199997070313, 90.8], 'cost_info': {'flops': 86.42625, 'params': 0.615386, 'latency': 0.019886672496795654, 'train_time': 11.101390759150187}}}\n","\u001b[32m[05/23 16:34:02 nl.defaults.trainer]: \u001b[0mEpoch 53 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:02 nl.defaults.trainer]: \u001b[0mEpoch 54 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:02 nl.defaults.trainer]: \u001b[0mEpoch 55 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:02 nl.defaults.trainer]: \u001b[0mEpoch 56 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:03 nl.defaults.trainer]: \u001b[0mEpoch 57 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:03 nl.defaults.trainer]: \u001b[0mEpoch 58 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:03 nl.defaults.trainer]: \u001b[0mEpoch 59 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:03 nl.defaults.trainer]: \u001b[0mEpoch 60 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:04 nl.defaults.trainer]: \u001b[0mEpoch 61 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:04 nl.defaults.trainer]: \u001b[0mEpoch 62 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:04 nl.defaults.trainer]: \u001b[0mEpoch 63 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:04 nl.defaults.trainer]: \u001b[0mEpoch 64 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:04 nl.defaults.trainer]: \u001b[0mEpoch 65 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:05 nl.defaults.trainer]: \u001b[0mEpoch 66 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:05 nl.defaults.trainer]: \u001b[0mEpoch 67 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:06 nl.defaults.trainer]: \u001b[0mEpoch 68 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:06 nl.defaults.trainer]: \u001b[0mEpoch 69 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:06 nl.defaults.trainer]: \u001b[0mEpoch 70 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:07 nl.defaults.trainer]: \u001b[0mEpoch 71 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:07 nl.defaults.trainer]: \u001b[0mEpoch 72, Anytime results: {'cifar10-valid': {'train_losses': [1.7569053060531616, 1.2664795138931275, 1.0398911100578307, 0.9061412560462951, 0.8145561787033081, 0.7282953679084778, 0.6751605457687377, 0.6325034687423706, 0.594797575340271, 0.5714447735023499, 0.5462822461795807, 0.5183249447441101, 0.5060108277034759, 0.4860454574871063, 0.47330892276763914, 0.45837394062042236, 0.4454547724342346, 0.4367031452178955, 0.4227136728191376, 0.4114862308216095, 0.4085151299095154, 0.4044977221775055, 0.38876685503959657, 0.38440722067832944, 0.3794570953273773, 0.3773342935180664, 0.36700300178527834, 0.370111882314682, 0.35280171340942384, 0.3534411968040466, 0.34880874015808105, 0.3392093047142029, 0.33516052363395693, 0.33190925087928774, 0.3343107649898529, 0.3237089006614685, 0.3215712014198303, 0.3171178406906128, 0.30574725152015686, 0.31025762138366697, 0.30747290229797364, 0.29834707723617554, 0.29427569427490236, 0.29449756768226626, 0.29159496780872346, 0.29581981219291686, 0.2777541013431549, 0.28210052105903627, 0.2820353820800781, 0.2740921457147598, 0.2777707223701477, 0.27363268907546995, 0.27083577856063845, 0.2679726627254486, 0.25681533714294436, 0.2701511300086975, 0.2552899360322952, 0.25207480679512023, 0.2520826415157318, 0.25758047731399536, 0.23979794030189513, 0.24494134342193605, 0.2434393112182617, 0.23536221855163575, 0.22918426724910737, 0.23721468706130983, 0.22874721122741698, 0.22816264547348022, 0.2232528401231766, 0.22619380402088166, 0.2239677005815506, 0.21510418560028077, 0.2157858929157257, 0.2110674531555176, 0.2087889788532257, 0.21243365513324738, 0.20813079245567323, 0.20389643756866455, 0.19675868477344513, 0.19769202645778655, 0.19059690853595734, 0.19251479341506958, 0.18629339147090912, 0.19223606120109557, 0.18190774082660674, 0.19243542908668518, 0.1761055871105194, 0.17961711973190309, 0.17529628326892852, 0.17030297406196596, 0.16327535594940185, 0.1726509228181839, 0.163730563454628, 0.16315957696914674, 0.15815423311471938, 0.15503937411785126, 0.16293003674030304, 0.15117002528190612, 0.13990541839122772, 0.15702265500068666, 0.1439029846382141, 0.14200549327373505, 0.13383040287971495, 0.1406310504436493, 0.1364821756696701, 0.1288030527639389, 0.1294026828765869, 0.12637779561519621, 0.12131864381313325, 0.125661949262619, 0.12044794710159301, 0.11840331094264984, 0.11663053024053574, 0.11261456810951233, 0.11047457273960114, 0.1045703645825386, 0.1094984476852417, 0.10084918767690658, 0.10446519842624664, 0.09294993334293365, 0.09034513345956803, 0.08801165543079376, 0.08451360163211823, 0.07844458384990692, 0.08243906379699707, 0.08179043726205826, 0.07237742782592774, 0.07404884174466134, 0.07023863109588623, 0.06873067468523979, 0.07019079623937607, 0.06733777047038078, 0.06257209670066834, 0.0591178988468647, 0.053110786118507385, 0.057006341593265536, 0.054067337636947634, 0.048774153035879134, 0.04665558832645416, 0.05043800618171692, 0.042935804923176765, 0.03886122808098793, 0.03610275668859482, 0.03468259646952152, 0.029686471796035768, 0.03174582464873791, 0.029260967531204225, 0.023907402811050416, 0.026981608538627626, 0.0215273837184906, 0.022613820883035658, 0.02012240275144577, 0.016215642614364624, 0.017552341111302376, 0.016573177622407675, 0.014351837279200554, 0.015186065632998944, 0.013720216526985168, 0.012305273621082306, 0.009820013044774532, 0.009034747025966645, 0.008558783235102892, 0.008558888110518456, 0.007024007311463356, 0.006049726008176804, 0.006208703562021255, 0.0055816052811592815, 0.005483860322833062, 0.005120645933151245, 0.004940851823240519, 0.004379023199342191, 0.004500048578828573, 0.003829212036281824, 0.0034377170379459856, 0.003725832347124815, 0.0036780160421878098, 0.003731304369196296, 0.0033510872841253877, 0.00363513479270041, 0.00350781282491982, 0.0033855385491251945, 0.0032582418429851533, 0.0029350116714835168, 0.003581193818822503, 0.0029704603014886377, 0.0025494210241734983, 0.003201259375065565, 0.0027124761680141093, 0.0028953837013989685, 0.0030145811362564563, 0.0028955158534646032, 0.0027816221611201763, 0.0028242863665521147, 0.0024912390230596064, 0.0025807611463963985, 0.0028283434772491457, 0.0026745883461833002, 0.002818832339346409, 0.0026991494470089672, 0.002995031623542309], 'eval_losses': [1.5692320011138916, 1.692255509376526, 1.259640083770752, 1.0358222034072877, 1.1081641393280028, 0.898577421207428, 0.8860601475715637, 0.7382295448493957, 0.813926875, 0.888411948184967, 0.7486177971839905, 0.7528334671783448, 0.9931170081329346, 0.8498606488990784, 0.6512779799270629, 0.7387924125480652, 0.8116760023117066, 0.7299716124153137, 0.6730028191947937, 0.6996099607467652, 0.6411852591514587, 0.9248606335830688, 0.6231177605438233, 0.890373495979309, 0.5836540268135071, 0.6635516252326965, 0.9188884570503235, 0.6369978741645813, 0.8734158744049072, 0.7266159543991089, 0.6872789871215821, 0.813729638004303, 0.6383802032470703, 0.7549205728912354, 0.6218803883171081, 0.700077579498291, 0.6347955551338196, 0.6381415802383423, 0.7855197314834594, 0.6381312977790833, 0.6686823948478698, 0.7025910236167908, 0.6351864266395569, 0.6211878901100159, 0.61226732421875, 0.7281109514617919, 0.6917098893928528, 0.816404071598053, 0.6148451482582092, 0.7654599810791015, 0.6374987333869934, 0.6595930378913879, 0.5458997198104858, 0.7432138886642456, 0.5766457987594604, 0.6001726524925232, 0.7027325080490112, 0.7266061331176757, 0.6104864811897278, 0.5152941138839722, 0.5384895776557922, 0.4726872467136383, 0.5839475108337402, 0.6504479524230957, 0.6767966947555542, 0.8578970531463623, 0.5744328165435791, 0.5219236636161804, 0.7383748282051087, 0.48225053327560424, 0.634156963005066, 0.5497831882286072, 0.6862307289505005, 0.9092927713394166, 0.5589307807159424, 0.6638886155891418, 0.733991358089447, 0.555501425113678, 0.6120970909118653, 0.516873232345581, 0.8179938382148743, 0.5805805414962768, 0.6991592945671081, 0.6539873460960388, 0.5709471417427063, 0.6375534070968628, 0.5402056052017212, 0.6883054086875916, 0.5828042843151092, 0.6054750591659546, 0.566019707660675, 0.9152434265327454, 0.4966023212528229, 0.6784646076965332, 0.5414937542724609, 0.49248072995185854, 0.5574530310726166, 0.6342940159797669, 0.624105606880188, 0.754045444278717, 0.5569883807754517, 0.469898601732254, 0.5703178303909302, 0.5973637752342225, 0.5329736370658874, 0.5648937179946899, 0.5659561194038392, 0.5896530161857605, 0.5579477121353149, 0.6534712743759156, 0.5268841871261597, 0.6428838219451904, 0.6437939745140075, 0.48700583701133726, 0.5503930351448059, 0.6020848330116272, 0.4981022983932495, 0.46053907823562623, 0.4978150617599487, 0.6112286166381836, 0.4818751058101654, 0.4703215942335129, 0.5539687369918823, 0.5854696180915833, 0.5198580288219452, 0.5484057223129273, 0.6158625351619721, 0.5792768238639832, 0.5337661961746216, 0.5886052313423157, 0.54467154712677, 0.473427551279068, 0.4816957168865204, 0.5139731049251557, 0.550352405872345, 0.4698507158279419, 0.5226176941871643, 0.48719725017547605, 0.48560441466331483, 0.4822244606876373, 0.5956338468170166, 0.5404972162437439, 0.46963005029678345, 0.5527439107131958, 0.513271921749115, 0.4574300882911682, 0.4538339582061768, 0.47028755069732664, 0.42532012575149536, 0.4283977487182617, 0.4530713115692139, 0.4484299855709076, 0.46192191455841064, 0.4623718216705322, 0.47747744750022886, 0.4378578797149658, 0.44730199337005616, 0.4541953098487854, 0.4522034854507446, 0.4571830992126465, 0.4335714791870117, 0.427637976436615, 0.4394387770175934, 0.4353127297210693, 0.4287326905155182, 0.4174875314235687, 0.4283384783363342, 0.4249683612442017, 0.41909786179065706, 0.42239480409622193, 0.4236892115879059, 0.42108781467437745, 0.4160034220790863, 0.41670239393234254, 0.41843662134170534, 0.417412882938385, 0.4146304425907135, 0.420097362241745, 0.4165667124938965, 0.4135247115325928, 0.41516472861289977, 0.4136860141944885, 0.41217745824813845, 0.4159237167835236, 0.4151900646591187, 0.40994485832214356, 0.41669623952865603, 0.41205567766189577, 0.412605232963562, 0.41245238943099977, 0.41567705671310423, 0.41590032676696775, 0.41446701001167296, 0.4119553282356262, 0.412061138677597, 0.41358045135498045, 0.4162572134208679, 0.41225020356655123, 0.4152240486907959, 0.4137391041278839, 0.4160864718437195], 'train_acc1es': [32.86799998901367, 53.528000007324216, 62.39199997558594, 67.29599998291016, 70.92000001464844, 74.30399999511718, 76.35999998046876, 77.848, 79.05599998046875, 80.1439999975586, 81.26000001464844, 82.17599997314453, 82.22800001953125, 83.21200000488281, 83.74799997314453, 84.37599997314453, 84.82800001464844, 84.876, 85.21999999755859, 85.7, 85.77600000976562, 85.996, 86.67199998779297, 86.66000000244141, 86.87199999023437, 86.84000000488281, 87.42, 87.04400001708984, 87.7240000024414, 87.8480000048828, 87.74400000244141, 87.99199999511718, 88.35999999023437, 88.55199999511719, 88.55599998291015, 88.90799999755859, 88.88800000976562, 89.06000000488281, 89.30399998535157, 89.13599999511719, 89.29199999267578, 89.60800000488281, 89.7960000024414, 89.87599999511718, 89.94799998535156, 89.63200000976562, 90.468, 90.25999999511718, 90.17599998535157, 90.48399998046875, 90.256, 90.44799997070312, 90.67999998535156, 90.6239999975586, 90.95999999511719, 90.47199998779297, 91.05199999023438, 91.09199997802735, 91.31599998291016, 90.99999998535156, 91.65999999511719, 91.24399998046874, 91.51199998535157, 91.91599999267578, 92.03999997558594, 91.8519999975586, 92.0359999951172, 92.12000000488281, 92.23599998291016, 92.03199997558593, 92.15999997070313, 92.61599998779297, 92.39999999267579, 92.65599999023438, 92.66399997802735, 92.43599998779297, 92.73199998291015, 92.84399999267578, 92.98399998046875, 93.02399998291015, 93.29599997558594, 93.41199997802734, 93.61199997314453, 93.29599999023438, 93.79199998779296, 93.40799998046874, 94.04799997070313, 93.87199997314453, 93.85599998046875, 94.07199997314453, 94.29999997802734, 94.05999997558594, 94.37600001708985, 94.50799997314454, 94.46400000976563, 94.61200001464844, 94.27999997558594, 94.87199997070313, 95.18399997314454, 94.59999999023438, 95.19599997070313, 95.13599997314454, 95.35199997314453, 95.17599997558594, 95.31999997070312, 95.41199998291016, 95.57199998046875, 95.63600001464843, 95.59200001220704, 95.77999998046874, 95.89200001953125, 95.85599997314453, 95.98400001953125, 96.16800001464844, 96.29600001953125, 96.37200001220702, 96.30799997314453, 96.54400001464843, 96.46000001220703, 96.76799997070313, 97.09200001464843, 97.06399997558594, 97.15600001464844, 97.43200001464844, 97.29599997070312, 97.24400001464844, 97.59199997314452, 97.59600000732422, 97.64000000976563, 97.7280000024414, 97.64400001464844, 97.79200000732422, 97.98000001220703, 98.0720000024414, 98.28400001708984, 98.12800000244141, 98.21600000976562, 98.49200000976562, 98.50400001220703, 98.41600000976563, 98.56800000488282, 98.8600000048828, 98.85200000488281, 98.98800000244141, 99.08400000488281, 99.05600000244141, 99.12800000244141, 99.29600000488281, 99.18800000488281, 99.38800000732422, 99.39200000488282, 99.42000000488281, 99.60800000732422, 99.5080000024414, 99.536, 99.65200000488281, 99.592, 99.6560000024414, 99.732, 99.796, 99.7760000024414, 99.82, 99.816, 99.884, 99.9120000024414, 99.90800000244141, 99.892, 99.9000000024414, 99.928, 99.916, 99.948, 99.924, 99.972, 99.968, 99.964, 99.948, 99.964, 99.968, 99.952, 99.948, 99.96, 99.96, 99.984, 99.948, 99.984, 99.992, 99.964, 99.992, 99.964, 99.972, 99.976, 99.98, 99.984, 100.0, 99.988, 99.984, 99.984, 99.976, 99.976, 99.968], 'eval_acc1es': [41.03999999633789, 45.6880000012207, 57.227999998779296, 63.77199999023438, 62.38399999267578, 69.82399997558593, 70.60799998779297, 74.79199998046874, 72.80800001708984, 71.01599999267579, 75.71999997314452, 75.15999998046875, 66.86, 73.90399999511719, 78.76, 75.73600001708985, 75.01999998779297, 75.94400000976563, 77.948, 77.128, 78.49600001708984, 72.59999999023438, 80.14000001953124, 73.75600000976563, 81.30800001464844, 79.14799998779297, 73.75999998779297, 79.24399997802735, 74.55199998291016, 77.89599998779296, 78.79199999267578, 76.60399999023437, 80.02399997802735, 77.98399999511719, 80.54399998046875, 79.12399997070312, 80.11199997314453, 80.28399998779297, 77.16000000976562, 80.31199998535156, 79.8320000024414, 77.94800001464844, 80.63600001953125, 81.14799997802734, 80.65599997558594, 78.70799999511719, 78.72399998046875, 76.936, 81.69599998291015, 77.57199997558594, 81.30400001708985, 79.71199998779296, 83.00000000976563, 77.47599997070313, 82.50400001708984, 81.89600000732422, 79.752, 79.09599998046875, 81.71599998046875, 83.59599997070312, 83.55599997558593, 85.29599999267577, 82.30799997070312, 80.79200001953124, 81.04400001708984, 76.46000000976562, 82.97600000732422, 83.59599997802735, 78.57199999511718, 84.72800001220703, 80.96799999267579, 83.05199997070312, 80.77600001708984, 76.216, 82.832, 80.96800001953125, 80.05599998779297, 83.77200001220703, 81.68400001953125, 84.48800001953126, 77.98399998291016, 83.22799998535156, 80.58000000732422, 81.33599997802735, 83.29599999267577, 81.66000000244141, 83.95999998046875, 80.91999997070313, 82.90400001220704, 82.87600001220703, 83.94000000488282, 76.33599997802735, 85.28800000976563, 82.06400001708984, 84.24800001708985, 85.172, 84.23200000732422, 82.84000001708985, 82.76000001464844, 81.17599998535157, 84.16000000976562, 86.372, 84.9600000024414, 84.12800000732422, 85.32800001220703, 84.59600001708985, 84.35600000488282, 83.8560000024414, 85.38000000488282, 82.80400000732422, 85.43200001953124, 83.46800001708985, 82.72400001708985, 86.5519999975586, 85.53200000976562, 84.38800000976562, 86.41200000732422, 87.2719999975586, 86.27199997070312, 84.31200000488282, 87.14799998535156, 87.47599998779297, 86.25200000488282, 85.28400001220703, 86.26399999511719, 85.78000000976563, 84.824, 85.95600001220703, 86.45600000976563, 85.24800000732422, 86.38800000488281, 87.76399998046875, 87.66399999267578, 87.2159999975586, 86.19599999755859, 88.30799998291016, 87.296, 87.94799997802734, 88.15599998779297, 88.10799999267579, 86.59999999023438, 87.43599999023438, 88.64800001953125, 87.35200001464844, 87.81599999267578, 89.0279999975586, 89.04400000244141, 88.91199998291016, 89.42000000244141, 89.656, 89.24799999511718, 89.55599997802734, 89.372, 89.47599999511719, 89.17199998291015, 89.66400001220703, 89.89199999511719, 89.48799999267578, 89.65199999755859, 89.83199998779297, 90.0359999951172, 90.30799998779297, 89.94800000732423, 90.18799999755859, 90.49599998535156, 90.62399997070312, 90.38799998779297, 90.52000001220703, 90.73199998046876, 90.52799997558594, 90.53999998779297, 90.57599998779297, 90.80000001953125, 90.69999998291016, 90.7639999975586, 90.70399998046875, 90.82399999267578, 90.71599997070312, 90.76800000244141, 90.77599998291015, 90.85599998291016, 90.77599998291015, 90.75999998291016, 90.77999998535157, 90.83199998535156, 90.79599998046875, 90.80399999267578, 90.77599999023437, 90.73599999511718, 90.79199999023437, 90.78400001220703, 90.8, 90.76799998291015, 90.80399999023437, 90.81999998535156, 90.81999998535156, 90.78799999267578, 90.84400001708984, 90.78799999511719, 90.79199997070313, 90.8], 'cost_info': {'flops': 86.42625, 'params': 0.615386, 'latency': 0.019886672496795654, 'train_time': 11.101390759150187}}}\n","\u001b[32m[05/23 16:34:07 nl.defaults.trainer]: \u001b[0mEpoch 72 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:07 nl.defaults.trainer]: \u001b[0mEpoch 73 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:07 nl.defaults.trainer]: \u001b[0mEpoch 74 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:08 nl.defaults.trainer]: \u001b[0mEpoch 75 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:08 nl.defaults.trainer]: \u001b[0mEpoch 76 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:08 nl.defaults.trainer]: \u001b[0mEpoch 77 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:08 nl.defaults.trainer]: \u001b[0mEpoch 78 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:08 nl.defaults.trainer]: \u001b[0mEpoch 79 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:09 nl.defaults.trainer]: \u001b[0mEpoch 80 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:09 nl.defaults.trainer]: \u001b[0mEpoch 81 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:09 nl.defaults.trainer]: \u001b[0mEpoch 82 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:09 nl.defaults.trainer]: \u001b[0mEpoch 83 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:10 nl.defaults.trainer]: \u001b[0mEpoch 84 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:10 nl.defaults.trainer]: \u001b[0mEpoch 85 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:11 nl.defaults.trainer]: \u001b[0mEpoch 86 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:11 nl.defaults.trainer]: \u001b[0mEpoch 87 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:11 nl.defaults.trainer]: \u001b[0mEpoch 88 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:12 nl.defaults.trainer]: \u001b[0mEpoch 89 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:12 nl.defaults.trainer]: \u001b[0mEpoch 90, Anytime results: {'cifar10-valid': {'train_losses': [1.7569053060531616, 1.2664795138931275, 1.0398911100578307, 0.9061412560462951, 0.8145561787033081, 0.7282953679084778, 0.6751605457687377, 0.6325034687423706, 0.594797575340271, 0.5714447735023499, 0.5462822461795807, 0.5183249447441101, 0.5060108277034759, 0.4860454574871063, 0.47330892276763914, 0.45837394062042236, 0.4454547724342346, 0.4367031452178955, 0.4227136728191376, 0.4114862308216095, 0.4085151299095154, 0.4044977221775055, 0.38876685503959657, 0.38440722067832944, 0.3794570953273773, 0.3773342935180664, 0.36700300178527834, 0.370111882314682, 0.35280171340942384, 0.3534411968040466, 0.34880874015808105, 0.3392093047142029, 0.33516052363395693, 0.33190925087928774, 0.3343107649898529, 0.3237089006614685, 0.3215712014198303, 0.3171178406906128, 0.30574725152015686, 0.31025762138366697, 0.30747290229797364, 0.29834707723617554, 0.29427569427490236, 0.29449756768226626, 0.29159496780872346, 0.29581981219291686, 0.2777541013431549, 0.28210052105903627, 0.2820353820800781, 0.2740921457147598, 0.2777707223701477, 0.27363268907546995, 0.27083577856063845, 0.2679726627254486, 0.25681533714294436, 0.2701511300086975, 0.2552899360322952, 0.25207480679512023, 0.2520826415157318, 0.25758047731399536, 0.23979794030189513, 0.24494134342193605, 0.2434393112182617, 0.23536221855163575, 0.22918426724910737, 0.23721468706130983, 0.22874721122741698, 0.22816264547348022, 0.2232528401231766, 0.22619380402088166, 0.2239677005815506, 0.21510418560028077, 0.2157858929157257, 0.2110674531555176, 0.2087889788532257, 0.21243365513324738, 0.20813079245567323, 0.20389643756866455, 0.19675868477344513, 0.19769202645778655, 0.19059690853595734, 0.19251479341506958, 0.18629339147090912, 0.19223606120109557, 0.18190774082660674, 0.19243542908668518, 0.1761055871105194, 0.17961711973190309, 0.17529628326892852, 0.17030297406196596, 0.16327535594940185, 0.1726509228181839, 0.163730563454628, 0.16315957696914674, 0.15815423311471938, 0.15503937411785126, 0.16293003674030304, 0.15117002528190612, 0.13990541839122772, 0.15702265500068666, 0.1439029846382141, 0.14200549327373505, 0.13383040287971495, 0.1406310504436493, 0.1364821756696701, 0.1288030527639389, 0.1294026828765869, 0.12637779561519621, 0.12131864381313325, 0.125661949262619, 0.12044794710159301, 0.11840331094264984, 0.11663053024053574, 0.11261456810951233, 0.11047457273960114, 0.1045703645825386, 0.1094984476852417, 0.10084918767690658, 0.10446519842624664, 0.09294993334293365, 0.09034513345956803, 0.08801165543079376, 0.08451360163211823, 0.07844458384990692, 0.08243906379699707, 0.08179043726205826, 0.07237742782592774, 0.07404884174466134, 0.07023863109588623, 0.06873067468523979, 0.07019079623937607, 0.06733777047038078, 0.06257209670066834, 0.0591178988468647, 0.053110786118507385, 0.057006341593265536, 0.054067337636947634, 0.048774153035879134, 0.04665558832645416, 0.05043800618171692, 0.042935804923176765, 0.03886122808098793, 0.03610275668859482, 0.03468259646952152, 0.029686471796035768, 0.03174582464873791, 0.029260967531204225, 0.023907402811050416, 0.026981608538627626, 0.0215273837184906, 0.022613820883035658, 0.02012240275144577, 0.016215642614364624, 0.017552341111302376, 0.016573177622407675, 0.014351837279200554, 0.015186065632998944, 0.013720216526985168, 0.012305273621082306, 0.009820013044774532, 0.009034747025966645, 0.008558783235102892, 0.008558888110518456, 0.007024007311463356, 0.006049726008176804, 0.006208703562021255, 0.0055816052811592815, 0.005483860322833062, 0.005120645933151245, 0.004940851823240519, 0.004379023199342191, 0.004500048578828573, 0.003829212036281824, 0.0034377170379459856, 0.003725832347124815, 0.0036780160421878098, 0.003731304369196296, 0.0033510872841253877, 0.00363513479270041, 0.00350781282491982, 0.0033855385491251945, 0.0032582418429851533, 0.0029350116714835168, 0.003581193818822503, 0.0029704603014886377, 0.0025494210241734983, 0.003201259375065565, 0.0027124761680141093, 0.0028953837013989685, 0.0030145811362564563, 0.0028955158534646032, 0.0027816221611201763, 0.0028242863665521147, 0.0024912390230596064, 0.0025807611463963985, 0.0028283434772491457, 0.0026745883461833002, 0.002818832339346409, 0.0026991494470089672, 0.002995031623542309], 'eval_losses': [1.5692320011138916, 1.692255509376526, 1.259640083770752, 1.0358222034072877, 1.1081641393280028, 0.898577421207428, 0.8860601475715637, 0.7382295448493957, 0.813926875, 0.888411948184967, 0.7486177971839905, 0.7528334671783448, 0.9931170081329346, 0.8498606488990784, 0.6512779799270629, 0.7387924125480652, 0.8116760023117066, 0.7299716124153137, 0.6730028191947937, 0.6996099607467652, 0.6411852591514587, 0.9248606335830688, 0.6231177605438233, 0.890373495979309, 0.5836540268135071, 0.6635516252326965, 0.9188884570503235, 0.6369978741645813, 0.8734158744049072, 0.7266159543991089, 0.6872789871215821, 0.813729638004303, 0.6383802032470703, 0.7549205728912354, 0.6218803883171081, 0.700077579498291, 0.6347955551338196, 0.6381415802383423, 0.7855197314834594, 0.6381312977790833, 0.6686823948478698, 0.7025910236167908, 0.6351864266395569, 0.6211878901100159, 0.61226732421875, 0.7281109514617919, 0.6917098893928528, 0.816404071598053, 0.6148451482582092, 0.7654599810791015, 0.6374987333869934, 0.6595930378913879, 0.5458997198104858, 0.7432138886642456, 0.5766457987594604, 0.6001726524925232, 0.7027325080490112, 0.7266061331176757, 0.6104864811897278, 0.5152941138839722, 0.5384895776557922, 0.4726872467136383, 0.5839475108337402, 0.6504479524230957, 0.6767966947555542, 0.8578970531463623, 0.5744328165435791, 0.5219236636161804, 0.7383748282051087, 0.48225053327560424, 0.634156963005066, 0.5497831882286072, 0.6862307289505005, 0.9092927713394166, 0.5589307807159424, 0.6638886155891418, 0.733991358089447, 0.555501425113678, 0.6120970909118653, 0.516873232345581, 0.8179938382148743, 0.5805805414962768, 0.6991592945671081, 0.6539873460960388, 0.5709471417427063, 0.6375534070968628, 0.5402056052017212, 0.6883054086875916, 0.5828042843151092, 0.6054750591659546, 0.566019707660675, 0.9152434265327454, 0.4966023212528229, 0.6784646076965332, 0.5414937542724609, 0.49248072995185854, 0.5574530310726166, 0.6342940159797669, 0.624105606880188, 0.754045444278717, 0.5569883807754517, 0.469898601732254, 0.5703178303909302, 0.5973637752342225, 0.5329736370658874, 0.5648937179946899, 0.5659561194038392, 0.5896530161857605, 0.5579477121353149, 0.6534712743759156, 0.5268841871261597, 0.6428838219451904, 0.6437939745140075, 0.48700583701133726, 0.5503930351448059, 0.6020848330116272, 0.4981022983932495, 0.46053907823562623, 0.4978150617599487, 0.6112286166381836, 0.4818751058101654, 0.4703215942335129, 0.5539687369918823, 0.5854696180915833, 0.5198580288219452, 0.5484057223129273, 0.6158625351619721, 0.5792768238639832, 0.5337661961746216, 0.5886052313423157, 0.54467154712677, 0.473427551279068, 0.4816957168865204, 0.5139731049251557, 0.550352405872345, 0.4698507158279419, 0.5226176941871643, 0.48719725017547605, 0.48560441466331483, 0.4822244606876373, 0.5956338468170166, 0.5404972162437439, 0.46963005029678345, 0.5527439107131958, 0.513271921749115, 0.4574300882911682, 0.4538339582061768, 0.47028755069732664, 0.42532012575149536, 0.4283977487182617, 0.4530713115692139, 0.4484299855709076, 0.46192191455841064, 0.4623718216705322, 0.47747744750022886, 0.4378578797149658, 0.44730199337005616, 0.4541953098487854, 0.4522034854507446, 0.4571830992126465, 0.4335714791870117, 0.427637976436615, 0.4394387770175934, 0.4353127297210693, 0.4287326905155182, 0.4174875314235687, 0.4283384783363342, 0.4249683612442017, 0.41909786179065706, 0.42239480409622193, 0.4236892115879059, 0.42108781467437745, 0.4160034220790863, 0.41670239393234254, 0.41843662134170534, 0.417412882938385, 0.4146304425907135, 0.420097362241745, 0.4165667124938965, 0.4135247115325928, 0.41516472861289977, 0.4136860141944885, 0.41217745824813845, 0.4159237167835236, 0.4151900646591187, 0.40994485832214356, 0.41669623952865603, 0.41205567766189577, 0.412605232963562, 0.41245238943099977, 0.41567705671310423, 0.41590032676696775, 0.41446701001167296, 0.4119553282356262, 0.412061138677597, 0.41358045135498045, 0.4162572134208679, 0.41225020356655123, 0.4152240486907959, 0.4137391041278839, 0.4160864718437195], 'train_acc1es': [32.86799998901367, 53.528000007324216, 62.39199997558594, 67.29599998291016, 70.92000001464844, 74.30399999511718, 76.35999998046876, 77.848, 79.05599998046875, 80.1439999975586, 81.26000001464844, 82.17599997314453, 82.22800001953125, 83.21200000488281, 83.74799997314453, 84.37599997314453, 84.82800001464844, 84.876, 85.21999999755859, 85.7, 85.77600000976562, 85.996, 86.67199998779297, 86.66000000244141, 86.87199999023437, 86.84000000488281, 87.42, 87.04400001708984, 87.7240000024414, 87.8480000048828, 87.74400000244141, 87.99199999511718, 88.35999999023437, 88.55199999511719, 88.55599998291015, 88.90799999755859, 88.88800000976562, 89.06000000488281, 89.30399998535157, 89.13599999511719, 89.29199999267578, 89.60800000488281, 89.7960000024414, 89.87599999511718, 89.94799998535156, 89.63200000976562, 90.468, 90.25999999511718, 90.17599998535157, 90.48399998046875, 90.256, 90.44799997070312, 90.67999998535156, 90.6239999975586, 90.95999999511719, 90.47199998779297, 91.05199999023438, 91.09199997802735, 91.31599998291016, 90.99999998535156, 91.65999999511719, 91.24399998046874, 91.51199998535157, 91.91599999267578, 92.03999997558594, 91.8519999975586, 92.0359999951172, 92.12000000488281, 92.23599998291016, 92.03199997558593, 92.15999997070313, 92.61599998779297, 92.39999999267579, 92.65599999023438, 92.66399997802735, 92.43599998779297, 92.73199998291015, 92.84399999267578, 92.98399998046875, 93.02399998291015, 93.29599997558594, 93.41199997802734, 93.61199997314453, 93.29599999023438, 93.79199998779296, 93.40799998046874, 94.04799997070313, 93.87199997314453, 93.85599998046875, 94.07199997314453, 94.29999997802734, 94.05999997558594, 94.37600001708985, 94.50799997314454, 94.46400000976563, 94.61200001464844, 94.27999997558594, 94.87199997070313, 95.18399997314454, 94.59999999023438, 95.19599997070313, 95.13599997314454, 95.35199997314453, 95.17599997558594, 95.31999997070312, 95.41199998291016, 95.57199998046875, 95.63600001464843, 95.59200001220704, 95.77999998046874, 95.89200001953125, 95.85599997314453, 95.98400001953125, 96.16800001464844, 96.29600001953125, 96.37200001220702, 96.30799997314453, 96.54400001464843, 96.46000001220703, 96.76799997070313, 97.09200001464843, 97.06399997558594, 97.15600001464844, 97.43200001464844, 97.29599997070312, 97.24400001464844, 97.59199997314452, 97.59600000732422, 97.64000000976563, 97.7280000024414, 97.64400001464844, 97.79200000732422, 97.98000001220703, 98.0720000024414, 98.28400001708984, 98.12800000244141, 98.21600000976562, 98.49200000976562, 98.50400001220703, 98.41600000976563, 98.56800000488282, 98.8600000048828, 98.85200000488281, 98.98800000244141, 99.08400000488281, 99.05600000244141, 99.12800000244141, 99.29600000488281, 99.18800000488281, 99.38800000732422, 99.39200000488282, 99.42000000488281, 99.60800000732422, 99.5080000024414, 99.536, 99.65200000488281, 99.592, 99.6560000024414, 99.732, 99.796, 99.7760000024414, 99.82, 99.816, 99.884, 99.9120000024414, 99.90800000244141, 99.892, 99.9000000024414, 99.928, 99.916, 99.948, 99.924, 99.972, 99.968, 99.964, 99.948, 99.964, 99.968, 99.952, 99.948, 99.96, 99.96, 99.984, 99.948, 99.984, 99.992, 99.964, 99.992, 99.964, 99.972, 99.976, 99.98, 99.984, 100.0, 99.988, 99.984, 99.984, 99.976, 99.976, 99.968], 'eval_acc1es': [41.03999999633789, 45.6880000012207, 57.227999998779296, 63.77199999023438, 62.38399999267578, 69.82399997558593, 70.60799998779297, 74.79199998046874, 72.80800001708984, 71.01599999267579, 75.71999997314452, 75.15999998046875, 66.86, 73.90399999511719, 78.76, 75.73600001708985, 75.01999998779297, 75.94400000976563, 77.948, 77.128, 78.49600001708984, 72.59999999023438, 80.14000001953124, 73.75600000976563, 81.30800001464844, 79.14799998779297, 73.75999998779297, 79.24399997802735, 74.55199998291016, 77.89599998779296, 78.79199999267578, 76.60399999023437, 80.02399997802735, 77.98399999511719, 80.54399998046875, 79.12399997070312, 80.11199997314453, 80.28399998779297, 77.16000000976562, 80.31199998535156, 79.8320000024414, 77.94800001464844, 80.63600001953125, 81.14799997802734, 80.65599997558594, 78.70799999511719, 78.72399998046875, 76.936, 81.69599998291015, 77.57199997558594, 81.30400001708985, 79.71199998779296, 83.00000000976563, 77.47599997070313, 82.50400001708984, 81.89600000732422, 79.752, 79.09599998046875, 81.71599998046875, 83.59599997070312, 83.55599997558593, 85.29599999267577, 82.30799997070312, 80.79200001953124, 81.04400001708984, 76.46000000976562, 82.97600000732422, 83.59599997802735, 78.57199999511718, 84.72800001220703, 80.96799999267579, 83.05199997070312, 80.77600001708984, 76.216, 82.832, 80.96800001953125, 80.05599998779297, 83.77200001220703, 81.68400001953125, 84.48800001953126, 77.98399998291016, 83.22799998535156, 80.58000000732422, 81.33599997802735, 83.29599999267577, 81.66000000244141, 83.95999998046875, 80.91999997070313, 82.90400001220704, 82.87600001220703, 83.94000000488282, 76.33599997802735, 85.28800000976563, 82.06400001708984, 84.24800001708985, 85.172, 84.23200000732422, 82.84000001708985, 82.76000001464844, 81.17599998535157, 84.16000000976562, 86.372, 84.9600000024414, 84.12800000732422, 85.32800001220703, 84.59600001708985, 84.35600000488282, 83.8560000024414, 85.38000000488282, 82.80400000732422, 85.43200001953124, 83.46800001708985, 82.72400001708985, 86.5519999975586, 85.53200000976562, 84.38800000976562, 86.41200000732422, 87.2719999975586, 86.27199997070312, 84.31200000488282, 87.14799998535156, 87.47599998779297, 86.25200000488282, 85.28400001220703, 86.26399999511719, 85.78000000976563, 84.824, 85.95600001220703, 86.45600000976563, 85.24800000732422, 86.38800000488281, 87.76399998046875, 87.66399999267578, 87.2159999975586, 86.19599999755859, 88.30799998291016, 87.296, 87.94799997802734, 88.15599998779297, 88.10799999267579, 86.59999999023438, 87.43599999023438, 88.64800001953125, 87.35200001464844, 87.81599999267578, 89.0279999975586, 89.04400000244141, 88.91199998291016, 89.42000000244141, 89.656, 89.24799999511718, 89.55599997802734, 89.372, 89.47599999511719, 89.17199998291015, 89.66400001220703, 89.89199999511719, 89.48799999267578, 89.65199999755859, 89.83199998779297, 90.0359999951172, 90.30799998779297, 89.94800000732423, 90.18799999755859, 90.49599998535156, 90.62399997070312, 90.38799998779297, 90.52000001220703, 90.73199998046876, 90.52799997558594, 90.53999998779297, 90.57599998779297, 90.80000001953125, 90.69999998291016, 90.7639999975586, 90.70399998046875, 90.82399999267578, 90.71599997070312, 90.76800000244141, 90.77599998291015, 90.85599998291016, 90.77599998291015, 90.75999998291016, 90.77999998535157, 90.83199998535156, 90.79599998046875, 90.80399999267578, 90.77599999023437, 90.73599999511718, 90.79199999023437, 90.78400001220703, 90.8, 90.76799998291015, 90.80399999023437, 90.81999998535156, 90.81999998535156, 90.78799999267578, 90.84400001708984, 90.78799999511719, 90.79199997070313, 90.8], 'cost_info': {'flops': 86.42625, 'params': 0.615386, 'latency': 0.019886672496795654, 'train_time': 11.101390759150187}}}\n","\u001b[32m[05/23 16:34:12 nl.defaults.trainer]: \u001b[0mEpoch 90 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:12 nl.defaults.trainer]: \u001b[0mEpoch 91 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:12 nl.defaults.trainer]: \u001b[0mEpoch 92 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:13 nl.defaults.trainer]: \u001b[0mEpoch 93 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:13 nl.defaults.trainer]: \u001b[0mEpoch 94 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:13 nl.defaults.trainer]: \u001b[0mEpoch 95 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:13 nl.defaults.trainer]: \u001b[0mEpoch 96 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:14 nl.defaults.trainer]: \u001b[0mEpoch 97 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:14 nl.defaults.trainer]: \u001b[0mEpoch 98 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:15 nl.defaults.trainer]: \u001b[0mEpoch 99 done. Train accuracy (top1, top5): 99.96800, 0.00000, Validation accuracy: 90.80000, 0.00000\n","\u001b[32m[05/23 16:34:15 nl.defaults.trainer]: \u001b[0mTraining finished\n"]}],"source":["# call only a method to run the search for the number of iterations specified in the yaml configuration file.\n","trainer.search()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCuc5fqZtIGx","executionInfo":{"status":"ok","timestamp":1653323662304,"user_tz":-120,"elapsed":199,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"de147d54-fa60-413a-9b07-b276949c9f29"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[05/23 16:34:22 nl.defaults.trainer]: \u001b[0mStart evaluation\n","\u001b[32m[05/23 16:34:22 nl.defaults.trainer]: \u001b[0mloading model from file run/cifar10/nas_predictors/nasbench201/var_sparse_gp/0/search/model_final.pth\n","\u001b[32m[05/23 16:34:22 nl.defaults.trainer]: \u001b[0mFinal architecture:\n","Graph makrograph-0.2902704, scope None, 20 nodes\n","\u001b[32m[05/23 16:34:22 nl.defaults.trainer]: \u001b[0mQueried results (Metric.TEST_ACCURACY): 90.8\n"]}],"source":["# After the search is done, we want to evaluate the test performance of\n","# the best architecture found using the validation set.\n","trainer.evaluate(dataset_api=dataset_api)"]},{"cell_type":"markdown","metadata":{"id":"nWvAy24EtIGx"},"source":["## NAS predictors"]},{"cell_type":"markdown","metadata":{"id":"m3_Qwg8ctIGx"},"source":["The performance predictors in NASLib are categorized in 4 classes:\n","- *Model-based predictors*\n","    - These are usually regression models (e.g. Gaussian Processes or XGBoost) that are trained with a data (x, y), where x is the architecture encoding and y is the validation performance of the trained architectures. At test time, they predict the performance of new architectures from the space.\n","- *Learning curve predictors*\n","    - These predictors estimate the architecture ranking (e.g. at epoch 100) by using the performance at a lower epoch or some other statistics. An example is early stopping. By early stopping the training at epoch 30, we hope that the ranking of the architectures will be the same as the ranking at epoch 100.\n","- *Zero-cost predictors*\n","    - These predictors usually run only a single mini-batch iteration through a sampled architecture and use some statistics (e.g. norm of gradients) in order to determine how good that architecture is.\n","- *One-shot predictors*\n","    - This class of predictors utilizes the shared weights of the one-shot model in order to rank the architectures based on the validation performance using these shared weights.\n","    \n","In NASLib we have implemented **31 predictors** that can be easily imported and evaluated on the tabular benchmarks. Check also this file for some more details: https://github.com/automl/NASLib/blob/master/docs/predictors.md and our paper: https://arxiv.org/abs/2104.01177"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5oNVZkditIGy","outputId":"fbe60dbf-2e83-44a5-acff-5a5693a36f26","executionInfo":{"status":"ok","timestamp":1653323725210,"user_tz":-120,"elapsed":45068,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['--config-file', './naslib/benchmarks/predictors/predictor_config.yaml']\n","\u001b[32m[05/23 16:34:40 nl.utils.utils]: \u001b[0mCommand line args: ['--config-file', './naslib/benchmarks/predictors/predictor_config.yaml']\n","\u001b[32m[05/23 16:34:40 nl.utils.utils]: \u001b[0mExperiment dir : run/cifar10/predictors/xgb/1000\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mExperiment dir : run/cifar10/predictors/xgb/1000/search\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mExperiment dir : run/cifar10/predictors/xgb/1000/eval\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mexperiment_type.............................single\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0msearch_space...........................nasbench201\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mdataset....................................cifar10\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mpredictor......................................xgb\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0muniform_random...................................1\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mtest_size......................................100\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mtrain_size_single...............................50\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mtrain_size_list...[5, 8, 14, 24, 42, 71, 121, 205]\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mfidelity_single..................................5\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mfidelity_list[1, 2, 3, 5, 7, 9, 13, 19, 26, 37, 52, 73]\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mout_dir........................................run\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mmax_hpo_time.....................................0\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mseed..........................................1000\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0msearchbatch_size: 256\n","cutout: False\n","cutout_length: 16\n","cutout_prob: 1.0\n","data_size: 25000\n","seed: 1000\n","train_portion: 0.7\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0msave...............run/cifar10/predictors/xgb/1000\n","\u001b[32m[05/23 16:34:41 nl.utils.utils]: \u001b[0mdata/content/drive/MyDrive/NasLib/NASLib/naslib/data\n","\u001b[32m[05/23 16:34:41 nl.defaults.predictor_evaluator]: \u001b[0mLoad the test set\n","\u001b[32m[05/23 16:35:08 nl.defaults.predictor_evaluator]: \u001b[0mLoad the training set\n","\u001b[32m[05/23 16:35:23 nl.defaults.predictor_evaluator]: \u001b[0mFit the predictor\n","\u001b[32m[05/23 16:35:23 nl.defaults.predictor_evaluator]: \u001b[0mCompute evaluation metrics\n","\u001b[32m[05/23 16:35:23 nl.defaults.predictor_evaluator]: \u001b[0mtrain_size: 50, fidelity: 5, kendall tau 0.3555\n","\u001b[32m[05/23 16:35:23 nl.defaults.predictor_evaluator]: \u001b[0mmae: 4.3203, rmse: 8.3852, pearson: 0.3591, spearman: 0.4884, kendalltau: 0.3555, kt_2dec: 0.3557, kt_1dec: 0.3563, precision_10: 0.5, precision_20: 0.45, train_size: 50, fidelity: 5, train_time: 462.4131, fit_time: 0.0665, query_time: 0.0, hp_max_depth: 6, hp_min_child_weight: 1, hp_colsample_bytree: 1, hp_learning_rate: 0.3, hp_colsample_bylevel: 1, cv_score: 0, \n"]},{"output_type":"execute_result","data":{"text/plain":["[CfgNode({'experiment_type': 'single', 'search_space': 'nasbench201', 'dataset': 'cifar10', 'predictor': 'xgb', 'uniform_random': 1, 'test_size': 100, 'train_size_single': 50, 'train_size_list': [5, 8, 14, 24, 42, 71, 121, 205], 'fidelity_single': 5, 'fidelity_list': [1, 2, 3, 5, 7, 9, 13, 19, 26, 37, 52, 73], 'out_dir': 'run', 'max_hpo_time': 0, 'seed': 1000, 'search': CfgNode({'seed': 1000, 'batch_size': 256, 'data_size': 25000, 'cutout': False, 'cutout_length': 16, 'cutout_prob': 1.0, 'train_portion': 0.7}), 'save': 'run/cifar10/predictors/xgb/1000', 'data': '/content/drive/MyDrive/NasLib/NASLib/naslib/data'}),\n"," {'cv_score': 0,\n","  'fidelity': 5,\n","  'fit_time': 0.06654930114746094,\n","  'hp_booster': 'gbtree',\n","  'hp_colsample_bylevel': 1,\n","  'hp_colsample_bytree': 1,\n","  'hp_eval_metric': 'rmse',\n","  'hp_learning_rate': 0.3,\n","  'hp_max_depth': 6,\n","  'hp_min_child_weight': 1,\n","  'hp_objective': 'reg:squarederror',\n","  'kendalltau': 0.3555331429138299,\n","  'kt_1dec': 0.3563206034824803,\n","  'kt_2dec': 0.35567687978766804,\n","  'mae': 4.3203251312255855,\n","  'pearson': 0.3591195879068839,\n","  'precision_10': 0.5,\n","  'precision_20': 0.45,\n","  'query_time': 1.3442039489746094e-05,\n","  'rmse': 8.38522659259413,\n","  'spearman': 0.48840216630407646,\n","  'train_size': 50,\n","  'train_time': 462.41313511133194}]"]},"metadata":{},"execution_count":9}],"source":[" # Load the predictor evaluator and the predictor (XGBoost in this case)\n","from naslib.defaults.predictor_evaluator import PredictorEvaluator\n","from naslib.predictors import XGBoost\n","\n","# read the new configuration file that has the parameters of the predictor model\n","# NOTE: it is important to set config_type=\"predictor\" here\n","config = utils.get_config_from_args(args=[\"--config-file\", \"./naslib/benchmarks/predictors/predictor_config.yaml\"], \n","                                    config_type=\"predictor\")\n","utils.set_seed(config.seed)\n","utils.log_args(config)\n","\n","logger = setup_logger(config.save + \"/log.log\")\n","logger.setLevel(logging.INFO)\n","\n","# Now instantiate the predictor (every predictor works with certain encoding types for the architecture)\n","predictor = XGBoost(encoding_type='adjacency_one_hot', hpo_wrapper=False)\n","# Instantiate the evaluator\n","predictor_evaluator = PredictorEvaluator(predictor, config=config)\n","# similarly to the conventional NAS search that we saw before, the predictor evaluator also adapts to \n","# the search space at hand\n","predictor_evaluator.adapt_search_space(search_space, load_labeled=False, \n","                                       dataset_api=dataset_api)\n","# No search in this case. We only train the predictor on the training data and evaluate it on the test data.\n","# Note that the training data here is the pair (arch, performance) and not (image, label).\n","predictor_evaluator.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"wGkvgJJctIGy"},"source":["The stdout shows some metrics such as the rank correlation (Spearman or Kendall Tau) of 100 sampled architectures from the test set. This shows how good the ranking of the architectures based on the performance predictor is compared to the true ranking from NAS-Bench-201."]},{"cell_type":"markdown","metadata":{"id":"aCf2Tn91tIGy"},"source":["## Using the predictors as surrogate models in Bayesian Optimization"]},{"cell_type":"markdown","metadata":{"id":"wpbY6sh4tIGy"},"source":["In order to use the aforementioned predictors as surrogate models inside Bayesian Optimization, we need to have a mean prediction and uncertainty estimates for every architecture. Some of the models (e.g. GPs) already provide this, but for some others such as MLPs we construct an ensemble of MLPs in order to obtain the uncertainty estimates.\n","\n","This code snippet shows how to run [BANANAS](https://arxiv.org/abs/1910.11858) with some of the performance predictors as surrogate models. We will do 3 trials with 3 different seeds of BANANAS for 300 iterations. For this we need to firstly generate the configuration files. The bash commands below do this. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BspLX5L8tIGy"},"outputs":[],"source":["%%bash\n","optimizer=re\n","predictors=(mlp lgb xgb rf bayes_lin_reg gp none)\n","\n","start_seed=0\n","\n","# folders:\n","# this supposes your location is at NASLib/docs. Change the base_file location based on where you\n","# opened the notebook\n","base_file=./naslib\n","save_dir=./docs/re_run\n","out_dir=$save_dir\\_$start_seed\n","\n","# search space / data:\n","search_space=nasbench201\n","dataset=cifar10\n","search_epochs=200\n","\n","# trials / seeds:\n","trials=3\n","end_seed=$(($start_seed + $trials - 1))\n","\n","# create config files\n","for i in $(seq 0 $((${#predictors[@]}-1)) )\n","do\n","    predictor=${predictors[$i]}\n","    python $base_file/benchmarks/create_configs.py --predictor $predictor \\\n","    --epochs $search_epochs --start_seed $start_seed --trials $trials \\\n","    --out_dir $out_dir --dataset=$dataset --config_type nas_predictor \\\n","    --search_space $search_space --optimizer $optimizer\n","done"]},{"cell_type":"markdown","metadata":{"id":"t6SoO4c_tIGy"},"source":["Similarly to how we ran RE before, write a function that gets a configuration file and optimizer as input and runs them."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3RexZPV2tIGy","executionInfo":{"status":"ok","timestamp":1653323736740,"user_tz":-120,"elapsed":210,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}}},"outputs":[],"source":["from naslib.optimizers import Bananas\n","\n","def run_optimizer(config_file=\"/content/drive/MyDrive/NasLib/NASLib/docs/bananas_run_0/cifar10/configs/nas_predictors/config_bananas_gp_0.yaml\",\n","                  nas_optimizer=Bananas) -> None:\n","    # TODO: add all the utilities, such as config file reading, logging as before.\n","    # afterwards instantiate the search space, optimizer, trainer and run the search + evaluation\n","\n","    # read the new configuration file that has the parameters of the predictor model\n","    config = utils.get_config_from_args(args=[\"--config-file\", config_file], \n","                                        config_type=\"nas_predictor\")\n","    \n","    # config = utils.get_config_from_args(config_type=\"nas_predictor\")\n","    utils.set_seed(config.seed)\n","    utils.log_args(config)\n","\n","    logger = setup_logger(config.save + \"/log.log\")\n","    logger.setLevel(logging.INFO)\n","\n","    optimizer = nas_optimizer(config)\n","    search_space = NB201()\n","    # this will load the NAS-Bench-201 data (architectures and their accuracy, runtime, etc).\n","    dataset_api = get_dataset_api(config.search_space, config.dataset)\n","    # adapt the search space to the optimizer type\n","    optimizer.adapt_search_space(search_space, dataset_api=dataset_api)\n","\n","    trainer = Trainer(optimizer, config, lightweight_output=True)\n","    trainer.search()\n","    trainer.evaluate(dataset_api=dataset_api)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMUfWOn7tIGy","executionInfo":{"status":"ok","timestamp":1653324489884,"user_tz":-120,"elapsed":745108,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"537e089b-55b5-4530-ee86-18e614db76a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["['--config-file', '/content/drive/MyDrive/NasLib/NASLib/docs/bananas_run_0/cifar10/configs/nas_predictors/config_bananas_gp_0.yaml']\n","\u001b[32m[05/23 16:35:44 nl.utils.utils]: \u001b[0mCommand line args: ['--config-file', '/content/drive/MyDrive/NasLib/NASLib/docs/bananas_run_0/cifar10/configs/nas_predictors/config_bananas_gp_0.yaml']\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0mExperiment dir : ./docs/bananas_run_0/cifar10/nas_predictors/nasbench201/gp/0\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0mExperiment dir : ./docs/bananas_run_0/cifar10/nas_predictors/nasbench201/gp/0/search\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0mExperiment dir : ./docs/bananas_run_0/cifar10/nas_predictors/nasbench201/gp/0/eval\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0mdataset....................................cifar10\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0moptimizer..................................bananas\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0mout_dir......................../docs/bananas_run_0\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0msearchacq_fn_optimization: random_sampling\n","acq_fn_type: its\n","batch_size: 256\n","checkpoint_freq: 5000\n","cutout: False\n","cutout_length: 16\n","cutout_prob: 1.0\n","data_size: 25000\n","encoding_type: adjacency_one_hot\n","epochs: 300\n","fidelity: 200\n","k: 20\n","max_mutations: 1\n","num_arches_to_mutate: 5\n","num_candidates: 200\n","num_ensemble: 3\n","num_init: 20\n","population_size: 30\n","predictor_type: gp\n","sample_size: 10\n","seed: 0\n","train_portion: 0.7\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0msearch_space...........................nasbench201\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0mseed.............................................0\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0msave./docs/bananas_run_0/cifar10/nas_predictors/nasbench201/gp/0\n","\u001b[32m[05/23 16:35:46 nl.utils.utils]: \u001b[0mdata/content/drive/MyDrive/NasLib/NASLib/naslib/data\n","\u001b[32m[05/23 16:35:47 nl.defaults.trainer]: \u001b[0mparam size = 0.000000MB\n","\u001b[32m[05/23 16:35:48 nl.defaults.trainer]: \u001b[0mStart training\n","\u001b[32m[05/23 16:35:48 nl.defaults.trainer]: \u001b[0mEpoch 0, Anytime results: {'cifar10-valid': {'train_losses': [1.933049173965454, 1.6435673345184325, 1.5047246058654786, 1.3834531283569336, 1.286956615371704, 1.1839038812637328, 1.1257015887069701, 1.0640545072746277, 1.008200834274292, 0.9675810929870605, 0.9294775085449218, 0.8978886487960815, 0.8689233894729614, 0.835043701877594, 0.8149485078430175, 0.7993172987365723, 0.7647924902915955, 0.7442652308464051, 0.7303601633262634, 0.7206139094543457, 0.700282748222351, 0.689298511505127, 0.671164067955017, 0.659271063709259, 0.6536657622528076, 0.644965997467041, 0.6267636371994019, 0.6300651649665833, 0.6204490633773804, 0.6097293877315522, 0.6010741853713989, 0.5971751938438415, 0.5914653929138184, 0.5821332813644409, 0.5756466757678985, 0.5765612985229492, 0.5747497636222839, 0.5639631831932068, 0.5726355790519715, 0.5540831290435791, 0.544603844833374, 0.538719157447815, 0.5455957692337036, 0.5412485385322571, 0.5337968168449402, 0.5338672785758972, 0.5202459384346009, 0.5235530172157288, 0.5228768538284302, 0.5111833030891418, 0.5069599935722351, 0.4985576431465149, 0.5061389976501465, 0.5057560344696045, 0.4975048216819763, 0.4996471509456635, 0.49808415460586547, 0.48002091426849364, 0.4895668503761291, 0.47426448446273806, 0.47582018551826477, 0.4727789403152466, 0.4713308194351196, 0.4654431737613678, 0.4631043137359619, 0.4602999722862244, 0.46426936804771424, 0.45147063561439515, 0.4586259645652771, 0.4530562820339203, 0.4525101449012756, 0.44904636945724485, 0.4421387914657593, 0.44143003540992737, 0.43449196798324585, 0.429807522983551, 0.4321302970981598, 0.42644655586242675, 0.42557577180862427, 0.4184540640449524, 0.4111059604167938, 0.41888580284118654, 0.4107645316886902, 0.4032634139728546, 0.3989506572628021, 0.40599107765197756, 0.4013190036678314, 0.4004554117488861, 0.39978235445976257, 0.3918292625141144, 0.38755730080604556, 0.3802079680633545, 0.37822834414482115, 0.3721178003501892, 0.36796443832397463, 0.3624983962631226, 0.3639153636550903, 0.3588394504070282, 0.3580660499668121, 0.35965268224716185, 0.3529567024803162, 0.34759018639564515, 0.3482636020565033, 0.3410040765285492, 0.34433123145103456, 0.3332363390350342, 0.3343586909866333, 0.33191886186599734, 0.32960432033538817, 0.3258754188966751, 0.3183572149848938, 0.31825309366226195, 0.31322453734397887, 0.3127961633872986, 0.3112921525478363, 0.3073782663154602, 0.305751911945343, 0.2877358784770966, 0.29309685286521914, 0.28946088859558106, 0.2847796403694153, 0.2818057761096954, 0.2738027645301819, 0.2745120370388031, 0.2675325034427643, 0.25867299350261685, 0.25669949093818667, 0.25210444190979003, 0.2556096069812775, 0.24657657341957093, 0.2538064208316803, 0.24273306458473207, 0.23724620116710662, 0.23558641786575318, 0.22658208312988282, 0.22561613562583924, 0.2175565439891815, 0.2160201839542389, 0.2115384543132782, 0.2083314898300171, 0.20276337226867674, 0.19796098860263825, 0.19677157368183135, 0.18868987060546874, 0.18665040482521056, 0.1838897520160675, 0.16965494362831116, 0.1692909675502777, 0.16223212686538696, 0.16421128366708757, 0.15417879284381866, 0.15248106106758116, 0.15179483103752137, 0.14301283118724822, 0.13277943490028382, 0.1390109401512146, 0.1331410027551651, 0.13165652403831482, 0.1251206089258194, 0.12002688515186309, 0.11082318178653718, 0.11014242079257965, 0.10549740042209625, 0.10062637070178986, 0.09586149839639664, 0.09223287776947021, 0.09235902231693267, 0.0871694572353363, 0.07851553828954697, 0.07523862042188645, 0.07313915983438492, 0.07498600163459777, 0.0686159856414795, 0.06791985613346099, 0.06255743339061737, 0.060810287736654284, 0.05605678023815155, 0.051493860071897504, 0.05079198920726776, 0.04651469718694687, 0.04590114063620567, 0.04247044575214386, 0.042684141470193865, 0.04604436099410057, 0.03932782050609589, 0.040091955519914624, 0.03989724842786789, 0.03675567040979862, 0.03643383831262589, 0.03524160267472267, 0.03457283695936203, 0.03541027491092682, 0.03261254559040069, 0.031013704183101655, 0.03276500719666481, 0.03511530919075012, 0.03020550874441862, 0.0300822855424881, 0.03165007179617882, 0.03257577588319779], 'eval_losses': [1.853276103477478, 1.9825896265411378, 1.7628808596038819, 1.4096657558441161, 1.4998609498214721, 1.383873239364624, 1.7190013084411622, 1.262677116317749, 1.3637014740371705, 1.2649028635406494, 1.4128168886947632, 1.3575548432922364, 1.1706336224746705, 1.4476164538574219, 1.085583380355835, 1.4277293459320068, 1.845134800338745, 1.1361894588470458, 1.7432173997497558, 1.047818994617462, 1.0644127959823608, 1.2358372732162475, 0.7923082675361633, 1.8984723958587646, 1.227219734992981, 1.2374632009124755, 1.8372280381774901, 3.3594971089172363, 1.8625118659973146, 1.4339509927368164, 1.194370693397522, 0.8332742945289612, 0.9140051091003418, 1.284939202232361, 0.9161269886398316, 1.3480814905166627, 1.0398822765731812, 1.2605186191177369, 0.8410207567596436, 0.9902118959808349, 0.7680131269073487, 1.2281337160491943, 1.0896810879898071, 0.8184736426544189, 0.8645902954673768, 1.7687164207839965, 0.8077349285507203, 1.207072050819397, 1.085643136177063, 0.9497915023803711, 1.2137908243942261, 1.0207273559761048, 1.5429754879379272, 0.8329608443450928, 0.8357771710777283, 0.7830682307052612, 1.1425826570892335, 0.7564472578811645, 0.87835656539917, 1.4388655133819581, 1.4618375290679932, 0.8127754815483094, 0.9564275854301453, 1.4416781497192384, 1.1074947327041627, 0.9531717235565186, 0.8289349126243591, 1.2754418816375732, 1.1349834226608277, 1.7311271363067626, 0.8819717637634278, 0.933219065990448, 0.784826379699707, 0.8595322378540039, 0.7136831183815002, 1.2118772090911865, 0.6783367133140564, 0.8996105028533935, 1.4115132711029053, 0.8072059643936157, 1.142419045753479, 0.7940620897483825, 0.878292625541687, 1.0021474601745606, 0.7369408583450318, 0.8604336462402343, 0.8097284167098999, 0.8572968395805359, 0.7299011550521851, 0.8498886232185364, 1.0990450579833984, 0.9377336064529419, 1.596045492286682, 0.7873356300163269, 0.9096064290618896, 0.8921308458900452, 0.847033512058258, 0.8047578199577331, 0.7195415874481201, 0.7557898583221435, 0.792297578868866, 0.6501456667709351, 1.2255437806701661, 0.7569386186790467, 0.8863202992630005, 0.6395072632789612, 0.7113047681808472, 0.6376822698974609, 0.7149502280426026, 0.686346060962677, 0.6167438936614991, 1.1942690195083618, 0.8190234329223632, 0.6529788191604614, 0.6655721626281739, 1.0146758702278138, 0.6935151036643982, 0.7063728413581848, 0.6997902191543579, 0.6693120042610169, 0.7805671958732605, 0.7888907621002197, 0.7633749666404724, 0.8210488289070129, 0.5793331812858582, 0.6228814896965027, 0.9085615486526489, 0.6486815407371521, 0.7352733605957031, 0.6726218161964417, 0.729565166721344, 0.7221049830436707, 0.6092571593093872, 0.9904315916442871, 0.7177288776016235, 0.8044267671012878, 0.7301563682746888, 0.5891368518066407, 0.6938168054580689, 0.6769888493728637, 0.6718026449966431, 0.6439840829849243, 0.6875117469215393, 0.692921744556427, 0.625256512184143, 0.6981553867149353, 0.636772664604187, 0.6946889575767518, 0.5836456839847565, 0.6240633099842071, 0.5985315733528137, 0.6856615443611145, 0.5918414127731323, 0.5658171324920654, 0.6106313031578064, 0.5521215028190612, 0.649893540172577, 0.5895428963470459, 0.5434328539276123, 0.597798399181366, 0.5711516212654114, 0.5831282989120483, 0.5978009645080566, 0.5461356635665894, 0.5734788090133667, 0.5795820503044128, 0.6116492777252197, 0.5694089279842377, 0.568785023059845, 0.5618854899406434, 0.5635403636169434, 0.5830152307128906, 0.5711482059288024, 0.5568729959487915, 0.5673009009170532, 0.5674946151924133, 0.5650128768253326, 0.5699412359237671, 0.5753453620719909, 0.5744260936355591, 0.5668122173500061, 0.5662241883659362, 0.5645727476119995, 0.5703306195449829, 0.55752571767807, 0.5635156677246094, 0.5574384237861634, 0.5620425259971619, 0.5665751437950134, 0.5677274066352844, 0.5643322320556641, 0.5647553562068939, 0.560993676662445, 0.5646405374145508, 0.5617116917800903, 0.5623938551521301, 0.5640535704803467, 0.5687453405570984, 0.5678173172187805, 0.5599888938522339, 0.5531601202487946], 'train_acc1es': [26.715999996337892, 38.55199999389649, 44.867999986572265, 49.551999997558596, 52.93199998535156, 57.03999998657227, 59.395999986572264, 61.803999990234374, 63.77599999511719, 65.5080000024414, 66.80799999023438, 68.05600001464843, 69.10000000732421, 70.80000001953125, 71.12400000976562, 71.73999997802734, 72.99600001708984, 74.06800000244141, 74.50400000732422, 74.81999999511719, 75.55599999267578, 75.58799998779297, 76.3640000024414, 76.87199998535156, 77.36799999023438, 77.53200000732421, 78.02399999755859, 78.13200000488281, 78.47199998291016, 78.72400001464844, 78.85999998291015, 79.03199999023437, 79.55599997314454, 79.72399998535157, 79.68400001220704, 79.78799999267578, 79.82000001708984, 80.31599997314453, 79.54799997558594, 80.78799997070313, 80.95199999511719, 81.33600001220704, 80.94, 81.30399999755859, 81.52799998779297, 81.34800001953126, 82.10399998291015, 81.69999999267579, 81.85199998779296, 82.32399998535156, 82.25200001953125, 82.668, 82.43999998291015, 82.53599997802735, 82.84800000244141, 82.42, 82.71199998291016, 83.21999997558594, 82.968, 83.38799997558594, 83.34000001220703, 83.65999997070313, 83.54800001464844, 83.93199997070313, 83.74000000976562, 84.13199997070312, 83.65600000976562, 84.11200001220703, 84.13999999267578, 84.26400001953125, 84.1080000024414, 84.47599998291015, 84.58799998046875, 84.64400001220703, 84.67999997070312, 85.06400001708984, 84.86800000488282, 85.21999998779297, 85.27600001220704, 85.3680000024414, 85.48799999755859, 85.21999997558594, 85.69999997314453, 85.91600000488282, 86.0920000048828, 85.91999997070313, 86.156, 86.09200001953126, 85.9760000048828, 86.31199998535156, 86.44800001953125, 86.69600001220704, 86.56, 87.04, 87.24000001953125, 87.21600001220703, 87.17199999511719, 87.2360000024414, 87.49999999755859, 87.61200001464844, 87.8880000024414, 88.02400000732422, 87.86000001464843, 87.99199998779297, 87.80399999267578, 88.28000001464844, 88.24800000488281, 88.35599999267578, 88.45199997070313, 88.64799998046875, 88.68399999755859, 88.9880000048828, 88.83599997314452, 88.99999999023437, 89.11599999755859, 89.39600000244141, 89.10799998535157, 90.0199999975586, 89.63599999023438, 89.7720000024414, 90.09999999267578, 90.0320000024414, 90.39999998291016, 90.22399998046875, 90.52799999023438, 90.91599999023437, 90.91599999267578, 91.01999998779297, 91.03999997314453, 91.40399998779297, 91.05199998291016, 91.46799998779296, 91.79999998291015, 91.61199999511719, 92.19599998291015, 92.1319999975586, 92.37599997314453, 92.32799998779296, 92.47999999267579, 92.64799997070313, 92.92399998291016, 93.14799999023438, 93.08800001708984, 93.30799998046875, 93.28399997070312, 93.53199998535156, 93.95999998535156, 94.15199997314453, 94.27999999267578, 94.18800001708985, 94.63999997802735, 94.72400001953125, 94.64800001953125, 94.86399997314453, 95.37199997802735, 95.25599998046874, 95.43599997802734, 95.28400001708984, 95.60800001220703, 95.74800001953125, 96.18000000976562, 96.15999998046875, 96.49200001464844, 96.61599997070313, 96.72800000976562, 96.84000001220703, 96.86400001708985, 97.03600000976563, 97.47200000976562, 97.50800000732421, 97.54000000976562, 97.62400001220703, 97.65200001220703, 97.76400000976562, 98.01600000732422, 98.02800000976562, 98.15200001464844, 98.39200000488282, 98.38400000732422, 98.50800001464843, 98.6040000048828, 98.7080000048828, 98.7320000048828, 98.55600000976563, 98.8360000048828, 98.82000000976562, 98.80400000488281, 98.91600000244141, 98.91600000244141, 98.99200000488281, 99.0000000048828, 99.02400000488281, 99.0960000024414, 99.18800000732422, 99.09200000244141, 99.01200000976563, 99.112, 99.23200000244141, 99.16400000244141, 99.116], 'eval_acc1es': [29.95599999511719, 34.831999998168946, 37.55999999755859, 48.356000002441405, 47.83199999633789, 50.7039999975586, 46.04000000366211, 55.82000000732422, 53.639999989013674, 56.139999998779295, 54.5159999987793, 55.676, 60.82399999267578, 54.960000001220706, 65.24799999267579, 56.69599999633789, 50.200000009765624, 63.07199999267578, 56.228000008544925, 64.50000001220702, 66.18799998535157, 60.80799998901367, 72.28399999511718, 49.7599999987793, 62.191999989013674, 59.923999995117185, 54.55200000854492, 36.352000009765625, 52.251999990234374, 60.30799999633789, 64.57999997558593, 71.59600000976563, 69.63200000732422, 62.28000001708985, 70.32799997558594, 60.78399998046875, 67.55999997802735, 63.82799997802734, 72.32399997070313, 67.67599997802735, 74.74799998779297, 63.70799998291016, 67.71199999511718, 73.57600001220703, 71.36000001708985, 52.228000006103514, 73.23599998291016, 63.84400001953125, 66.46399999633789, 70.40799999267578, 65.94399998046875, 68.784, 62.70000001464844, 72.89199997314454, 73.664, 74.50399999511718, 66.22000000244141, 75.77200001953125, 73.03599999755859, 62.29600000732422, 58.65999998657227, 73.96799997558594, 71.82800000732422, 62.524000002441404, 69.23200001464843, 71.10799997314453, 73.82799998535157, 64.84399999267578, 64.89600000732422, 57.97199999389648, 72.56400001953125, 71.7919999951172, 74.75599999755859, 73.2719999975586, 77.16000000976562, 65.59999998046875, 77.82399997314454, 71.83200001220703, 64.51599999023438, 74.01600001708984, 67.71999997314452, 75.51200001708985, 73.58000000976563, 70.11599997070313, 75.7039999975586, 73.46000000488282, 74.50800000488282, 73.21599998291016, 77.988, 73.65199999755859, 68.84399997314453, 72.25199998291015, 59.984000002441405, 76.34800000244141, 71.31600000732422, 74.85599999023438, 74.28000000488281, 74.60399999267578, 77.16400000732422, 76.48799999267578, 75.96399999267578, 79.26799998535157, 64.36800000976562, 76.85599998535156, 73.66799998291016, 79.89199998046875, 79.176, 79.89600000732422, 78.06400001464844, 78.42799998535156, 81.04399997558593, 67.30000001953125, 76.20800000732422, 79.68799998779296, 79.75999998046875, 72.96399999023437, 79.08399999267579, 78.97599998046876, 79.23599997314453, 79.13999998291015, 77.816, 76.524, 78.06000001708985, 76.54799998535157, 81.57199997314453, 81.24400001220702, 75.27599999023437, 80.54399998535156, 79.052, 80.38000000488282, 78.8920000024414, 79.83199997558594, 81.53199997802734, 73.84000001953125, 79.89199997314454, 77.56800000488282, 79.63599997558593, 82.38400001464844, 80.96399997070313, 81.15199998291016, 81.20000001953125, 81.72800000976562, 81.13199997558594, 81.27199998291016, 82.62000001220703, 80.55200000732422, 82.01999997070313, 81.62399997314454, 83.62000000488281, 82.81199999267578, 83.42400001708984, 81.61600001708985, 83.80799997802734, 84.21600000488282, 83.50800001708984, 84.52799999023438, 82.46399999267578, 83.76400000488282, 84.95200001464843, 83.99600001953125, 84.69599999755859, 84.68400001953125, 84.36400001708985, 85.46400000244141, 85.20000000976563, 85.02399997070313, 84.59599997070312, 85.32000000732423, 85.34799999755859, 85.65200000976563, 85.86000000732422, 85.70000000732422, 85.7479999975586, 85.96800001953125, 85.9560000024414, 86.10400001708985, 86.11999999023438, 86.18800001220703, 86.18400001220704, 86.39200000488282, 86.2840000024414, 86.5279999975586, 86.35200000976562, 86.324, 86.61999998291016, 86.59199997314452, 86.82, 86.6919999975586, 86.73199998291015, 86.67199999023437, 86.77600000732421, 86.76800000976563, 86.73600000976562, 86.776, 86.80400001708985, 86.78800000732421, 86.70799999755859, 86.7280000024414, 86.69600001220704, 86.74800001708985, 86.81], 'cost_info': {'flops': 19.57953, 'params': 0.157306, 'latency': 0.01700269443946972, 'train_time': 9.658029774824778}}}\n","\u001b[32m[05/23 16:35:48 nl.defaults.trainer]: \u001b[0mEpoch 0 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:35:48 nl.defaults.trainer]: \u001b[0mEpoch 1 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:35:48 nl.defaults.trainer]: \u001b[0mEpoch 2 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:35:49 nl.defaults.trainer]: \u001b[0mEpoch 3 done. Train accuracy (top1, top5): 99.11600, 0.00000, Validation accuracy: 86.81000, 0.00000\n","\u001b[32m[05/23 16:35:49 nl.defaults.trainer]: \u001b[0mEpoch 4 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:49 nl.defaults.trainer]: \u001b[0mEpoch 5 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:49 nl.defaults.trainer]: \u001b[0mEpoch 6 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:50 nl.defaults.trainer]: \u001b[0mEpoch 7 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:50 nl.defaults.trainer]: \u001b[0mEpoch 8 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:50 nl.defaults.trainer]: \u001b[0mEpoch 9 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:50 nl.defaults.trainer]: \u001b[0mEpoch 10 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:51 nl.defaults.trainer]: \u001b[0mEpoch 11 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:51 nl.defaults.trainer]: \u001b[0mEpoch 12 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:51 nl.defaults.trainer]: \u001b[0mEpoch 13 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:51 nl.defaults.trainer]: \u001b[0mEpoch 14 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:51 nl.defaults.trainer]: \u001b[0mEpoch 15 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:52 nl.defaults.trainer]: \u001b[0mEpoch 16 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:52 nl.defaults.trainer]: \u001b[0mEpoch 17 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:52 nl.defaults.trainer]: \u001b[0mEpoch 18 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:35:52 nl.defaults.trainer]: \u001b[0mEpoch 19 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pyro/contrib/gp/models/gpr.py:126: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n","L = torch.cholesky(A)\n","should be replaced with\n","L = torch.linalg.cholesky(A)\n","and\n","U = torch.cholesky(A, upper=True)\n","should be replaced with\n","U = torch.linalg.cholesky(A).mH().\n","This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1337.)\n","  Lff = Kff.cholesky()\n","/usr/local/lib/python3.7/dist-packages/pyro/contrib/gp/util.py:109: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n","torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n","X = torch.triangular_solve(B, A).solution\n","should be replaced with\n","X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n","  Lffinv_pack = pack.triangular_solve(Lff, upper=False)[0]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[05/23 16:36:43 nl.defaults.trainer]: \u001b[0mEpoch 20, Anytime results: {'cifar10-valid': {'train_losses': [1.7726301501464843, 1.2632741512680055, 1.0350315731430053, 0.9116640870666504, 0.8138554672622681, 0.7384605021095276, 0.6771002819061279, 0.6386288579177857, 0.5977942006492615, 0.566234061164856, 0.5407228638648987, 0.5169966495037079, 0.5059799674415588, 0.49211094816207884, 0.47442392370224, 0.4547991913414001, 0.45366372842788694, 0.44375011929512026, 0.4291874082946777, 0.4207805109882355, 0.4070393644332886, 0.4128223983192444, 0.3933644982147217, 0.3912780677032471, 0.39287704973220827, 0.37701327048301697, 0.3703632626247406, 0.36252842462539675, 0.3545865700340271, 0.36439799418449403, 0.35175954774856566, 0.352374792804718, 0.3494409676837921, 0.34050146408081056, 0.33357596693992614, 0.3253499046516418, 0.3226811494445801, 0.32070203971862793, 0.32613728584289553, 0.3122583133125305, 0.31861459453582763, 0.29858239007949827, 0.3031420729446411, 0.29814767778396606, 0.30188757351875306, 0.2935050654029846, 0.2895284996509552, 0.29574748558044434, 0.28127229190826414, 0.2788175543785095, 0.2840972238445282, 0.27199181344032286, 0.27290838750839236, 0.26574461709022523, 0.27254494309425353, 0.2622075592327118, 0.2729633536148071, 0.2605763591194153, 0.258357668504715, 0.23966920917510987, 0.2618053030633926, 0.25782158448696135, 0.24394119193077088, 0.2535585989665985, 0.2447747621011734, 0.239952808508873, 0.24004719898223878, 0.23840140478134156, 0.24016718745708465, 0.23675682633399964, 0.22616518263816834, 0.21403014478683471, 0.22661552424430847, 0.22467548847675323, 0.20833352692604065, 0.21816086867809295, 0.21417523289680482, 0.21433385649681092, 0.20875024881839752, 0.20629779204368592, 0.1999822235584259, 0.20519787709236145, 0.1970332114267349, 0.19073082847595216, 0.19611911709308624, 0.1894867743396759, 0.19472460577487946, 0.17954142199993134, 0.17535858225107193, 0.18349442404270172, 0.17372775327205658, 0.17052123005867004, 0.17219759708881377, 0.1724909539937973, 0.16931497011661528, 0.16221350789546968, 0.1642095751476288, 0.1597701438188553, 0.15603769296169281, 0.15719229858636857, 0.15613695202350616, 0.14955226908683777, 0.14637396189451218, 0.14552984980583192, 0.1412839818239212, 0.14201841655254363, 0.14395703977823257, 0.13532956699371337, 0.12968134902000428, 0.1280316431903839, 0.1239628472828865, 0.11874924341201783, 0.12164036078929902, 0.11990649643421174, 0.1160284399986267, 0.11443230902433395, 0.11033453067302704, 0.10941301799297333, 0.10761771523952485, 0.10543239567756653, 0.09001801859736443, 0.10175345405340194, 0.09055124494314194, 0.08845513292551041, 0.08165875105142593, 0.08407168956756592, 0.08406028326034545, 0.08446159843683243, 0.08083324142694473, 0.07214234795331954, 0.07961240248322488, 0.07521961565852166, 0.07206464721918106, 0.06412235758781433, 0.05742816984653473, 0.06045057648539543, 0.05137665984988213, 0.049202715791463854, 0.049984927271604536, 0.04855161390900612, 0.047922370524406434, 0.043593682114481926, 0.039393371309041976, 0.03481456549406051, 0.03561475551605225, 0.03113965147972107, 0.027730674822330475, 0.03230222392678261, 0.02651573492050171, 0.027377016479969023, 0.022964896864891053, 0.022539460213184356, 0.023155455704927445, 0.020795817275047302, 0.019449235087633132, 0.016223811691999435, 0.015722117793262005, 0.014958812029063701, 0.012903136225938796, 0.011836160101294518, 0.010960419072806836, 0.011182013713121414, 0.010827825953662395, 0.009900919553041457, 0.008297104788422584, 0.0077525005152821545, 0.006521991423070431, 0.006128952867686749, 0.006098052520677447, 0.005712904340922833, 0.00588519031316042, 0.004925194225162268, 0.0043670635037124155, 0.004761073724329472, 0.0037600692857801916, 0.004550940673947334, 0.004170487490743399, 0.004020287989675998, 0.004145785541385412, 0.003908578156679869, 0.003949201945364475, 0.003207805385775864, 0.003279204101189971, 0.003943141021057963, 0.0038551958274841308, 0.0034629081816226243, 0.0034469756795093417, 0.0031426940720528365, 0.0034230355936288835, 0.0032149739553034304, 0.003457264813706279, 0.0033051802176237107, 0.003482307368069887, 0.003406692513898015, 0.0032044207777082922, 0.0028920193284004926, 0.003023021241724491, 0.0034502618987113237, 0.003478339290767908, 0.0033523044963926075], 'eval_losses': [2.164647883682251, 1.6545580722427369, 1.4628006410598755, 1.1600808632278443, 1.3669910679244994, 0.9744308032226563, 0.9985012427902221, 0.9576312366867066, 0.8076681733703613, 0.8454236519622803, 0.9638540901184082, 0.7826630718803406, 1.104512394886017, 0.7641541923141479, 0.6548123612785339, 0.9922218333053588, 0.8117137370300292, 1.2596006659698487, 0.8352864991950989, 0.7102846459007263, 0.948417996635437, 0.6667930041122436, 0.6735515013122558, 0.6765720962524414, 0.6404460549545288, 0.5868661316299438, 0.8539215717697144, 0.671702494392395, 1.013946421394348, 0.7828061346626282, 0.6231124632453918, 0.9472909074783326, 0.9412059941101074, 0.7917986108016968, 0.6953180638313293, 0.5138192662715911, 0.6458280938911438, 0.5993597709274292, 0.6608743241500854, 0.5610510663795472, 0.9400737268257141, 0.9475615718841552, 0.6772247442245484, 0.7058313579368591, 0.6999283320236206, 0.7601127938270569, 0.5406990502738953, 0.6744494660568238, 0.657445820388794, 0.6360727245140075, 0.602183510017395, 0.6638840437507629, 0.5764787740898132, 0.7622425645637512, 0.6026571141052246, 0.6648900294494628, 0.8960332232666015, 0.6581889182662964, 0.6574881332015992, 0.764426356048584, 0.5661938891410828, 0.5509537802505493, 0.6939318278503418, 0.8738080065155029, 0.8335734016609192, 0.5141450018692016, 0.5745392135429382, 0.8005889149475097, 0.5406961914157867, 0.5273537969589234, 0.7863380772590637, 0.5588566858005524, 0.6890827312850952, 0.6057677677345276, 0.5635084333992004, 0.6811963825798034, 0.61648023935318, 1.012724828414917, 0.6362171352672576, 0.600728142566681, 0.8946510879516602, 0.6929350837135315, 0.7718009796142579, 0.6391929166984558, 0.5173586741065979, 0.5696404926109314, 0.696883238658905, 0.5419068127822876, 0.5304592200279236, 0.49453839639663694, 0.6299375939750671, 0.5407747402286529, 0.5964672617912292, 0.6953459352493286, 0.4981718883323669, 0.5146202296638489, 0.6263791172599793, 0.4971261043357849, 0.541742048034668, 0.5074004801368713, 0.5106167580413818, 0.5403941158676148, 0.4952197231388092, 0.5036902098464966, 0.5564737716388702, 0.6205085544586182, 0.5223774889564514, 0.636497908191681, 0.5072039118480682, 0.5414098038864136, 0.577336726436615, 0.6121881593322754, 0.5503580962467194, 0.5647501354217529, 0.5259331694030762, 0.5857357997512818, 0.6622110190010071, 0.5913814347076416, 0.5286097303771973, 0.6344818830299378, 0.5167601127433776, 0.5717268344116211, 0.503782015247345, 0.5718589818191528, 0.5040748626327515, 0.5289617172050476, 0.5618893656158447, 0.6697765984916687, 0.4896399263381958, 0.5026871321678161, 0.5995179688262939, 0.5867765543365479, 0.6022817820549011, 0.5503802780532837, 0.5891882818222046, 0.5659550923728943, 0.5393634149551392, 0.4725204941082001, 0.5599682631874084, 0.49285970909118654, 0.4587254029464722, 0.5250094151496887, 0.4481734387016296, 0.5108769823455811, 0.46357153235435483, 0.46746708969116213, 0.5047348567390442, 0.5160715837097168, 0.4970678808498383, 0.47975242698669435, 0.46656886087417604, 0.4607551993751526, 0.4550916090297699, 0.4969077893257141, 0.45320259128570556, 0.4825685316467285, 0.4614853197288513, 0.4551181153869629, 0.4619613722896576, 0.4459185376644135, 0.4371619209480286, 0.43250919277191163, 0.4586801371669769, 0.4258842087650299, 0.4228464393901825, 0.43363750972747805, 0.424913526930809, 0.42323920888900757, 0.43190860176086426, 0.4162640994262695, 0.4204883956050873, 0.42004101861953735, 0.41806100769519805, 0.41835685523986815, 0.4199794206905365, 0.4170577170944214, 0.4155419568443298, 0.4160143413925171, 0.4168384044075012, 0.4160309219741821, 0.4137410012769699, 0.4120999512767792, 0.41584254943847654, 0.4088985359096527, 0.41060246324539185, 0.4111568983078003, 0.4107550534629822, 0.415529646282196, 0.413400959815979, 0.41062481578826904, 0.41101011686325073, 0.4162301109313965, 0.41249493049621583, 0.411628330783844, 0.4098601459789276, 0.41143245264053346, 0.41225017765045163, 0.413348842458725, 0.41110972929000855, 0.41610408491134643, 0.4268304099082947], 'train_acc1es': [33.06400000732422, 53.84400000122071, 62.50399999267578, 67.13199997314453, 70.876, 73.9, 76.27199998535156, 77.71199999755859, 79.13600000976562, 80.49200001464844, 81.03199999023437, 81.96000001953125, 82.45600001708985, 82.82399997802735, 83.49999999023437, 84.28000000244141, 84.20799997070313, 84.70000001220703, 85.17199997802734, 85.36399999023438, 85.78799997558593, 85.72800000488282, 86.34800000244141, 86.48400000488282, 86.36799999267578, 87.00000000244141, 87.13600001708984, 87.4, 87.644, 87.2879999975586, 87.82800001464844, 87.57200001708985, 87.85599999511719, 88.41599999511719, 88.52000001464843, 88.6, 88.87599998535157, 88.7480000024414, 88.6, 89.07200001708985, 88.96, 89.72399999023438, 89.648, 89.4799999975586, 89.31999997802734, 89.83199999511719, 89.99199998779297, 89.57999998046876, 90.09199999511719, 90.32799999511718, 89.94399998291016, 90.49999999755859, 90.60799999267579, 90.68799997802735, 90.72399999023438, 90.81200000732422, 90.4119999975586, 90.97999999267579, 90.916, 91.71199998046875, 90.89999998291016, 91.09199997314452, 91.5200000024414, 91.10399998291015, 91.51999998779297, 91.52399999023437, 91.75599998779298, 91.45199998779297, 91.81999997558594, 91.63199999511718, 92.27999998291016, 92.4799999975586, 92.10799997070312, 92.08799997558594, 92.76399999511719, 92.51199998779298, 92.64799997558593, 92.59199999511719, 92.53599998046874, 92.73999997558593, 92.94399999755859, 92.86399997802734, 93.09999997558593, 93.384, 93.01599997802734, 93.29999999267578, 93.23600001220703, 93.95200001464843, 93.88000001708984, 93.61599997558594, 93.92800001953125, 94.21199997558594, 94.00399997070312, 93.98399998046875, 94.18399997314454, 94.36399998046875, 94.32399999267578, 94.55599997558593, 94.58799998046875, 94.58800001708984, 94.55999997802735, 94.78800001708984, 95.09600000732422, 95.01199997070313, 95.12400001953125, 95.02399998046874, 95.06800001953125, 95.40399997070313, 95.43999997314454, 95.70799997314454, 95.76000000732422, 96.04800001220703, 95.77599997802734, 95.87600001220703, 96.02800000976562, 96.09200001220704, 96.17599997314453, 96.31600001953124, 96.32400001708984, 96.41200000976562, 97.02400000976563, 96.47600001220704, 97.00800000976562, 96.90800001464844, 97.25600000488281, 97.16400001220703, 97.16800001220703, 97.08800000488282, 97.33600000976563, 97.62000000488281, 97.27200000732422, 97.5920000048828, 97.59600000976563, 97.96800000488281, 98.12399997070312, 98.02800000488281, 98.3680000024414, 98.48000000488281, 98.34400000488282, 98.4640000048828, 98.46800001953125, 98.66000000488282, 98.73200001220704, 98.98000000488281, 98.99200000732422, 99.08400000488281, 99.21600000732421, 99.05600000732422, 99.25600000732422, 99.19600000488282, 99.3880000024414, 99.3760000024414, 99.34800000732422, 99.3800000024414, 99.45600000488281, 99.58400000732422, 99.60400000244141, 99.568, 99.704, 99.73200000244141, 99.72, 99.736, 99.768, 99.824, 99.828, 99.868, 99.912, 99.92, 99.9, 99.89600000244141, 99.9040000024414, 99.936, 99.948, 99.96, 99.968, 99.952, 99.96, 99.976, 99.956, 99.952, 99.968, 99.976, 99.988, 99.956, 99.956, 99.976, 99.972, 99.984, 99.984, 99.968, 99.964, 99.9840000024414, 99.972, 99.976, 99.988, 99.98, 99.992, 99.964, 99.948, 99.964], 'eval_acc1es': [33.344, 43.964000007324216, 54.803999992675784, 62.55600000732422, 57.4680000012207, 66.68399998046876, 64.57600001220703, 68.19200000976562, 72.40000000488281, 72.42400000732422, 70.71599999267578, 73.48400000488282, 66.98400001953125, 74.51200001953126, 78.53599998046874, 68.46400000976563, 74.052, 65.61199998535156, 73.72800000488282, 77.83199999023438, 70.62000001708985, 78.69999998779296, 78.70799997314454, 78.82799999023437, 79.01999998291015, 80.87199997314453, 75.85199998291016, 77.97600001464843, 70.88799999023438, 75.66, 80.45199999267578, 74.11199998535156, 72.39599997070313, 77.23999998779297, 78.49599997558593, 83.26400001953125, 79.86799997314453, 80.86399997314453, 79.84799997558594, 82.13999998291015, 73.98399999267578, 73.21199997070312, 80.00399998046875, 79.31999999023438, 78.55999999023437, 77.32799999023437, 82.14400001464844, 79.76000001953125, 79.46400000244141, 81.29999999023437, 82.09999997558593, 80.80400001464844, 81.46400001953126, 78.54799998046875, 81.27199997558594, 80.28799999267578, 74.4479999975586, 80.75999997070312, 79.66399997314453, 79.67200000976563, 82.46000001464844, 82.94800001220703, 79.46399999267578, 75.77600001953125, 76.55199999267577, 84.17200001708984, 82.84399997558593, 78.06400000732422, 83.29600001708984, 83.88400001708985, 78.0999999975586, 83.05200001464844, 80.34799997802735, 81.83599998779297, 83.07200001953125, 80.64800001953125, 81.63599998046875, 73.6560000024414, 81.51600001708984, 82.86799997314453, 76.00400000488281, 80.75200001953125, 78.76799999023437, 81.66799997314453, 85.23600000488281, 83.28000000244141, 80.49600001953125, 84.19600001464843, 84.69199997314453, 85.31199997070313, 81.82000001953125, 84.21600001464844, 83.71600001953125, 82.01599997802734, 85.52800000976562, 85.24399997314453, 82.19999997314453, 85.89200000488282, 84.30400001708985, 85.43999997802734, 84.89200001708984, 84.336, 85.76800000244141, 85.12800001708985, 84.37600001220703, 82.62800001464844, 85.66399999755859, 82.81599997802735, 85.33999999755859, 85.16799997070312, 84.60400001464843, 83.93600000732422, 84.82, 85.06800001708984, 85.49600001464843, 84.53200001220704, 82.67200001953125, 84.89600001708985, 85.56400000488281, 83.27999997802735, 85.84800001953126, 85.16400000488281, 86.22400001464844, 85.64800001953125, 87.1240000024414, 85.80799998046875, 84.71599999511719, 83.96000000488282, 87.04799999023437, 87.37999999267578, 84.604, 85.54000000488281, 85.18399997314454, 85.95200000976563, 85.15999997070313, 85.824, 86.804, 88.17199999267578, 86.368, 87.824, 88.35999999511719, 86.96399997070313, 88.5159999975586, 87.6240000024414, 88.36799999267578, 88.30399997802735, 87.97200000976562, 87.88800001708984, 88.056, 88.57599998779297, 88.68000000976562, 88.64799999023438, 89.184, 88.39599999267578, 89.404, 88.8519999975586, 89.16799998291016, 89.32399999023437, 89.30799998291016, 89.74399999023437, 89.86, 89.80799999511719, 89.1800000024414, 90.05999998535157, 89.9839999975586, 89.90399997314454, 90.14799997558593, 90.14799998779297, 90.0959999975586, 90.15999999267578, 90.16799998535156, 90.41599998535156, 90.28799997314454, 90.27599999511719, 90.31999998046875, 90.45599999023437, 90.37599998535157, 90.30799998779297, 90.49999997802735, 90.35199997558594, 90.33600001708984, 90.42799999023437, 90.31999998779297, 90.43999998535156, 90.34399998779297, 90.39599998779296, 90.44399999267578, 90.3839999951172, 90.38799999023438, 90.35599999267578, 90.43999998291015, 90.30399997802735, 90.36399998291016, 90.38799999023438, 90.45199999023437, 90.35599999511719, 90.35999999023437, 90.36000001708985, 90.42799998046875, 90.2959999975586, 90.21], 'cost_info': {'flops': 54.96897, 'params': 0.400346, 'latency': 0.02005649867810701, 'train_time': 10.839458545049032}}}\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 20 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 21 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 22 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 23 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 24 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 25 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 26 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 27 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 28 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 29 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 30 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 31 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 32 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 33 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 34 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 35 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 36 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 37 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 38 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:36:44 nl.defaults.trainer]: \u001b[0mEpoch 39 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 40, Anytime results: {'cifar10-valid': {'train_losses': [1.7726301501464843, 1.2632741512680055, 1.0350315731430053, 0.9116640870666504, 0.8138554672622681, 0.7384605021095276, 0.6771002819061279, 0.6386288579177857, 0.5977942006492615, 0.566234061164856, 0.5407228638648987, 0.5169966495037079, 0.5059799674415588, 0.49211094816207884, 0.47442392370224, 0.4547991913414001, 0.45366372842788694, 0.44375011929512026, 0.4291874082946777, 0.4207805109882355, 0.4070393644332886, 0.4128223983192444, 0.3933644982147217, 0.3912780677032471, 0.39287704973220827, 0.37701327048301697, 0.3703632626247406, 0.36252842462539675, 0.3545865700340271, 0.36439799418449403, 0.35175954774856566, 0.352374792804718, 0.3494409676837921, 0.34050146408081056, 0.33357596693992614, 0.3253499046516418, 0.3226811494445801, 0.32070203971862793, 0.32613728584289553, 0.3122583133125305, 0.31861459453582763, 0.29858239007949827, 0.3031420729446411, 0.29814767778396606, 0.30188757351875306, 0.2935050654029846, 0.2895284996509552, 0.29574748558044434, 0.28127229190826414, 0.2788175543785095, 0.2840972238445282, 0.27199181344032286, 0.27290838750839236, 0.26574461709022523, 0.27254494309425353, 0.2622075592327118, 0.2729633536148071, 0.2605763591194153, 0.258357668504715, 0.23966920917510987, 0.2618053030633926, 0.25782158448696135, 0.24394119193077088, 0.2535585989665985, 0.2447747621011734, 0.239952808508873, 0.24004719898223878, 0.23840140478134156, 0.24016718745708465, 0.23675682633399964, 0.22616518263816834, 0.21403014478683471, 0.22661552424430847, 0.22467548847675323, 0.20833352692604065, 0.21816086867809295, 0.21417523289680482, 0.21433385649681092, 0.20875024881839752, 0.20629779204368592, 0.1999822235584259, 0.20519787709236145, 0.1970332114267349, 0.19073082847595216, 0.19611911709308624, 0.1894867743396759, 0.19472460577487946, 0.17954142199993134, 0.17535858225107193, 0.18349442404270172, 0.17372775327205658, 0.17052123005867004, 0.17219759708881377, 0.1724909539937973, 0.16931497011661528, 0.16221350789546968, 0.1642095751476288, 0.1597701438188553, 0.15603769296169281, 0.15719229858636857, 0.15613695202350616, 0.14955226908683777, 0.14637396189451218, 0.14552984980583192, 0.1412839818239212, 0.14201841655254363, 0.14395703977823257, 0.13532956699371337, 0.12968134902000428, 0.1280316431903839, 0.1239628472828865, 0.11874924341201783, 0.12164036078929902, 0.11990649643421174, 0.1160284399986267, 0.11443230902433395, 0.11033453067302704, 0.10941301799297333, 0.10761771523952485, 0.10543239567756653, 0.09001801859736443, 0.10175345405340194, 0.09055124494314194, 0.08845513292551041, 0.08165875105142593, 0.08407168956756592, 0.08406028326034545, 0.08446159843683243, 0.08083324142694473, 0.07214234795331954, 0.07961240248322488, 0.07521961565852166, 0.07206464721918106, 0.06412235758781433, 0.05742816984653473, 0.06045057648539543, 0.05137665984988213, 0.049202715791463854, 0.049984927271604536, 0.04855161390900612, 0.047922370524406434, 0.043593682114481926, 0.039393371309041976, 0.03481456549406051, 0.03561475551605225, 0.03113965147972107, 0.027730674822330475, 0.03230222392678261, 0.02651573492050171, 0.027377016479969023, 0.022964896864891053, 0.022539460213184356, 0.023155455704927445, 0.020795817275047302, 0.019449235087633132, 0.016223811691999435, 0.015722117793262005, 0.014958812029063701, 0.012903136225938796, 0.011836160101294518, 0.010960419072806836, 0.011182013713121414, 0.010827825953662395, 0.009900919553041457, 0.008297104788422584, 0.0077525005152821545, 0.006521991423070431, 0.006128952867686749, 0.006098052520677447, 0.005712904340922833, 0.00588519031316042, 0.004925194225162268, 0.0043670635037124155, 0.004761073724329472, 0.0037600692857801916, 0.004550940673947334, 0.004170487490743399, 0.004020287989675998, 0.004145785541385412, 0.003908578156679869, 0.003949201945364475, 0.003207805385775864, 0.003279204101189971, 0.003943141021057963, 0.0038551958274841308, 0.0034629081816226243, 0.0034469756795093417, 0.0031426940720528365, 0.0034230355936288835, 0.0032149739553034304, 0.003457264813706279, 0.0033051802176237107, 0.003482307368069887, 0.003406692513898015, 0.0032044207777082922, 0.0028920193284004926, 0.003023021241724491, 0.0034502618987113237, 0.003478339290767908, 0.0033523044963926075], 'eval_losses': [2.164647883682251, 1.6545580722427369, 1.4628006410598755, 1.1600808632278443, 1.3669910679244994, 0.9744308032226563, 0.9985012427902221, 0.9576312366867066, 0.8076681733703613, 0.8454236519622803, 0.9638540901184082, 0.7826630718803406, 1.104512394886017, 0.7641541923141479, 0.6548123612785339, 0.9922218333053588, 0.8117137370300292, 1.2596006659698487, 0.8352864991950989, 0.7102846459007263, 0.948417996635437, 0.6667930041122436, 0.6735515013122558, 0.6765720962524414, 0.6404460549545288, 0.5868661316299438, 0.8539215717697144, 0.671702494392395, 1.013946421394348, 0.7828061346626282, 0.6231124632453918, 0.9472909074783326, 0.9412059941101074, 0.7917986108016968, 0.6953180638313293, 0.5138192662715911, 0.6458280938911438, 0.5993597709274292, 0.6608743241500854, 0.5610510663795472, 0.9400737268257141, 0.9475615718841552, 0.6772247442245484, 0.7058313579368591, 0.6999283320236206, 0.7601127938270569, 0.5406990502738953, 0.6744494660568238, 0.657445820388794, 0.6360727245140075, 0.602183510017395, 0.6638840437507629, 0.5764787740898132, 0.7622425645637512, 0.6026571141052246, 0.6648900294494628, 0.8960332232666015, 0.6581889182662964, 0.6574881332015992, 0.764426356048584, 0.5661938891410828, 0.5509537802505493, 0.6939318278503418, 0.8738080065155029, 0.8335734016609192, 0.5141450018692016, 0.5745392135429382, 0.8005889149475097, 0.5406961914157867, 0.5273537969589234, 0.7863380772590637, 0.5588566858005524, 0.6890827312850952, 0.6057677677345276, 0.5635084333992004, 0.6811963825798034, 0.61648023935318, 1.012724828414917, 0.6362171352672576, 0.600728142566681, 0.8946510879516602, 0.6929350837135315, 0.7718009796142579, 0.6391929166984558, 0.5173586741065979, 0.5696404926109314, 0.696883238658905, 0.5419068127822876, 0.5304592200279236, 0.49453839639663694, 0.6299375939750671, 0.5407747402286529, 0.5964672617912292, 0.6953459352493286, 0.4981718883323669, 0.5146202296638489, 0.6263791172599793, 0.4971261043357849, 0.541742048034668, 0.5074004801368713, 0.5106167580413818, 0.5403941158676148, 0.4952197231388092, 0.5036902098464966, 0.5564737716388702, 0.6205085544586182, 0.5223774889564514, 0.636497908191681, 0.5072039118480682, 0.5414098038864136, 0.577336726436615, 0.6121881593322754, 0.5503580962467194, 0.5647501354217529, 0.5259331694030762, 0.5857357997512818, 0.6622110190010071, 0.5913814347076416, 0.5286097303771973, 0.6344818830299378, 0.5167601127433776, 0.5717268344116211, 0.503782015247345, 0.5718589818191528, 0.5040748626327515, 0.5289617172050476, 0.5618893656158447, 0.6697765984916687, 0.4896399263381958, 0.5026871321678161, 0.5995179688262939, 0.5867765543365479, 0.6022817820549011, 0.5503802780532837, 0.5891882818222046, 0.5659550923728943, 0.5393634149551392, 0.4725204941082001, 0.5599682631874084, 0.49285970909118654, 0.4587254029464722, 0.5250094151496887, 0.4481734387016296, 0.5108769823455811, 0.46357153235435483, 0.46746708969116213, 0.5047348567390442, 0.5160715837097168, 0.4970678808498383, 0.47975242698669435, 0.46656886087417604, 0.4607551993751526, 0.4550916090297699, 0.4969077893257141, 0.45320259128570556, 0.4825685316467285, 0.4614853197288513, 0.4551181153869629, 0.4619613722896576, 0.4459185376644135, 0.4371619209480286, 0.43250919277191163, 0.4586801371669769, 0.4258842087650299, 0.4228464393901825, 0.43363750972747805, 0.424913526930809, 0.42323920888900757, 0.43190860176086426, 0.4162640994262695, 0.4204883956050873, 0.42004101861953735, 0.41806100769519805, 0.41835685523986815, 0.4199794206905365, 0.4170577170944214, 0.4155419568443298, 0.4160143413925171, 0.4168384044075012, 0.4160309219741821, 0.4137410012769699, 0.4120999512767792, 0.41584254943847654, 0.4088985359096527, 0.41060246324539185, 0.4111568983078003, 0.4107550534629822, 0.415529646282196, 0.413400959815979, 0.41062481578826904, 0.41101011686325073, 0.4162301109313965, 0.41249493049621583, 0.411628330783844, 0.4098601459789276, 0.41143245264053346, 0.41225017765045163, 0.413348842458725, 0.41110972929000855, 0.41610408491134643, 0.4268304099082947], 'train_acc1es': [33.06400000732422, 53.84400000122071, 62.50399999267578, 67.13199997314453, 70.876, 73.9, 76.27199998535156, 77.71199999755859, 79.13600000976562, 80.49200001464844, 81.03199999023437, 81.96000001953125, 82.45600001708985, 82.82399997802735, 83.49999999023437, 84.28000000244141, 84.20799997070313, 84.70000001220703, 85.17199997802734, 85.36399999023438, 85.78799997558593, 85.72800000488282, 86.34800000244141, 86.48400000488282, 86.36799999267578, 87.00000000244141, 87.13600001708984, 87.4, 87.644, 87.2879999975586, 87.82800001464844, 87.57200001708985, 87.85599999511719, 88.41599999511719, 88.52000001464843, 88.6, 88.87599998535157, 88.7480000024414, 88.6, 89.07200001708985, 88.96, 89.72399999023438, 89.648, 89.4799999975586, 89.31999997802734, 89.83199999511719, 89.99199998779297, 89.57999998046876, 90.09199999511719, 90.32799999511718, 89.94399998291016, 90.49999999755859, 90.60799999267579, 90.68799997802735, 90.72399999023438, 90.81200000732422, 90.4119999975586, 90.97999999267579, 90.916, 91.71199998046875, 90.89999998291016, 91.09199997314452, 91.5200000024414, 91.10399998291015, 91.51999998779297, 91.52399999023437, 91.75599998779298, 91.45199998779297, 91.81999997558594, 91.63199999511718, 92.27999998291016, 92.4799999975586, 92.10799997070312, 92.08799997558594, 92.76399999511719, 92.51199998779298, 92.64799997558593, 92.59199999511719, 92.53599998046874, 92.73999997558593, 92.94399999755859, 92.86399997802734, 93.09999997558593, 93.384, 93.01599997802734, 93.29999999267578, 93.23600001220703, 93.95200001464843, 93.88000001708984, 93.61599997558594, 93.92800001953125, 94.21199997558594, 94.00399997070312, 93.98399998046875, 94.18399997314454, 94.36399998046875, 94.32399999267578, 94.55599997558593, 94.58799998046875, 94.58800001708984, 94.55999997802735, 94.78800001708984, 95.09600000732422, 95.01199997070313, 95.12400001953125, 95.02399998046874, 95.06800001953125, 95.40399997070313, 95.43999997314454, 95.70799997314454, 95.76000000732422, 96.04800001220703, 95.77599997802734, 95.87600001220703, 96.02800000976562, 96.09200001220704, 96.17599997314453, 96.31600001953124, 96.32400001708984, 96.41200000976562, 97.02400000976563, 96.47600001220704, 97.00800000976562, 96.90800001464844, 97.25600000488281, 97.16400001220703, 97.16800001220703, 97.08800000488282, 97.33600000976563, 97.62000000488281, 97.27200000732422, 97.5920000048828, 97.59600000976563, 97.96800000488281, 98.12399997070312, 98.02800000488281, 98.3680000024414, 98.48000000488281, 98.34400000488282, 98.4640000048828, 98.46800001953125, 98.66000000488282, 98.73200001220704, 98.98000000488281, 98.99200000732422, 99.08400000488281, 99.21600000732421, 99.05600000732422, 99.25600000732422, 99.19600000488282, 99.3880000024414, 99.3760000024414, 99.34800000732422, 99.3800000024414, 99.45600000488281, 99.58400000732422, 99.60400000244141, 99.568, 99.704, 99.73200000244141, 99.72, 99.736, 99.768, 99.824, 99.828, 99.868, 99.912, 99.92, 99.9, 99.89600000244141, 99.9040000024414, 99.936, 99.948, 99.96, 99.968, 99.952, 99.96, 99.976, 99.956, 99.952, 99.968, 99.976, 99.988, 99.956, 99.956, 99.976, 99.972, 99.984, 99.984, 99.968, 99.964, 99.9840000024414, 99.972, 99.976, 99.988, 99.98, 99.992, 99.964, 99.948, 99.964], 'eval_acc1es': [33.344, 43.964000007324216, 54.803999992675784, 62.55600000732422, 57.4680000012207, 66.68399998046876, 64.57600001220703, 68.19200000976562, 72.40000000488281, 72.42400000732422, 70.71599999267578, 73.48400000488282, 66.98400001953125, 74.51200001953126, 78.53599998046874, 68.46400000976563, 74.052, 65.61199998535156, 73.72800000488282, 77.83199999023438, 70.62000001708985, 78.69999998779296, 78.70799997314454, 78.82799999023437, 79.01999998291015, 80.87199997314453, 75.85199998291016, 77.97600001464843, 70.88799999023438, 75.66, 80.45199999267578, 74.11199998535156, 72.39599997070313, 77.23999998779297, 78.49599997558593, 83.26400001953125, 79.86799997314453, 80.86399997314453, 79.84799997558594, 82.13999998291015, 73.98399999267578, 73.21199997070312, 80.00399998046875, 79.31999999023438, 78.55999999023437, 77.32799999023437, 82.14400001464844, 79.76000001953125, 79.46400000244141, 81.29999999023437, 82.09999997558593, 80.80400001464844, 81.46400001953126, 78.54799998046875, 81.27199997558594, 80.28799999267578, 74.4479999975586, 80.75999997070312, 79.66399997314453, 79.67200000976563, 82.46000001464844, 82.94800001220703, 79.46399999267578, 75.77600001953125, 76.55199999267577, 84.17200001708984, 82.84399997558593, 78.06400000732422, 83.29600001708984, 83.88400001708985, 78.0999999975586, 83.05200001464844, 80.34799997802735, 81.83599998779297, 83.07200001953125, 80.64800001953125, 81.63599998046875, 73.6560000024414, 81.51600001708984, 82.86799997314453, 76.00400000488281, 80.75200001953125, 78.76799999023437, 81.66799997314453, 85.23600000488281, 83.28000000244141, 80.49600001953125, 84.19600001464843, 84.69199997314453, 85.31199997070313, 81.82000001953125, 84.21600001464844, 83.71600001953125, 82.01599997802734, 85.52800000976562, 85.24399997314453, 82.19999997314453, 85.89200000488282, 84.30400001708985, 85.43999997802734, 84.89200001708984, 84.336, 85.76800000244141, 85.12800001708985, 84.37600001220703, 82.62800001464844, 85.66399999755859, 82.81599997802735, 85.33999999755859, 85.16799997070312, 84.60400001464843, 83.93600000732422, 84.82, 85.06800001708984, 85.49600001464843, 84.53200001220704, 82.67200001953125, 84.89600001708985, 85.56400000488281, 83.27999997802735, 85.84800001953126, 85.16400000488281, 86.22400001464844, 85.64800001953125, 87.1240000024414, 85.80799998046875, 84.71599999511719, 83.96000000488282, 87.04799999023437, 87.37999999267578, 84.604, 85.54000000488281, 85.18399997314454, 85.95200000976563, 85.15999997070313, 85.824, 86.804, 88.17199999267578, 86.368, 87.824, 88.35999999511719, 86.96399997070313, 88.5159999975586, 87.6240000024414, 88.36799999267578, 88.30399997802735, 87.97200000976562, 87.88800001708984, 88.056, 88.57599998779297, 88.68000000976562, 88.64799999023438, 89.184, 88.39599999267578, 89.404, 88.8519999975586, 89.16799998291016, 89.32399999023437, 89.30799998291016, 89.74399999023437, 89.86, 89.80799999511719, 89.1800000024414, 90.05999998535157, 89.9839999975586, 89.90399997314454, 90.14799997558593, 90.14799998779297, 90.0959999975586, 90.15999999267578, 90.16799998535156, 90.41599998535156, 90.28799997314454, 90.27599999511719, 90.31999998046875, 90.45599999023437, 90.37599998535157, 90.30799998779297, 90.49999997802735, 90.35199997558594, 90.33600001708984, 90.42799999023437, 90.31999998779297, 90.43999998535156, 90.34399998779297, 90.39599998779296, 90.44399999267578, 90.3839999951172, 90.38799999023438, 90.35599999267578, 90.43999998291015, 90.30399997802735, 90.36399998291016, 90.38799999023438, 90.45199999023437, 90.35599999511719, 90.35999999023437, 90.36000001708985, 90.42799998046875, 90.2959999975586, 90.21], 'cost_info': {'flops': 54.96897, 'params': 0.400346, 'latency': 0.02005649867810701, 'train_time': 10.839458545049032}}}\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 40 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 41 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 42 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 43 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 44 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 45 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 46 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 47 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 48 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 49 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 50 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 51 done. Train accuracy (top1, top5): 99.96400, 0.00000, Validation accuracy: 90.21000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 52 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 53 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 54 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 55 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 56 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 57 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 58 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:37:37 nl.defaults.trainer]: \u001b[0mEpoch 59 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 60, Anytime results: {'cifar10-valid': {'train_losses': [1.7935791801071166, 1.3031733681106568, 1.0737871157073975, 0.9487924364280701, 0.862992466468811, 0.7975702769470215, 0.737628256111145, 0.6931763725090027, 0.655094328212738, 0.6118414051818848, 0.586295767993927, 0.5575053512096405, 0.540699010810852, 0.5211983412551879, 0.5077082473278046, 0.48945558955192564, 0.48167524900436404, 0.46222747884750365, 0.4567486795806885, 0.44589669778823854, 0.4317913123035431, 0.4241814169502258, 0.41608513511657713, 0.4097964020061493, 0.40527843321800233, 0.3977685804462433, 0.3851625113296509, 0.3843755209350586, 0.3745192371368408, 0.3726726738357544, 0.366421470041275, 0.36544047216415404, 0.3723149547386169, 0.3531569936943054, 0.33912221870422365, 0.34112697808265685, 0.32915115739822387, 0.34203579321861266, 0.3279771167087555, 0.33715354585647583, 0.3279255128860474, 0.31011376227378845, 0.32030275140762327, 0.3124150391483307, 0.31233117676734923, 0.2984787511730194, 0.30080383219242096, 0.29989991403579713, 0.2955612964820862, 0.30274778730392454, 0.2934384001159668, 0.27854230657577517, 0.2826259848880768, 0.2752956213951111, 0.2795300273036957, 0.282933711643219, 0.2732187385559082, 0.26728098918914794, 0.2647668207359314, 0.25134945885658266, 0.2647004081392288, 0.25346478788375854, 0.26008944917678833, 0.2466357824897766, 0.2485751241016388, 0.2413796410703659, 0.247944238986969, 0.24057170142173767, 0.23786420102119446, 0.2394295780658722, 0.23300297921180724, 0.23510555578231812, 0.23071957180976868, 0.22228310304641724, 0.2278409033870697, 0.22035984621047974, 0.21837335052013399, 0.21525729860305787, 0.20961420563697816, 0.2027743044090271, 0.2052953856563568, 0.206678606300354, 0.20588232663154601, 0.1930166968536377, 0.19600733091831207, 0.1992732063961029, 0.1953595857000351, 0.18751154425382613, 0.1815264042711258, 0.18329737274169922, 0.18262139576911926, 0.18514942042827606, 0.17096936546802521, 0.17472005428791046, 0.16136435117721556, 0.172491843457222, 0.16666422285079957, 0.16083806310653687, 0.157409882144928, 0.16131908716201782, 0.15322952212810517, 0.16139305492401124, 0.15055057518959045, 0.15371454420804978, 0.14087063976287842, 0.1419029926252365, 0.1354289136171341, 0.13605446275234223, 0.14027331398487092, 0.13176830911636353, 0.13031560957670213, 0.12517908477544784, 0.11608500853061676, 0.12210602921485901, 0.11140856155872345, 0.11355659672260285, 0.11747581746101379, 0.10496597966194153, 0.11320903593063354, 0.10065761254310608, 0.09654082948446274, 0.10554994513988494, 0.09862922424554825, 0.09219370166778565, 0.09855609544992447, 0.09197911250829696, 0.08041472967386246, 0.07800060278654099, 0.08641441587686538, 0.07885647554636002, 0.07174973679184914, 0.0701665931224823, 0.07169182637691497, 0.06836818879842758, 0.06178035049438477, 0.059648868544101716, 0.0621178349685669, 0.05638090744972229, 0.05663627731561661, 0.05169803264856339, 0.045666816952228545, 0.0435580085504055, 0.04279572793483734, 0.04499041535615921, 0.03917738445520401, 0.0351157073700428, 0.03710539132714272, 0.03138750398159027, 0.03137826120853424, 0.02880950395345688, 0.02822655435204506, 0.023020785654187203, 0.01941200367808342, 0.022588197146356105, 0.021500132505893707, 0.020963198867440223, 0.017722135280370713, 0.018995036559700966, 0.014656282947361468, 0.014247824840545655, 0.012889887491464615, 0.012137446011453867, 0.010976174126565456, 0.009663381957113743, 0.008132890256643295, 0.009541160365641116, 0.007701730488240719, 0.007413634777739644, 0.007113041990846396, 0.006694382687136531, 0.006839311799257994, 0.005608953580111265, 0.005108400354012847, 0.00520724994584918, 0.004566385269425809, 0.004420867766812444, 0.004069833841919899, 0.004336345347687602, 0.004538763780146837, 0.004034159565269947, 0.0039034861084073784, 0.0032582351490855217, 0.003783494386225939, 0.00329755959585309, 0.0038780851939320565, 0.003633611859679222, 0.00374742953337729, 0.0036183391064405442, 0.0036176029014587403, 0.0036843177883327007, 0.003314005116969347, 0.0036718560710549356, 0.0033319401514530183, 0.0036673332285881042, 0.00360382079128176, 0.0028894809067249298, 0.0032777877911925315, 0.0038542036439478396, 0.003324740428850055, 0.003273240509107709], 'eval_losses': [2.0567169677734376, 1.5897846926879884, 1.2577435057067872, 1.0519931610679627, 1.1619410678100586, 0.9337344456481934, 1.426833941345215, 2.0695390591430662, 0.8953599980926513, 1.065126843032837, 0.9435394616699219, 0.8007435558509827, 0.9148944520568848, 1.7812022411727906, 0.7336775478363037, 0.7530469501304626, 0.7483371437072754, 0.7719654908943177, 0.8301381659126281, 0.8900382118988037, 0.9340492597770691, 0.6421691151237487, 0.8522604529190063, 0.8510956635284423, 0.9723368549728394, 0.6095734555244445, 0.6027920788097382, 0.930475287361145, 0.7598180921554566, 0.6735420762634278, 0.7441412213516235, 0.6751509941673279, 1.0273376871490478, 0.72983432472229, 0.7110571522140503, 0.6251357056999206, 0.6021607000732422, 0.8058167532730103, 0.729524359664917, 0.660403576335907, 0.6811010831832885, 1.1004682762908935, 0.5985989016342164, 0.7435678200531006, 0.8935513804244996, 0.6247020026493072, 0.6109926904773713, 0.6948066058349609, 0.6320769904327392, 0.5974466782283783, 0.5897055105400085, 0.6415600547027588, 0.52345822265625, 0.692166830329895, 0.654646965789795, 0.6617010832595825, 0.8813625626945496, 0.6852665320396424, 0.642043534488678, 0.520782096195221, 0.5702440088272095, 0.5972622644424439, 0.6714920264816284, 0.5983736797904968, 0.6176759587478637, 0.5986247899055481, 0.6028506073570251, 0.6112239811325073, 0.5518875489616394, 0.510727606086731, 0.7070614140319824, 0.5411045763683319, 0.5561301808547974, 0.724376487197876, 0.6403936609077454, 0.6278956218528747, 0.6324842994499207, 0.7587074059104919, 0.5697611081314087, 0.5839151325798034, 0.7070935699844361, 0.5381036917686463, 0.608894586353302, 0.5416528963470459, 0.6087524477386475, 0.5377347767448425, 0.9970889128112793, 0.5470493211936951, 0.6414849165725708, 0.5243396365737915, 0.6648162748527526, 0.487749937877655, 0.5695161654281616, 0.5868629016780853, 0.5569072721099854, 0.5685955201911926, 0.6498248822402954, 0.5810978862762451, 0.5770051006126404, 0.6434048270988464, 0.7188110755157471, 0.5217052499675751, 0.5959255642700195, 0.5010776093673706, 0.6137037456512451, 0.5988540163040161, 0.7596997141838073, 0.5618882975769043, 0.5062828859710693, 0.562315291185379, 0.5180670824050904, 0.4644368179798126, 0.4950410157203674, 0.5756710403442383, 0.5409006059455872, 0.607992564239502, 0.5355698628234863, 0.5630035824012757, 0.5190157642364502, 0.5411217945289611, 0.6228681415176391, 0.516328962135315, 0.48171431566238404, 0.46168819458007815, 0.6114775118255615, 0.5306415400505066, 0.609798589515686, 0.49439995862960817, 0.5960866185188294, 0.48832980205535886, 0.5422028293991089, 0.5537544492530823, 0.4984058423614502, 0.47153841250419615, 0.602349258556366, 0.5150466002464295, 0.49149674055099485, 0.47946146631240844, 0.47274937982559206, 0.4834161495685577, 0.4738718696784973, 0.4511212501716614, 0.47749571821212766, 0.4495653869247436, 0.4910996462249756, 0.48394084251403807, 0.4592371803665161, 0.460197156791687, 0.4567746149921417, 0.4760672795677185, 0.44152224168777465, 0.4380817192745209, 0.4498139009475708, 0.4505696475982666, 0.4256017104053497, 0.42841105566978455, 0.44078830884933473, 0.4420398949146271, 0.4243061312866211, 0.4694807057380676, 0.4212555390262604, 0.43703071833610535, 0.44027906272888184, 0.42977403824806215, 0.4144840786838532, 0.44494338245391846, 0.4242143207836151, 0.4152459034442902, 0.4259005472946167, 0.4179868496799469, 0.42993556436538694, 0.4149001724243164, 0.41608459764480593, 0.4168929482078552, 0.41757568124771116, 0.41086932673454285, 0.4105690163326263, 0.41308956040382383, 0.41441235251426695, 0.4135060957431793, 0.4097174748706818, 0.4108570017051697, 0.409167435503006, 0.40497224497795103, 0.4066487728023529, 0.40598290254592895, 0.4073362425613403, 0.40723263858795167, 0.40935167068481443, 0.40822349349975584, 0.4072707957458496, 0.4073871739959717, 0.405870979347229, 0.4066324571609497, 0.40600703195571897, 0.4053080917453766, 0.4066062270450592, 0.4081116288614273, 0.40763897433280943, 0.40864563802719117, 0.42757557778358457], 'train_acc1es': [32.095999993896484, 51.84800000854492, 61.047999992675784, 65.99999998291015, 68.84800001464843, 71.44000001220704, 73.85600001708984, 75.40399999267578, 77.04399999267578, 78.65999997070313, 79.65599998046875, 80.61999997314453, 81.10800001953125, 81.82799998779296, 82.23600000488281, 83.03200000732421, 82.92400001953125, 83.83199997314453, 84.17999997802734, 84.44399998291016, 85.05600000732422, 84.99599997558593, 85.4959999975586, 85.81600000976563, 86.06400000488281, 86.2879999975586, 86.692, 86.5920000048828, 87.19199999023438, 87.02800001464844, 87.08800000976562, 87.5079999975586, 87.05600000488282, 87.71199998291016, 88.18799999511718, 88.17600001220703, 88.6199999975586, 87.9600000024414, 88.60799999511718, 88.18399997070313, 88.5840000024414, 89.27599999511719, 88.87600001708985, 89.03599999023437, 88.90799999023437, 89.54399998046875, 89.58000001953125, 89.56799997070313, 89.69199998535156, 89.42800001464843, 89.7279999975586, 90.47599999023437, 90.08399999511718, 90.26000000976562, 90.26000000732422, 90.27600000732421, 90.48400000732421, 90.84399998535156, 90.73599999023438, 91.20799999023437, 90.57199998046875, 91.36400001708985, 90.9720000024414, 91.20799998535156, 91.27199998779297, 91.45199998046876, 91.38399998779298, 91.51599998046875, 91.71999998291015, 91.56399998779297, 91.87199999267578, 91.91600000732421, 91.79599997314453, 92.00799998046875, 92.04399997558593, 92.47999999267579, 92.29599998046875, 92.4919999975586, 92.59999998291016, 92.97999998535157, 92.92799997802734, 93.02799999023438, 92.87999997070312, 93.21199999267579, 93.23199997802735, 92.99599998291016, 92.88799997070312, 93.33200000976562, 93.53999998046875, 93.67600001953124, 93.43199997314453, 93.38799998291016, 94.07199997314453, 93.95999997802734, 94.42799997558593, 94.02799998291016, 94.13999998779298, 94.40799999023437, 94.65599998779297, 94.49600001953125, 94.82799997558594, 94.31999997070312, 94.64000001953124, 94.64400001708984, 95.14400001464844, 95.01999997558593, 95.30799997558594, 95.28800001708984, 95.22399997802735, 95.43600001953125, 95.48800001220702, 95.67200001464843, 96.06000001220703, 95.75600001708985, 96.36000001220702, 95.95600000976563, 96.06799997558593, 96.38399997070313, 96.11199997558593, 96.54399997070313, 96.68800000976563, 96.47599997070313, 96.60000000732421, 96.83600001708984, 96.65200000976563, 96.89200001220703, 97.40400000732421, 97.37600000976562, 97.09600000732422, 97.39600001464844, 97.66400000732422, 97.57600001220703, 97.6160000048828, 97.68800000488281, 98.00800001464843, 98.07600000732423, 97.95200000976563, 98.17600001220703, 98.15200001220703, 98.34000000488281, 98.53600001464844, 98.6560000024414, 98.72000000732422, 98.59200000732422, 98.85600000976562, 98.9120000024414, 98.9800000024414, 99.08000001708984, 99.12800001220702, 99.18800000488281, 99.12400000488282, 99.38400000244141, 99.5400000024414, 99.364, 99.41600000732421, 99.42000000488281, 99.54400000244141, 99.46800000488281, 99.65200000244141, 99.664, 99.68800000244141, 99.692, 99.72, 99.828, 99.8800000024414, 99.7960000024414, 99.876, 99.876, 99.896, 99.86, 99.876, 99.936, 99.924, 99.932, 99.956, 99.968, 99.9680000024414, 99.948, 99.944, 99.956, 99.96, 99.992, 99.964, 99.984, 99.976, 99.98, 99.96, 99.9560000024414, 99.972, 99.968, 99.98, 99.964, 99.968, 99.9680000024414, 99.972, 99.98, 99.9840000024414, 99.964, 99.984, 99.948], 'eval_acc1es': [34.419999998779296, 47.20000000732422, 56.548000004882816, 63.39199999755859, 59.30000000854492, 67.65199999755859, 57.255999982910154, 49.864000009765626, 69.88799999023438, 66.03199997558593, 69.19600001220704, 72.78400000488281, 70.27200000732422, 57.14000000366211, 75.71999999755859, 76.23199998779297, 75.14800000732421, 75.89999998779297, 72.95999999267578, 73.10399997070313, 72.9279999975586, 79.06799999511719, 74.56799997558593, 73.9479999975586, 71.40000001708984, 80.25599997314453, 80.25600000976563, 72.88400001220703, 76.948, 78.53199999023437, 77.61599998046874, 78.72399997070312, 70.97199998046875, 78.07199998291016, 77.91999997314453, 80.42000000732422, 80.75600001708985, 75.86799998535156, 77.42399998535156, 78.79599999023438, 78.00800000976562, 69.81200001953125, 80.97600001953126, 78.20399997802734, 74.49600000488282, 81.28800001220704, 81.1560000024414, 78.15600000488281, 79.67599999267578, 81.18800001953124, 81.52399998046874, 80.27599999023437, 83.51999997802734, 79.18800001220703, 80.75599998046874, 80.53999999267577, 75.73999999511719, 80.04800001464844, 80.98399998046875, 83.97199999267578, 82.57600001464844, 82.13200000488281, 78.93599998291016, 81.70400000488281, 81.06000001708985, 82.40799999267578, 81.79599997558594, 81.8439999975586, 83.22000001708984, 83.78000001464844, 79.02799999023438, 82.61600000732422, 82.71199998779296, 79.80399997802735, 80.90399998046875, 81.96399997802735, 81.52799998535156, 79.18399997802734, 83.76000000976562, 83.20800000732422, 80.25599997802735, 83.49600001464843, 82.31599997314453, 84.06399998046875, 82.28799998046875, 83.83999997070312, 75.04800000976563, 83.80800001220703, 82.16400001220703, 84.07999998046876, 81.00399998046875, 85.65600001464844, 83.80399998779296, 82.96399999755859, 83.84800001708984, 83.03200001953125, 81.54399997558593, 83.89600001464844, 83.98400001708984, 82.58799997314453, 80.61599999267578, 85.03199999267578, 83.16000001464843, 85.69200000488281, 82.91600000244141, 83.81200001708984, 80.95600001220703, 83.92800001708984, 85.18399999267578, 84.68399998779297, 85.37600001953125, 86.78800000244141, 86.68400000976563, 84.19199998535156, 85.03200001464843, 83.65599998046875, 85.54, 84.55200000488281, 85.67600001220703, 85.35600001220703, 83.86799997314453, 85.59200000976563, 86.59199997070313, 87.20000001708985, 84.22400000732422, 85.88400001464844, 84.72000001220704, 87.00000000244141, 84.38400000976563, 87.15200000488281, 86.03199998535156, 86.392, 86.97600001953126, 87.568, 85.08399997558594, 86.86800001464844, 87.34800000244141, 87.73599999267579, 87.8, 87.664, 88.18800000732422, 88.57200001464844, 88.07199999755859, 88.51999999023438, 87.93199999023437, 87.8959999951172, 88.46800001708985, 88.75600000244141, 88.77599998535156, 88.33199997802734, 89.10000000488282, 89.07599999023438, 89.33599999511719, 88.9880000048828, 89.624, 89.57599999267578, 89.35199997558594, 89.22399998291016, 89.97199999023438, 89.11600000244141, 90.00799999511719, 89.78, 89.72400001220703, 90.03599998535157, 90.06799999511719, 89.58799998291016, 90.12799998046874, 90.41599998291015, 90.28, 90.29599999511719, 90.2599999975586, 90.43999998535156, 90.45199997802735, 90.50799999023438, 90.37999997802734, 90.54399999267578, 90.53999999267577, 90.57199997314453, 90.4919999975586, 90.52399997558594, 90.65200001953124, 90.69999997802735, 90.66799999023438, 90.79599999511719, 90.69999998046875, 90.80799997802734, 90.71999998779297, 90.65999998535156, 90.63599999267578, 90.69199999511719, 90.67599999755859, 90.61599997558594, 90.70799998535156, 90.68400000488282, 90.65599999511718, 90.71199998046875, 90.67199998779297, 90.64399997070312, 90.66399999755859, 90.628, 90.51], 'cost_info': {'flops': 54.96897, 'params': 0.400346, 'latency': 0.019268616249686794, 'train_time': 10.631003499031067}}}\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 60 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 61 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 62 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 63 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 64 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 65 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 66 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 67 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 68 done. Train accuracy (top1, top5): 99.94800, 0.00000, Validation accuracy: 90.51000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 69 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 90.77000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 70 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 90.77000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 71 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 72 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 73 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 74 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 75 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 76 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 77 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 78 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:38:27 nl.defaults.trainer]: \u001b[0mEpoch 79 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 80, Anytime results: {'cifar10-valid': {'train_losses': [1.7746254404449462, 1.2525715937042237, 1.0205010886001586, 0.9041887921142578, 0.8123479414558411, 0.7364584699249268, 0.6741630848312378, 0.6267640244293213, 0.5884891187858582, 0.5503827807998657, 0.5296464962577819, 0.5095477344322205, 0.4777109776973724, 0.46621709315299986, 0.4492229323959351, 0.4391581182575226, 0.41857200494766234, 0.41713718710899356, 0.39895620523452757, 0.39085034116744993, 0.3904488983440399, 0.373608210849762, 0.36480088010787964, 0.36227050880432127, 0.35649055032730104, 0.3367236298084259, 0.3392516921710968, 0.3346933298683166, 0.3225389605140686, 0.33025471789360045, 0.31885675958633425, 0.31981347249031067, 0.30317366431236265, 0.31309911171913146, 0.3072423775959015, 0.29401487164497375, 0.29690482659339906, 0.2849114439201355, 0.2825883536720276, 0.27828021587371826, 0.28039682487487794, 0.2737912114095688, 0.26544114431381227, 0.26463417078018187, 0.2617005796146393, 0.2601780160331726, 0.25530390516281126, 0.2518099638414383, 0.24869031894683838, 0.2468419282054901, 0.2476457279396057, 0.24159966375350952, 0.23833100407600402, 0.2348895914554596, 0.232398039894104, 0.23142358202934266, 0.22846744904518126, 0.21901357915878297, 0.22316245243549346, 0.22272548840522766, 0.22078373539924623, 0.21504916458129883, 0.21110136355876924, 0.21320405406951903, 0.20293406505584716, 0.20283125587940215, 0.2041709073638916, 0.19773421635627747, 0.19889009864807128, 0.1906140609741211, 0.1887351924133301, 0.19090879890918733, 0.19261226412296295, 0.1828590488243103, 0.1787980257129669, 0.18291468800544738, 0.17475275500297546, 0.17200511803150176, 0.1749662488746643, 0.17150208112239837, 0.1687265163040161, 0.17420377104282378, 0.16103298442840577, 0.16325909739971162, 0.15561836744308472, 0.15403854426860808, 0.1571541468524933, 0.15451104388237, 0.14480088228702545, 0.13443238100528718, 0.14081464869976043, 0.14170886375427247, 0.13764053753852845, 0.14171770803928374, 0.14043696076631546, 0.13193515920162202, 0.1384855412864685, 0.12902787802696228, 0.13071472544670104, 0.12137279039859772, 0.1237334413933754, 0.12061486110687256, 0.11273883316755295, 0.1253305329990387, 0.10924769383668899, 0.10911147862911225, 0.11562112350940704, 0.10475705012798309, 0.10070889367580414, 0.1055792672920227, 0.10370195034027099, 0.09979624215841293, 0.09613510760307312, 0.0906841297340393, 0.09373684048652649, 0.08760787142038345, 0.08393638427257538, 0.08264624837875366, 0.08651380552768707, 0.07866799503326416, 0.07234020408987998, 0.0711566081237793, 0.07441978561401368, 0.06602694724798203, 0.07517099815845489, 0.06673867328464984, 0.058758132054805755, 0.057964024276733396, 0.06235463780641556, 0.05575353326439857, 0.051894831169843676, 0.04638636527776718, 0.0502672025513649, 0.05250447427034378, 0.04262666498184204, 0.04480634725093841, 0.04165797773599625, 0.0434769571018219, 0.038418945420980455, 0.03450439054727554, 0.035305368042588235, 0.035014791700839994, 0.03439501115083694, 0.031205382689833642, 0.027247063233852387, 0.02535728253275156, 0.029330354204177858, 0.025590090939998627, 0.016749941045045853, 0.020620152432322503, 0.021016789978146554, 0.017043285992741585, 0.015662926484942438, 0.013701772001981735, 0.012769260455965995, 0.011417203328609467, 0.011001510855555535, 0.006619351912140846, 0.008096077761873603, 0.007799483299404383, 0.0081732770550251, 0.0067813857555389405, 0.006534027804583311, 0.005591512687206268, 0.005985180187001824, 0.004235397043973207, 0.003967167109698057, 0.004052955968081951, 0.0033897193717956544, 0.0030407860757783057, 0.0028935578538477422, 0.00304538688685745, 0.0028457803250104188, 0.0023270040908455847, 0.002077452517300844, 0.0023477312177419664, 0.0024758788580447437, 0.0024956189342960717, 0.0019968066969513892, 0.0026833326147124173, 0.002210773143619299, 0.002054941701814532, 0.001915849809832871, 0.001974466485530138, 0.0018404873282462358, 0.0016433955763466657, 0.001937553005181253, 0.0017352377039194108, 0.0017995360084623099, 0.0019928793147578837, 0.0017312279224768281, 0.0014986567307636142, 0.0016601075265184045, 0.00208857716538012, 0.0018482246779650449, 0.00170278529971838, 0.0017075534347072243, 0.0017847442341595889, 0.0015362979980558158, 0.0018243489837273955], 'eval_losses': [1.7004167099761962, 1.2640720648956298, 1.1260783890151977, 1.167028021697998, 1.138815598526001, 1.046353260154724, 0.8218274205207825, 0.997259196395874, 0.8635318907928466, 0.7336437378692627, 0.7437615155982972, 0.7468032462310791, 0.7344474097633362, 0.7467612626647949, 0.8481156837272644, 0.6279564411735534, 0.7176448118591309, 0.8004950892448426, 0.6628228933906555, 0.5957677000045777, 0.6927953131484985, 0.7332342207336425, 0.6403082070732117, 0.7456984884262085, 0.6115048058319091, 0.6504589539909362, 0.6663137049674988, 0.7057497912025452, 0.6305248817253113, 0.632772862701416, 0.7624817274284362, 0.543254351978302, 0.6806864162063598, 0.6177824017715454, 0.5389980775260925, 0.6397953797721863, 0.560062555141449, 0.7072728757667541, 0.8136304460716247, 0.620847117729187, 0.6324208123302459, 0.6037143187904358, 0.5745815641593933, 0.4938424517726898, 0.6989603466796875, 0.5070402376365661, 0.5867429835510254, 0.6726844787406921, 0.7395950947570801, 0.7267618775367737, 0.7175866047859192, 0.5458885543060302, 0.6356919926452637, 0.6179738328170776, 0.5608704095363617, 0.6791090923881531, 0.7380701489067077, 0.6739645804786683, 0.5942101516151428, 0.8164201127624512, 0.7452011046028137, 0.7390241236686707, 0.6843553509712219, 0.6064271252250671, 0.8003216227912903, 0.5449528525352478, 0.5140533643722535, 0.647411085357666, 0.5758555371379852, 0.6981896110534668, 0.6432808949661255, 0.6219934247970581, 0.5505880363082886, 0.5291692859840393, 0.5924714015197754, 0.6320746515274048, 0.7140037968254089, 0.5236182795906067, 0.48174719415664674, 0.6173274262237549, 0.6041679553318023, 0.4672905652332306, 0.6286126975631714, 0.4608450119781494, 0.7094485459327697, 0.6815414708328247, 0.5702635599327087, 0.6062382802391052, 0.6579453928947449, 0.5664668649101258, 0.539786413116455, 0.6447139527130127, 0.538816554813385, 0.5575917622947693, 0.5069919419193267, 0.5117909422683716, 0.5118781038284301, 0.4982229266357422, 0.6083105189323426, 0.5793051228904724, 0.7671536774444581, 0.570645072889328, 0.6245588023757934, 0.5943541495704651, 0.577113770942688, 0.5988013249778747, 0.5411356259918213, 0.6576287629318237, 0.4925712329673767, 0.5643642643928528, 0.4961236543941498, 0.4942912080001831, 0.5766916935729981, 0.525230995054245, 0.5198735524654389, 0.4664132689857483, 0.5806890152454376, 0.4978510242462158, 0.5211024802970886, 0.5624003765296937, 0.4864869812393188, 0.5404220580863953, 0.67064609790802, 0.5391317514133454, 0.5065233495330811, 0.487877036857605, 0.48500618773460386, 0.4984992779922485, 0.4898747313117981, 0.5495070009803772, 0.49451827681541444, 0.4935645276260376, 0.5243667325019836, 0.4801720001888275, 0.496932391872406, 0.5161631118679046, 0.47474053245544434, 0.5574271750640869, 0.4728213084602356, 0.4604569463634491, 0.4875291523742676, 0.4989668164253235, 0.4845734143638611, 0.4789671956443787, 0.4966791892814636, 0.47059591999053957, 0.5252741628742218, 0.4803629207801819, 0.4614901226806641, 0.49611511160850524, 0.4358408811378479, 0.48612382457733155, 0.48724539588928223, 0.44330364521980287, 0.5029443155288696, 0.46430020725250243, 0.4678618911075592, 0.44827442228794095, 0.46440804655075074, 0.46001242347717286, 0.463009759721756, 0.48400899085044863, 0.4463294166660309, 0.44851717462539675, 0.4446151565551758, 0.4630494070243835, 0.43449869334220886, 0.4431028169250488, 0.43825167273521426, 0.4425428218078613, 0.4443647616291046, 0.43404180862426756, 0.43483548391342164, 0.43881195081710817, 0.4369903937959671, 0.4347187344837189, 0.43359984853744504, 0.43702171206474305, 0.43538841225624086, 0.4349768181419373, 0.42986678256988525, 0.42855164794921874, 0.4285649630355835, 0.4318992595672607, 0.4362735063934326, 0.42980637818336487, 0.4323894614028931, 0.43400580436706543, 0.4298272946166992, 0.43184122931480406, 0.4287837957191467, 0.429223907327652, 0.4288473167324066, 0.4289644967794418, 0.43249841203689576, 0.4302399096107483, 0.4318051530170441, 0.4294998967933655, 0.4281154341125488, 0.4298875627088547, 0.43989779443740845], 'train_acc1es': [33.08799999145508, 54.035999986572264, 63.092000007324216, 67.42800001464843, 70.89200001464843, 73.75199997558593, 76.36399999267579, 78.0159999975586, 79.39599998779296, 80.92399998779297, 81.59600000976563, 82.15600001464844, 83.53999997802734, 83.66400001708985, 84.26799997070313, 84.75200000488282, 85.29599997314453, 85.47599998291015, 86.00800000732421, 86.36799999267578, 86.50400001220703, 87.00000000976563, 87.19999999511718, 87.29199999755859, 87.60399999023437, 88.34799999755859, 88.044, 88.54800000732422, 88.59599999511718, 88.57199999755859, 88.85600000732421, 88.74800000488281, 89.31200000732422, 89.01599999023438, 89.07599999023438, 89.80000000244141, 89.70799999267578, 90.04799998779296, 90.188, 90.32799999267579, 90.23999999267578, 90.57999998535156, 90.8360000048828, 90.78400000488281, 90.80799999023438, 90.78399999267579, 91.04399998779297, 91.35999999267578, 91.38399999023437, 91.41600001464843, 91.42799997802734, 91.78799998535156, 91.89999997314453, 91.73999998291016, 91.87199997070313, 91.98799998291015, 92.15599999023438, 92.45999998291016, 92.16799997558594, 92.01999997558593, 92.26399997802734, 92.51599998046875, 92.50399998291016, 92.55199999511719, 93.03999999511718, 92.87999998291015, 92.71599999023438, 93.20799998291015, 93.00399999267579, 93.45200001220704, 93.29199999267578, 93.40799997802735, 93.35999997070313, 93.57199997802735, 93.92799998535156, 93.57999997314454, 93.89599999267578, 93.94399998779296, 94.04799999267578, 94.06399997314453, 94.12000001953125, 93.97999997070312, 94.46799998046875, 94.39600001953124, 94.59199998291015, 94.63599997558593, 94.45599997314453, 94.74400001953126, 95.10000001708984, 95.42399998291016, 95.18799997558594, 95.03200001708984, 95.19999997802735, 95.03199997314454, 95.05200000976562, 95.34799997070313, 95.16399997558594, 95.46800001953125, 95.54400001953125, 95.84800000976563, 95.82000000732423, 95.96400001953126, 96.19600001708984, 95.67199997070313, 96.34800000732422, 96.21999997070313, 95.99199998046875, 96.60000001220703, 96.57199997070313, 96.55600001708984, 96.46399997558593, 96.53200001220704, 96.71600001953125, 97.05600001953125, 96.74800001708985, 97.08000001464843, 97.10000000976562, 97.23600001464844, 97.07600001464844, 97.33599997314452, 97.63600000488282, 97.64000001220703, 97.52000000976562, 97.80800000976562, 97.59600001464844, 97.75600000488281, 98.12400000976562, 98.12000000488281, 98.02400001708985, 98.11600001464844, 98.39600000244141, 98.552, 98.40800001220703, 98.30400001220703, 98.6240000024414, 98.56800000976563, 98.67600000976563, 98.59200000732422, 98.796, 98.92400000488281, 98.9600000024414, 98.85600000488282, 98.87600000732422, 99.08800000488282, 99.21600000732421, 99.228, 99.0960000024414, 99.20400000488281, 99.51200000732422, 99.376, 99.3400000024414, 99.48800000244141, 99.592, 99.67600000244141, 99.664, 99.7120000024414, 99.7160000024414, 99.87600000488281, 99.788, 99.824, 99.792, 99.84, 99.864, 99.9, 99.872, 99.936, 99.92, 99.948, 99.948, 99.968, 99.956, 99.952, 99.956, 99.98, 99.976, 99.98, 99.956, 99.972, 99.988, 99.96, 99.976, 99.976, 99.98, 99.968, 99.98, 99.996, 99.988, 99.992, 99.988, 99.972, 99.992, 99.992, 99.988, 99.984, 99.984, 99.988, 99.988, 99.992, 99.996, 99.984], 'eval_acc1es': [38.02000000488281, 54.33600000854492, 60.659999990234375, 61.90399999511719, 62.59599998779297, 64.3439999975586, 72.49999997314453, 68.67599998291016, 72.12400001464843, 75.79600000976562, 75.73199998779297, 76.05599997558593, 76.29199998535157, 76.52799998291016, 72.73999997802734, 79.50399997314453, 76.89600000732422, 75.21199999267579, 78.49999998779298, 80.34399998291016, 78.36399997802734, 76.68799999267578, 80.27999998291016, 76.54399998779297, 80.81200001464843, 79.79199999023437, 78.99199997802734, 78.58400001708985, 80.69599997558593, 81.21999997314452, 77.53199997558593, 81.97199998535156, 78.39199998779297, 80.3800000024414, 82.65200001708985, 80.69599997558593, 82.19999998046875, 79.64000001464844, 76.52800000976562, 81.10399998535156, 79.78399997558594, 81.75200001708984, 82.13600001953125, 84.46000001464844, 79.72799999267578, 83.65200001953124, 81.77199998535156, 80.62399997802734, 79.35199999267579, 79.01599997802734, 78.37199999511719, 83.50399997802734, 81.21600001953125, 80.60800001708985, 83.1440000024414, 79.96399997802735, 79.95999999023438, 80.44, 82.98400001464844, 77.24399997802735, 79.16399997558594, 79.61600001953126, 79.49999998046874, 82.19599998535156, 78.59199997314452, 84.08800000732423, 84.59200001953126, 81.97599998291015, 83.55999999755859, 79.70799998046876, 82.45600001708985, 83.08000001220704, 83.20799997314454, 83.82400001708984, 83.16799997558594, 81.95600001708985, 80.29600001953125, 85.19599997070313, 85.672, 83.08400000488281, 83.76000000732422, 85.99200001220703, 82.89999997314453, 86.01600001220703, 80.7999999975586, 82.30399997070313, 84.46000001464844, 83.23199998046876, 82.24000001220703, 84.59200000732422, 85.10000001464844, 82.46400000976563, 84.98799997070313, 84.39199997558593, 85.90799999267578, 85.46000001708984, 85.64399998291016, 85.62400000976562, 83.42800001708984, 83.92799999023437, 80.86000001708985, 84.85600000976562, 83.54399997558593, 83.764, 84.74400001220702, 84.53199997070313, 85.61599998535156, 83.41600001953125, 86.46400001708984, 84.69599999023437, 86.68400000488282, 86.50800000488282, 85.12399997070312, 86.29999998779297, 86.11999999511718, 87.4560000024414, 84.8839999951172, 87.47999999023438, 86.42400001953125, 85.50800001953125, 87.10000000488282, 86.24800000976562, 84.23999999511719, 86.55999999755859, 87.06800000976563, 87.36400000488281, 87.59999999511719, 87.46800001464844, 87.67200001464843, 87.07200001220703, 87.72799999267578, 87.90799999267578, 87.10000001708984, 87.868, 87.87199998779298, 87.524, 88.60399999755859, 86.51200001464844, 88.4839999975586, 89.03199999023437, 88.69999999267579, 88.07600001464844, 88.62800000732422, 88.7759999975586, 88.57200000488281, 89.184, 88.18399998779297, 88.932, 89.53199998535156, 88.79199997802735, 89.7279999975586, 89.23999999511719, 89.05599999511719, 90.08399999511718, 89.1080000024414, 89.48800000244141, 90.06799999511719, 90.37199997314453, 90.04799998535157, 90.06799999511719, 90.07999999023437, 89.80799998046875, 90.45999998779297, 90.52399998046874, 90.47200000488282, 90.34799999267578, 90.78399999267579, 90.7719999975586, 90.83999998535157, 90.74399999755859, 90.77999997558594, 90.87599998046875, 90.90399997802734, 90.91199999267577, 90.89999997558594, 90.93199998046875, 91.00399997802734, 91.00399998046875, 91.02799998046875, 90.97199998535156, 91.04399998779297, 91.02799999267579, 91.05199998779297, 91.05599998535156, 91.03999999511718, 91.07599997558594, 91.09599997558594, 91.07199998779296, 91.09599998779296, 91.10799998535157, 91.05999999023437, 91.08799997314453, 91.03999997558594, 91.13999997314453, 91.03599997070313, 91.10399998535156, 91.07999997314454, 91.11999998291016, 91.10000000976562, 91.05599997070313, 90.78], 'cost_info': {'flops': 82.49409, 'params': 0.587386, 'latency': 0.017394404662282842, 'train_time': 9.476682742436727}}}\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 80 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 81 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 82 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 83 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 84 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 85 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 86 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 87 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 88 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 89 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 90 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 91 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 92 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 93 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 94 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 95 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 96 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 97 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 98 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:39:20 nl.defaults.trainer]: \u001b[0mEpoch 99 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 100, Anytime results: {'cifar10-valid': {'train_losses': [1.7746254404449462, 1.2525715937042237, 1.0205010886001586, 0.9041887921142578, 0.8123479414558411, 0.7364584699249268, 0.6741630848312378, 0.6267640244293213, 0.5884891187858582, 0.5503827807998657, 0.5296464962577819, 0.5095477344322205, 0.4777109776973724, 0.46621709315299986, 0.4492229323959351, 0.4391581182575226, 0.41857200494766234, 0.41713718710899356, 0.39895620523452757, 0.39085034116744993, 0.3904488983440399, 0.373608210849762, 0.36480088010787964, 0.36227050880432127, 0.35649055032730104, 0.3367236298084259, 0.3392516921710968, 0.3346933298683166, 0.3225389605140686, 0.33025471789360045, 0.31885675958633425, 0.31981347249031067, 0.30317366431236265, 0.31309911171913146, 0.3072423775959015, 0.29401487164497375, 0.29690482659339906, 0.2849114439201355, 0.2825883536720276, 0.27828021587371826, 0.28039682487487794, 0.2737912114095688, 0.26544114431381227, 0.26463417078018187, 0.2617005796146393, 0.2601780160331726, 0.25530390516281126, 0.2518099638414383, 0.24869031894683838, 0.2468419282054901, 0.2476457279396057, 0.24159966375350952, 0.23833100407600402, 0.2348895914554596, 0.232398039894104, 0.23142358202934266, 0.22846744904518126, 0.21901357915878297, 0.22316245243549346, 0.22272548840522766, 0.22078373539924623, 0.21504916458129883, 0.21110136355876924, 0.21320405406951903, 0.20293406505584716, 0.20283125587940215, 0.2041709073638916, 0.19773421635627747, 0.19889009864807128, 0.1906140609741211, 0.1887351924133301, 0.19090879890918733, 0.19261226412296295, 0.1828590488243103, 0.1787980257129669, 0.18291468800544738, 0.17475275500297546, 0.17200511803150176, 0.1749662488746643, 0.17150208112239837, 0.1687265163040161, 0.17420377104282378, 0.16103298442840577, 0.16325909739971162, 0.15561836744308472, 0.15403854426860808, 0.1571541468524933, 0.15451104388237, 0.14480088228702545, 0.13443238100528718, 0.14081464869976043, 0.14170886375427247, 0.13764053753852845, 0.14171770803928374, 0.14043696076631546, 0.13193515920162202, 0.1384855412864685, 0.12902787802696228, 0.13071472544670104, 0.12137279039859772, 0.1237334413933754, 0.12061486110687256, 0.11273883316755295, 0.1253305329990387, 0.10924769383668899, 0.10911147862911225, 0.11562112350940704, 0.10475705012798309, 0.10070889367580414, 0.1055792672920227, 0.10370195034027099, 0.09979624215841293, 0.09613510760307312, 0.0906841297340393, 0.09373684048652649, 0.08760787142038345, 0.08393638427257538, 0.08264624837875366, 0.08651380552768707, 0.07866799503326416, 0.07234020408987998, 0.0711566081237793, 0.07441978561401368, 0.06602694724798203, 0.07517099815845489, 0.06673867328464984, 0.058758132054805755, 0.057964024276733396, 0.06235463780641556, 0.05575353326439857, 0.051894831169843676, 0.04638636527776718, 0.0502672025513649, 0.05250447427034378, 0.04262666498184204, 0.04480634725093841, 0.04165797773599625, 0.0434769571018219, 0.038418945420980455, 0.03450439054727554, 0.035305368042588235, 0.035014791700839994, 0.03439501115083694, 0.031205382689833642, 0.027247063233852387, 0.02535728253275156, 0.029330354204177858, 0.025590090939998627, 0.016749941045045853, 0.020620152432322503, 0.021016789978146554, 0.017043285992741585, 0.015662926484942438, 0.013701772001981735, 0.012769260455965995, 0.011417203328609467, 0.011001510855555535, 0.006619351912140846, 0.008096077761873603, 0.007799483299404383, 0.0081732770550251, 0.0067813857555389405, 0.006534027804583311, 0.005591512687206268, 0.005985180187001824, 0.004235397043973207, 0.003967167109698057, 0.004052955968081951, 0.0033897193717956544, 0.0030407860757783057, 0.0028935578538477422, 0.00304538688685745, 0.0028457803250104188, 0.0023270040908455847, 0.002077452517300844, 0.0023477312177419664, 0.0024758788580447437, 0.0024956189342960717, 0.0019968066969513892, 0.0026833326147124173, 0.002210773143619299, 0.002054941701814532, 0.001915849809832871, 0.001974466485530138, 0.0018404873282462358, 0.0016433955763466657, 0.001937553005181253, 0.0017352377039194108, 0.0017995360084623099, 0.0019928793147578837, 0.0017312279224768281, 0.0014986567307636142, 0.0016601075265184045, 0.00208857716538012, 0.0018482246779650449, 0.00170278529971838, 0.0017075534347072243, 0.0017847442341595889, 0.0015362979980558158, 0.0018243489837273955], 'eval_losses': [1.7004167099761962, 1.2640720648956298, 1.1260783890151977, 1.167028021697998, 1.138815598526001, 1.046353260154724, 0.8218274205207825, 0.997259196395874, 0.8635318907928466, 0.7336437378692627, 0.7437615155982972, 0.7468032462310791, 0.7344474097633362, 0.7467612626647949, 0.8481156837272644, 0.6279564411735534, 0.7176448118591309, 0.8004950892448426, 0.6628228933906555, 0.5957677000045777, 0.6927953131484985, 0.7332342207336425, 0.6403082070732117, 0.7456984884262085, 0.6115048058319091, 0.6504589539909362, 0.6663137049674988, 0.7057497912025452, 0.6305248817253113, 0.632772862701416, 0.7624817274284362, 0.543254351978302, 0.6806864162063598, 0.6177824017715454, 0.5389980775260925, 0.6397953797721863, 0.560062555141449, 0.7072728757667541, 0.8136304460716247, 0.620847117729187, 0.6324208123302459, 0.6037143187904358, 0.5745815641593933, 0.4938424517726898, 0.6989603466796875, 0.5070402376365661, 0.5867429835510254, 0.6726844787406921, 0.7395950947570801, 0.7267618775367737, 0.7175866047859192, 0.5458885543060302, 0.6356919926452637, 0.6179738328170776, 0.5608704095363617, 0.6791090923881531, 0.7380701489067077, 0.6739645804786683, 0.5942101516151428, 0.8164201127624512, 0.7452011046028137, 0.7390241236686707, 0.6843553509712219, 0.6064271252250671, 0.8003216227912903, 0.5449528525352478, 0.5140533643722535, 0.647411085357666, 0.5758555371379852, 0.6981896110534668, 0.6432808949661255, 0.6219934247970581, 0.5505880363082886, 0.5291692859840393, 0.5924714015197754, 0.6320746515274048, 0.7140037968254089, 0.5236182795906067, 0.48174719415664674, 0.6173274262237549, 0.6041679553318023, 0.4672905652332306, 0.6286126975631714, 0.4608450119781494, 0.7094485459327697, 0.6815414708328247, 0.5702635599327087, 0.6062382802391052, 0.6579453928947449, 0.5664668649101258, 0.539786413116455, 0.6447139527130127, 0.538816554813385, 0.5575917622947693, 0.5069919419193267, 0.5117909422683716, 0.5118781038284301, 0.4982229266357422, 0.6083105189323426, 0.5793051228904724, 0.7671536774444581, 0.570645072889328, 0.6245588023757934, 0.5943541495704651, 0.577113770942688, 0.5988013249778747, 0.5411356259918213, 0.6576287629318237, 0.4925712329673767, 0.5643642643928528, 0.4961236543941498, 0.4942912080001831, 0.5766916935729981, 0.525230995054245, 0.5198735524654389, 0.4664132689857483, 0.5806890152454376, 0.4978510242462158, 0.5211024802970886, 0.5624003765296937, 0.4864869812393188, 0.5404220580863953, 0.67064609790802, 0.5391317514133454, 0.5065233495330811, 0.487877036857605, 0.48500618773460386, 0.4984992779922485, 0.4898747313117981, 0.5495070009803772, 0.49451827681541444, 0.4935645276260376, 0.5243667325019836, 0.4801720001888275, 0.496932391872406, 0.5161631118679046, 0.47474053245544434, 0.5574271750640869, 0.4728213084602356, 0.4604569463634491, 0.4875291523742676, 0.4989668164253235, 0.4845734143638611, 0.4789671956443787, 0.4966791892814636, 0.47059591999053957, 0.5252741628742218, 0.4803629207801819, 0.4614901226806641, 0.49611511160850524, 0.4358408811378479, 0.48612382457733155, 0.48724539588928223, 0.44330364521980287, 0.5029443155288696, 0.46430020725250243, 0.4678618911075592, 0.44827442228794095, 0.46440804655075074, 0.46001242347717286, 0.463009759721756, 0.48400899085044863, 0.4463294166660309, 0.44851717462539675, 0.4446151565551758, 0.4630494070243835, 0.43449869334220886, 0.4431028169250488, 0.43825167273521426, 0.4425428218078613, 0.4443647616291046, 0.43404180862426756, 0.43483548391342164, 0.43881195081710817, 0.4369903937959671, 0.4347187344837189, 0.43359984853744504, 0.43702171206474305, 0.43538841225624086, 0.4349768181419373, 0.42986678256988525, 0.42855164794921874, 0.4285649630355835, 0.4318992595672607, 0.4362735063934326, 0.42980637818336487, 0.4323894614028931, 0.43400580436706543, 0.4298272946166992, 0.43184122931480406, 0.4287837957191467, 0.429223907327652, 0.4288473167324066, 0.4289644967794418, 0.43249841203689576, 0.4302399096107483, 0.4318051530170441, 0.4294998967933655, 0.4281154341125488, 0.4298875627088547, 0.43989779443740845], 'train_acc1es': [33.08799999145508, 54.035999986572264, 63.092000007324216, 67.42800001464843, 70.89200001464843, 73.75199997558593, 76.36399999267579, 78.0159999975586, 79.39599998779296, 80.92399998779297, 81.59600000976563, 82.15600001464844, 83.53999997802734, 83.66400001708985, 84.26799997070313, 84.75200000488282, 85.29599997314453, 85.47599998291015, 86.00800000732421, 86.36799999267578, 86.50400001220703, 87.00000000976563, 87.19999999511718, 87.29199999755859, 87.60399999023437, 88.34799999755859, 88.044, 88.54800000732422, 88.59599999511718, 88.57199999755859, 88.85600000732421, 88.74800000488281, 89.31200000732422, 89.01599999023438, 89.07599999023438, 89.80000000244141, 89.70799999267578, 90.04799998779296, 90.188, 90.32799999267579, 90.23999999267578, 90.57999998535156, 90.8360000048828, 90.78400000488281, 90.80799999023438, 90.78399999267579, 91.04399998779297, 91.35999999267578, 91.38399999023437, 91.41600001464843, 91.42799997802734, 91.78799998535156, 91.89999997314453, 91.73999998291016, 91.87199997070313, 91.98799998291015, 92.15599999023438, 92.45999998291016, 92.16799997558594, 92.01999997558593, 92.26399997802734, 92.51599998046875, 92.50399998291016, 92.55199999511719, 93.03999999511718, 92.87999998291015, 92.71599999023438, 93.20799998291015, 93.00399999267579, 93.45200001220704, 93.29199999267578, 93.40799997802735, 93.35999997070313, 93.57199997802735, 93.92799998535156, 93.57999997314454, 93.89599999267578, 93.94399998779296, 94.04799999267578, 94.06399997314453, 94.12000001953125, 93.97999997070312, 94.46799998046875, 94.39600001953124, 94.59199998291015, 94.63599997558593, 94.45599997314453, 94.74400001953126, 95.10000001708984, 95.42399998291016, 95.18799997558594, 95.03200001708984, 95.19999997802735, 95.03199997314454, 95.05200000976562, 95.34799997070313, 95.16399997558594, 95.46800001953125, 95.54400001953125, 95.84800000976563, 95.82000000732423, 95.96400001953126, 96.19600001708984, 95.67199997070313, 96.34800000732422, 96.21999997070313, 95.99199998046875, 96.60000001220703, 96.57199997070313, 96.55600001708984, 96.46399997558593, 96.53200001220704, 96.71600001953125, 97.05600001953125, 96.74800001708985, 97.08000001464843, 97.10000000976562, 97.23600001464844, 97.07600001464844, 97.33599997314452, 97.63600000488282, 97.64000001220703, 97.52000000976562, 97.80800000976562, 97.59600001464844, 97.75600000488281, 98.12400000976562, 98.12000000488281, 98.02400001708985, 98.11600001464844, 98.39600000244141, 98.552, 98.40800001220703, 98.30400001220703, 98.6240000024414, 98.56800000976563, 98.67600000976563, 98.59200000732422, 98.796, 98.92400000488281, 98.9600000024414, 98.85600000488282, 98.87600000732422, 99.08800000488282, 99.21600000732421, 99.228, 99.0960000024414, 99.20400000488281, 99.51200000732422, 99.376, 99.3400000024414, 99.48800000244141, 99.592, 99.67600000244141, 99.664, 99.7120000024414, 99.7160000024414, 99.87600000488281, 99.788, 99.824, 99.792, 99.84, 99.864, 99.9, 99.872, 99.936, 99.92, 99.948, 99.948, 99.968, 99.956, 99.952, 99.956, 99.98, 99.976, 99.98, 99.956, 99.972, 99.988, 99.96, 99.976, 99.976, 99.98, 99.968, 99.98, 99.996, 99.988, 99.992, 99.988, 99.972, 99.992, 99.992, 99.988, 99.984, 99.984, 99.988, 99.988, 99.992, 99.996, 99.984], 'eval_acc1es': [38.02000000488281, 54.33600000854492, 60.659999990234375, 61.90399999511719, 62.59599998779297, 64.3439999975586, 72.49999997314453, 68.67599998291016, 72.12400001464843, 75.79600000976562, 75.73199998779297, 76.05599997558593, 76.29199998535157, 76.52799998291016, 72.73999997802734, 79.50399997314453, 76.89600000732422, 75.21199999267579, 78.49999998779298, 80.34399998291016, 78.36399997802734, 76.68799999267578, 80.27999998291016, 76.54399998779297, 80.81200001464843, 79.79199999023437, 78.99199997802734, 78.58400001708985, 80.69599997558593, 81.21999997314452, 77.53199997558593, 81.97199998535156, 78.39199998779297, 80.3800000024414, 82.65200001708985, 80.69599997558593, 82.19999998046875, 79.64000001464844, 76.52800000976562, 81.10399998535156, 79.78399997558594, 81.75200001708984, 82.13600001953125, 84.46000001464844, 79.72799999267578, 83.65200001953124, 81.77199998535156, 80.62399997802734, 79.35199999267579, 79.01599997802734, 78.37199999511719, 83.50399997802734, 81.21600001953125, 80.60800001708985, 83.1440000024414, 79.96399997802735, 79.95999999023438, 80.44, 82.98400001464844, 77.24399997802735, 79.16399997558594, 79.61600001953126, 79.49999998046874, 82.19599998535156, 78.59199997314452, 84.08800000732423, 84.59200001953126, 81.97599998291015, 83.55999999755859, 79.70799998046876, 82.45600001708985, 83.08000001220704, 83.20799997314454, 83.82400001708984, 83.16799997558594, 81.95600001708985, 80.29600001953125, 85.19599997070313, 85.672, 83.08400000488281, 83.76000000732422, 85.99200001220703, 82.89999997314453, 86.01600001220703, 80.7999999975586, 82.30399997070313, 84.46000001464844, 83.23199998046876, 82.24000001220703, 84.59200000732422, 85.10000001464844, 82.46400000976563, 84.98799997070313, 84.39199997558593, 85.90799999267578, 85.46000001708984, 85.64399998291016, 85.62400000976562, 83.42800001708984, 83.92799999023437, 80.86000001708985, 84.85600000976562, 83.54399997558593, 83.764, 84.74400001220702, 84.53199997070313, 85.61599998535156, 83.41600001953125, 86.46400001708984, 84.69599999023437, 86.68400000488282, 86.50800000488282, 85.12399997070312, 86.29999998779297, 86.11999999511718, 87.4560000024414, 84.8839999951172, 87.47999999023438, 86.42400001953125, 85.50800001953125, 87.10000000488282, 86.24800000976562, 84.23999999511719, 86.55999999755859, 87.06800000976563, 87.36400000488281, 87.59999999511719, 87.46800001464844, 87.67200001464843, 87.07200001220703, 87.72799999267578, 87.90799999267578, 87.10000001708984, 87.868, 87.87199998779298, 87.524, 88.60399999755859, 86.51200001464844, 88.4839999975586, 89.03199999023437, 88.69999999267579, 88.07600001464844, 88.62800000732422, 88.7759999975586, 88.57200000488281, 89.184, 88.18399998779297, 88.932, 89.53199998535156, 88.79199997802735, 89.7279999975586, 89.23999999511719, 89.05599999511719, 90.08399999511718, 89.1080000024414, 89.48800000244141, 90.06799999511719, 90.37199997314453, 90.04799998535157, 90.06799999511719, 90.07999999023437, 89.80799998046875, 90.45999998779297, 90.52399998046874, 90.47200000488282, 90.34799999267578, 90.78399999267579, 90.7719999975586, 90.83999998535157, 90.74399999755859, 90.77999997558594, 90.87599998046875, 90.90399997802734, 90.91199999267577, 90.89999997558594, 90.93199998046875, 91.00399997802734, 91.00399998046875, 91.02799998046875, 90.97199998535156, 91.04399998779297, 91.02799999267579, 91.05199998779297, 91.05599998535156, 91.03999999511718, 91.07599997558594, 91.09599997558594, 91.07199998779296, 91.09599998779296, 91.10799998535157, 91.05999999023437, 91.08799997314453, 91.03999997558594, 91.13999997314453, 91.03599997070313, 91.10399998535156, 91.07999997314454, 91.11999998291016, 91.10000000976562, 91.05599997070313, 90.78], 'cost_info': {'flops': 82.49409, 'params': 0.587386, 'latency': 0.017394404662282842, 'train_time': 9.476682742436727}}}\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 100 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 101 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 102 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.78000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 103 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 104 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 105 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 106 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 107 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 108 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 109 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 110 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 111 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 112 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 113 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 114 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 115 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 116 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 117 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 118 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:40:08 nl.defaults.trainer]: \u001b[0mEpoch 119 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 120, Anytime results: {'cifar10-valid': {'train_losses': [1.813578914604187, 1.375085512084961, 1.1382878940963745, 0.9621319083976746, 0.862207123966217, 0.7617532536125183, 0.6960988823318481, 0.6416646764564514, 0.6028365447616577, 0.5783322171020507, 0.5468255836486816, 0.5167316392326355, 0.50389789645195, 0.480193195066452, 0.4703355005168915, 0.4532011636543274, 0.4404766054725647, 0.4249968845939636, 0.4173572106075287, 0.39862349851608275, 0.3997572455596924, 0.3922178601074219, 0.37923961587905886, 0.37551175874710085, 0.371239254989624, 0.360505373210907, 0.3542351379966736, 0.3508215751552582, 0.34175008977890015, 0.34312157720565795, 0.3335299086856842, 0.33312971104621886, 0.3240192581176758, 0.31405843797683713, 0.31282732993125917, 0.3129633214569092, 0.3093061092567444, 0.2963112823867798, 0.29557503288269044, 0.29502460523605345, 0.28520991539001467, 0.2897753960227966, 0.28165626730918886, 0.2761667509937286, 0.27480600978851316, 0.27863602599143983, 0.2662856970310211, 0.2702925876235962, 0.2640638767051697, 0.26033864000320434, 0.2587759704875946, 0.2582172531032562, 0.2598734571933746, 0.24909213945388795, 0.25055396521568296, 0.2446175438117981, 0.2351680696105957, 0.23934589011669158, 0.23868910919189454, 0.2372131815338135, 0.22480380046844484, 0.22525944798469544, 0.22112522306919097, 0.21883974040985107, 0.21423383518695832, 0.22548242789268494, 0.20978444765090942, 0.21710567967414857, 0.21254395008087157, 0.20369471448898316, 0.20477642362594606, 0.2046469808769226, 0.19940260817050934, 0.19609095338344573, 0.19682635208129884, 0.1882415479040146, 0.1866137414741516, 0.18475500873088838, 0.17792527112960815, 0.19063886136054992, 0.17594724514961244, 0.17903554495573043, 0.17064522906303406, 0.1851587593317032, 0.168072231259346, 0.1643205472278595, 0.1695693263244629, 0.1653488435125351, 0.15248643101215362, 0.15653011132717132, 0.15047078259944915, 0.15359570139884948, 0.15374530082702637, 0.15252107415199279, 0.14343497542858125, 0.13784610998153687, 0.14334930797576903, 0.13761203592777252, 0.1394188969373703, 0.13788317673683168, 0.13204672792434693, 0.12955346121788025, 0.12381967745304108, 0.1273166833114624, 0.1265234402322769, 0.11436215786457062, 0.12640361583709717, 0.10792558992385864, 0.11099669610023498, 0.10873861113548279, 0.10899115583658218, 0.10898271660089492, 0.105892713367939, 0.10064567738056183, 0.09892228623867035, 0.09343521584987641, 0.0924743539428711, 0.09331673178195954, 0.08470275827407837, 0.08682290690660477, 0.08565762790203095, 0.08406598603248597, 0.08253227596759796, 0.07552571233272552, 0.08026977212905884, 0.07036632357120513, 0.07258001209497451, 0.06972358108878135, 0.06536100054502487, 0.06831513055443764, 0.06673602684497833, 0.06142414780378342, 0.05391410364508629, 0.05616509069681168, 0.052889454035758975, 0.049771042034626005, 0.049040126779079436, 0.04947056351661682, 0.04209215601682663, 0.04271879445791245, 0.03874612349867821, 0.03777475172281265, 0.03797348924040794, 0.03684933309793472, 0.03377732513189316, 0.030768196781873702, 0.0340382342839241, 0.02772801495671272, 0.027090003516674042, 0.022277071015834808, 0.022307028062939643, 0.023036027194261552, 0.01865836918473244, 0.01749191312968731, 0.017475750043690206, 0.013347296935915947, 0.013109609518647194, 0.012530383757352829, 0.011164135592579841, 0.010203858543783426, 0.009858894967585801, 0.010853964072167873, 0.0074779535863175985, 0.006742933603525162, 0.006806282175630331, 0.008788819402456283, 0.005838904247432947, 0.005578986684679985, 0.005008951893076301, 0.004794767541140318, 0.004187784242331982, 0.003925555639266968, 0.004331494293734431, 0.003552300119623542, 0.0035450145529210566, 0.0031864269149303437, 0.003788628484159708, 0.0032570449827238916, 0.0028634048559516667, 0.0024951376724243165, 0.0026710034469515087, 0.0025975958444178103, 0.0025276920315623285, 0.002533317032121122, 0.002292304762750864, 0.00213106379494071, 0.002345026520937681, 0.002152119693867862, 0.00220800601022318, 0.0019550023267418145, 0.002159499997496605, 0.002229716806448996, 0.0020964937871694564, 0.0018842083736509085, 0.0021412251855432987, 0.0019007790467888118, 0.001960073574781418, 0.001869560870938003, 0.002091606602743268, 0.0019707122030854225], 'eval_losses': [2.7770329852294924, 1.3317027779388428, 1.5989022208023072, 1.2371610392379762, 1.6954035946273804, 1.2668077746582032, 0.9198338829040528, 1.0901482295227052, 0.7177742719459533, 0.7943678004646302, 0.6991302251625061, 0.811405728302002, 0.8467027216720581, 0.7895524572753906, 0.7012435438537598, 0.7864242402839661, 0.6525066874694824, 0.7187118339538574, 0.8023443943595886, 0.7241259594726562, 0.9622642405319214, 0.9012036827850342, 0.8655216027832031, 0.7547226168060303, 0.7647245067787171, 0.63730341796875, 0.8258360938835144, 0.641546701335907, 0.6145756422996521, 0.6897222831535339, 0.5755782868576049, 0.8195246295166015, 0.5244025342941284, 0.6718606747245789, 0.5401989694023133, 0.8249639940452576, 0.7415823185539245, 0.6894496656036377, 0.7024648052406312, 0.5679599473953247, 0.7244415075111389, 0.6136970628547669, 0.5524110034847259, 0.6637134241294861, 0.6142680104255677, 0.7573993234443664, 0.6493376180839538, 0.5987946834945679, 0.6163347816848755, 0.8108815986442566, 0.5325242105102539, 0.680179905834198, 0.5283937713432312, 0.7302488035202026, 0.6103225261116028, 0.5239436099624634, 0.705709838256836, 0.5845587982559204, 0.5717593933868408, 0.5652983058738709, 0.6723647736930847, 0.568752654876709, 0.521654092760086, 0.924004627609253, 0.5743097490692138, 0.5562198945808411, 0.6394166798210144, 0.6682093679237365, 0.5306243863105774, 0.49061835329055786, 0.5299289615821838, 0.6885828894805908, 0.5411702075386048, 0.5483574610137939, 0.6068382260322571, 0.668465132522583, 0.5392415371704101, 0.5274190531253815, 0.534455364189148, 0.5723560587692261, 0.6548462141227722, 0.6001446495246887, 0.6726788217639923, 0.574045663280487, 0.6391570588684082, 0.6097074349975586, 0.45517286600112916, 0.4797070222854614, 0.5235885754299164, 0.6666484070396423, 0.5880852006912232, 0.47340559052467346, 0.6254756129837036, 0.558291533241272, 0.5440644855308533, 0.560938609085083, 0.5401667181968689, 0.7751417042732239, 0.600517382068634, 0.5507582465744019, 0.5224009158706665, 0.6430349178695679, 0.5000030417251586, 0.4943157803249359, 0.559876114025116, 0.5206498579978943, 0.4684784734535217, 0.5549166851329803, 0.5299840214157104, 0.5529828047752381, 0.48928591846466063, 0.5007693557643891, 0.4766637505722046, 0.4852993103027344, 0.5423551260471344, 0.5539629400634766, 0.4738146502494812, 0.6519482008171081, 0.5296464585494995, 0.5129101769447326, 0.5181727746582031, 0.5267564272212982, 0.4362519080066681, 0.46894978540420534, 0.5299262034225464, 0.6563997418022156, 0.5247973093795777, 0.5018094155025482, 0.5614937986755371, 0.499577211894989, 0.5507646076965332, 0.5107169623756409, 0.4808931051635742, 0.4839380470275879, 0.4757007504749298, 0.49333270359039305, 0.5092339842033387, 0.46814728907585146, 0.5155842344093323, 0.4593089134216309, 0.5038433455133439, 0.48565652669906617, 0.4906182969856262, 0.4753928746795654, 0.5173720743465423, 0.4832147206783295, 0.48374536905288695, 0.4659645278930664, 0.5058171892166138, 0.495892733001709, 0.43904805791854856, 0.4599167072868347, 0.46061240756988525, 0.46061728939056396, 0.45256642459869384, 0.44682694774627685, 0.45980399277687073, 0.46036244896888734, 0.4446504336547852, 0.45641547053337095, 0.4496014758872986, 0.44808739212989807, 0.4380212150096893, 0.4523743890953064, 0.4483520462799072, 0.43972219219207764, 0.4498318808555603, 0.4427395128822327, 0.44266229627132414, 0.44190420981407164, 0.44100101215362547, 0.447216741733551, 0.43689802835464475, 0.43478747034072873, 0.43540094310760497, 0.43863728043556216, 0.43078851943969726, 0.4361747253513336, 0.4324694058609009, 0.43388379932403565, 0.4332809908390045, 0.4334468923377991, 0.42950780173301695, 0.42864004475593565, 0.43057035345077516, 0.4274860317897797, 0.4312501430606842, 0.43110426800727847, 0.4301257569503784, 0.4293438516139984, 0.42917567519187927, 0.43183779952049256, 0.42817570869445803, 0.4301721441078186, 0.42712184247016904, 0.4336481524467468, 0.4305367309188843, 0.426312005572319, 0.42976499336242674, 0.428797401638031, 0.4395636076927185], 'train_acc1es': [31.639999995117186, 49.13599998413086, 58.619999990234376, 65.42000001953124, 69.45599998535157, 72.69599999511719, 75.6719999975586, 77.752, 78.87999998779297, 79.82799998046875, 81.01999997314454, 81.97199999511719, 82.63200001220703, 83.26799998779296, 83.75600000976563, 84.05600001708984, 84.6919999975586, 85.31600000488281, 85.548, 86.12400001708984, 86.1679999975586, 86.27200001220703, 87.09999998535156, 86.90400000488282, 87.23599999267579, 87.55599999267578, 87.7559999951172, 87.67199997314454, 88.23200000244141, 88.05200001464844, 88.23999998291016, 88.25999997070312, 88.86399999267579, 89.03199998779297, 89.39199999511719, 89.01599998046875, 89.20800000244141, 89.64799998779297, 89.61200000732421, 89.67999999023438, 89.99599999023438, 89.88000000488282, 90.1680000024414, 90.27199999023438, 90.49599998535156, 90.352, 90.78799999511719, 90.66799998779297, 90.95599999267579, 91.07199999023437, 91.01599998779297, 91.06399997802734, 90.83599999511719, 91.43599997558594, 91.21599998779297, 91.592, 91.83599999511719, 91.63199998046875, 91.76799998779296, 91.7, 92.19199998046875, 92.24800001953125, 92.33200001953125, 92.55599999755859, 92.38799998046875, 91.93200000244141, 92.72799999511719, 92.38800000488281, 92.63999999023437, 92.88399998535156, 93.05599997314454, 92.85999998291015, 93.12399998291015, 93.20000001953125, 93.11999998046875, 93.54399997802734, 93.56799998779297, 93.65199997070313, 93.84399997802734, 93.34399997070312, 94.06799997558593, 93.76400001953125, 94.04799998779296, 93.54399998779297, 94.30799998046875, 94.27599999023437, 94.11199998291016, 94.30800000976562, 94.71199998291016, 94.59999997802734, 94.73199997558594, 94.74400001953126, 94.63200001953125, 94.60000001708984, 95.06000001220703, 95.27599997314454, 95.03999997070312, 95.31599997802735, 95.15199997802735, 95.18799998046875, 95.42400000976562, 95.55600001220704, 95.73999998046875, 95.66399997070313, 95.58000001953125, 96.08799997558594, 95.55199997314453, 96.28399997070312, 96.14399997070312, 96.34399997802734, 96.24400001708985, 96.06400001464844, 96.42800000976563, 96.55200000976562, 96.58000001708984, 96.80800001220703, 96.88400001708985, 96.93200001464844, 97.17600000976563, 97.00000000732422, 97.19600001708984, 97.10000001708984, 97.15600001708984, 97.43600001708984, 97.28000000976563, 97.60400000976563, 97.48800001953126, 97.72800000732421, 97.76400001708984, 97.7640000024414, 97.75999997314453, 97.89600000732422, 98.28400000732422, 98.10800000976562, 98.35600000732421, 98.37600001953125, 98.42400000976562, 98.30400000732422, 98.64000001708985, 98.63600001708984, 98.81200000976563, 98.78000000976563, 98.73200000244141, 98.83200000732423, 98.95600000732422, 99.04800000488281, 98.99200000732422, 99.11200000732421, 99.15600000732422, 99.3200000024414, 99.31200000244141, 99.34000000488281, 99.49600000488282, 99.476, 99.51200000244141, 99.6480000024414, 99.62, 99.64000000244141, 99.664, 99.748, 99.736, 99.692, 99.848, 99.8680000024414, 99.836, 99.7720000024414, 99.872, 99.86800000488282, 99.908, 99.916, 99.936, 99.928, 99.912, 99.932, 99.944, 99.9480000024414, 99.932, 99.944, 99.948, 99.964, 99.952, 99.968, 99.972, 99.976, 99.968, 99.972, 99.98, 99.968, 99.976, 99.988, 99.98, 99.98, 99.972, 99.984, 99.976, 99.988, 99.992, 99.988, 99.968, 99.984], 'eval_acc1es': [26.91200000061035, 52.24799998413086, 47.99599999145508, 57.268, 51.835999997558595, 63.44000000366211, 68.55199997802734, 66.74399998413087, 75.4239999975586, 73.58399997558594, 76.42400001708984, 73.51599999511718, 70.94400000488281, 74.62399999267578, 76.93600001220703, 76.13600000732421, 78.68799998779296, 77.63999997802735, 74.91199997558594, 76.91599999267578, 72.41599998779297, 73.55600000732422, 73.77600000976562, 76.59599998291016, 77.01599998779297, 80.28799997558593, 74.10799999267579, 80.35199997314453, 80.75199999511719, 78.31199998535156, 81.43599997558594, 75.24400001953126, 82.22000000976563, 79.16799998291016, 82.41199997802734, 75.35199998291016, 77.58799999023438, 79.53999999267577, 78.99999998779298, 82.27200001708984, 77.9079999951172, 80.82399998535156, 82.82400000244141, 79.67999998535156, 80.86399997070312, 78.31599998535157, 80.52799997802734, 81.5199999975586, 80.93599999023438, 76.10400000732422, 83.388, 79.38399998046874, 83.64000001220703, 79.02399997802735, 81.49199998779297, 83.65600000488281, 79.96799999267579, 82.55600000488282, 83.46399997314452, 82.69999999023437, 81.84799998291015, 83.27200000732422, 84.17200001708984, 74.26000000732422, 83.29199997558594, 83.32000001464844, 81.46399998291015, 80.30399998779296, 84.37599997802734, 84.69999997070312, 83.64399997558594, 80.53600000976563, 83.78799997070313, 83.49600001953125, 82.33999997802735, 80.73199997558594, 83.72000001220704, 84.58399999267579, 84.42400001708984, 82.79999998535156, 82.02800001464844, 82.33199997558594, 80.94799997070312, 83.75200000732421, 82.70399998291016, 82.61600000976563, 86.08799997314453, 85.7080000048828, 85.07999998535156, 82.09200001708984, 83.16000000976562, 85.99599998779297, 83.25599997558594, 83.98000001953125, 84.78800000244141, 84.27200001708984, 85.00400001220703, 80.20000001464844, 82.99600001220703, 84.26800000732422, 85.26800001953124, 83.00400001220703, 85.73600000732422, 85.956, 84.53599997314453, 85.96000000488282, 86.54800000488281, 85.3280000024414, 85.52400000732422, 85.25200001220703, 86.60799999267579, 86.4719999975586, 86.716, 86.78399999267579, 85.83599999511719, 85.26800001953124, 86.81600000976563, 83.75599997070313, 86.0199999975586, 86.63599999267578, 86.38399999023437, 85.85599999267578, 88.40800000488281, 87.84000001464844, 86.29600001464844, 84.72800001464844, 87.0200000024414, 87.41999999755859, 85.83600000244141, 87.27199998779297, 86.632, 86.90399999511719, 88.01999999023438, 87.83599999755859, 88.07199998535157, 87.49199998046875, 87.60800000976562, 88.43999998779297, 87.70799999755859, 88.46000001464844, 88.10799997314453, 88.44799998535156, 88.29599997314453, 88.5239999951172, 87.75600000732422, 88.46, 88.60400000976563, 89.14799997070313, 88.14400001464844, 88.6479999975586, 89.69999999511718, 89.28000000488281, 89.49199999023438, 89.41599999023437, 89.60799998535157, 89.672, 89.79199997802735, 90.35999999023437, 90.2120000024414, 90.05199998535156, 90.13999998779298, 90.21199997070312, 90.48799998535156, 90.30799999023438, 90.32399999755859, 90.56399997558594, 90.30799999023438, 90.48000000976562, 90.51200001953126, 90.60399998779297, 90.73599997558594, 90.56799997802734, 90.72399997802735, 90.79999997802734, 90.67999999511719, 90.75999998046875, 90.94800000488281, 90.88799997802734, 90.93599998779297, 90.99199997314453, 90.97999998291016, 91.04799998535157, 91.06399998779297, 91.00399998046875, 91.11599997314453, 91.05199997802734, 91.1319999975586, 91.08399999023437, 91.088, 91.13999998046874, 91.09999999267578, 91.15999999511719, 91.11999997070312, 91.07199999511718, 91.15599997314453, 91.06799997802734, 91.09599999267579, 91.11599997802735, 91.17199998779297, 91.09599997558594, 90.87], 'cost_info': {'flops': 86.42625, 'params': 0.615386, 'latency': 0.018924427659888016, 'train_time': 12.369429608186087}}}\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 120 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 121 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 122 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 123 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 124 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 125 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 126 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 127 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 128 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 129 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 130 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 131 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 132 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 133 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 134 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 135 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 136 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 137 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 138 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:02 nl.defaults.trainer]: \u001b[0mEpoch 139 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 140, Anytime results: {'cifar10-valid': {'train_losses': [1.813578914604187, 1.375085512084961, 1.1382878940963745, 0.9621319083976746, 0.862207123966217, 0.7617532536125183, 0.6960988823318481, 0.6416646764564514, 0.6028365447616577, 0.5783322171020507, 0.5468255836486816, 0.5167316392326355, 0.50389789645195, 0.480193195066452, 0.4703355005168915, 0.4532011636543274, 0.4404766054725647, 0.4249968845939636, 0.4173572106075287, 0.39862349851608275, 0.3997572455596924, 0.3922178601074219, 0.37923961587905886, 0.37551175874710085, 0.371239254989624, 0.360505373210907, 0.3542351379966736, 0.3508215751552582, 0.34175008977890015, 0.34312157720565795, 0.3335299086856842, 0.33312971104621886, 0.3240192581176758, 0.31405843797683713, 0.31282732993125917, 0.3129633214569092, 0.3093061092567444, 0.2963112823867798, 0.29557503288269044, 0.29502460523605345, 0.28520991539001467, 0.2897753960227966, 0.28165626730918886, 0.2761667509937286, 0.27480600978851316, 0.27863602599143983, 0.2662856970310211, 0.2702925876235962, 0.2640638767051697, 0.26033864000320434, 0.2587759704875946, 0.2582172531032562, 0.2598734571933746, 0.24909213945388795, 0.25055396521568296, 0.2446175438117981, 0.2351680696105957, 0.23934589011669158, 0.23868910919189454, 0.2372131815338135, 0.22480380046844484, 0.22525944798469544, 0.22112522306919097, 0.21883974040985107, 0.21423383518695832, 0.22548242789268494, 0.20978444765090942, 0.21710567967414857, 0.21254395008087157, 0.20369471448898316, 0.20477642362594606, 0.2046469808769226, 0.19940260817050934, 0.19609095338344573, 0.19682635208129884, 0.1882415479040146, 0.1866137414741516, 0.18475500873088838, 0.17792527112960815, 0.19063886136054992, 0.17594724514961244, 0.17903554495573043, 0.17064522906303406, 0.1851587593317032, 0.168072231259346, 0.1643205472278595, 0.1695693263244629, 0.1653488435125351, 0.15248643101215362, 0.15653011132717132, 0.15047078259944915, 0.15359570139884948, 0.15374530082702637, 0.15252107415199279, 0.14343497542858125, 0.13784610998153687, 0.14334930797576903, 0.13761203592777252, 0.1394188969373703, 0.13788317673683168, 0.13204672792434693, 0.12955346121788025, 0.12381967745304108, 0.1273166833114624, 0.1265234402322769, 0.11436215786457062, 0.12640361583709717, 0.10792558992385864, 0.11099669610023498, 0.10873861113548279, 0.10899115583658218, 0.10898271660089492, 0.105892713367939, 0.10064567738056183, 0.09892228623867035, 0.09343521584987641, 0.0924743539428711, 0.09331673178195954, 0.08470275827407837, 0.08682290690660477, 0.08565762790203095, 0.08406598603248597, 0.08253227596759796, 0.07552571233272552, 0.08026977212905884, 0.07036632357120513, 0.07258001209497451, 0.06972358108878135, 0.06536100054502487, 0.06831513055443764, 0.06673602684497833, 0.06142414780378342, 0.05391410364508629, 0.05616509069681168, 0.052889454035758975, 0.049771042034626005, 0.049040126779079436, 0.04947056351661682, 0.04209215601682663, 0.04271879445791245, 0.03874612349867821, 0.03777475172281265, 0.03797348924040794, 0.03684933309793472, 0.03377732513189316, 0.030768196781873702, 0.0340382342839241, 0.02772801495671272, 0.027090003516674042, 0.022277071015834808, 0.022307028062939643, 0.023036027194261552, 0.01865836918473244, 0.01749191312968731, 0.017475750043690206, 0.013347296935915947, 0.013109609518647194, 0.012530383757352829, 0.011164135592579841, 0.010203858543783426, 0.009858894967585801, 0.010853964072167873, 0.0074779535863175985, 0.006742933603525162, 0.006806282175630331, 0.008788819402456283, 0.005838904247432947, 0.005578986684679985, 0.005008951893076301, 0.004794767541140318, 0.004187784242331982, 0.003925555639266968, 0.004331494293734431, 0.003552300119623542, 0.0035450145529210566, 0.0031864269149303437, 0.003788628484159708, 0.0032570449827238916, 0.0028634048559516667, 0.0024951376724243165, 0.0026710034469515087, 0.0025975958444178103, 0.0025276920315623285, 0.002533317032121122, 0.002292304762750864, 0.00213106379494071, 0.002345026520937681, 0.002152119693867862, 0.00220800601022318, 0.0019550023267418145, 0.002159499997496605, 0.002229716806448996, 0.0020964937871694564, 0.0018842083736509085, 0.0021412251855432987, 0.0019007790467888118, 0.001960073574781418, 0.001869560870938003, 0.002091606602743268, 0.0019707122030854225], 'eval_losses': [2.7770329852294924, 1.3317027779388428, 1.5989022208023072, 1.2371610392379762, 1.6954035946273804, 1.2668077746582032, 0.9198338829040528, 1.0901482295227052, 0.7177742719459533, 0.7943678004646302, 0.6991302251625061, 0.811405728302002, 0.8467027216720581, 0.7895524572753906, 0.7012435438537598, 0.7864242402839661, 0.6525066874694824, 0.7187118339538574, 0.8023443943595886, 0.7241259594726562, 0.9622642405319214, 0.9012036827850342, 0.8655216027832031, 0.7547226168060303, 0.7647245067787171, 0.63730341796875, 0.8258360938835144, 0.641546701335907, 0.6145756422996521, 0.6897222831535339, 0.5755782868576049, 0.8195246295166015, 0.5244025342941284, 0.6718606747245789, 0.5401989694023133, 0.8249639940452576, 0.7415823185539245, 0.6894496656036377, 0.7024648052406312, 0.5679599473953247, 0.7244415075111389, 0.6136970628547669, 0.5524110034847259, 0.6637134241294861, 0.6142680104255677, 0.7573993234443664, 0.6493376180839538, 0.5987946834945679, 0.6163347816848755, 0.8108815986442566, 0.5325242105102539, 0.680179905834198, 0.5283937713432312, 0.7302488035202026, 0.6103225261116028, 0.5239436099624634, 0.705709838256836, 0.5845587982559204, 0.5717593933868408, 0.5652983058738709, 0.6723647736930847, 0.568752654876709, 0.521654092760086, 0.924004627609253, 0.5743097490692138, 0.5562198945808411, 0.6394166798210144, 0.6682093679237365, 0.5306243863105774, 0.49061835329055786, 0.5299289615821838, 0.6885828894805908, 0.5411702075386048, 0.5483574610137939, 0.6068382260322571, 0.668465132522583, 0.5392415371704101, 0.5274190531253815, 0.534455364189148, 0.5723560587692261, 0.6548462141227722, 0.6001446495246887, 0.6726788217639923, 0.574045663280487, 0.6391570588684082, 0.6097074349975586, 0.45517286600112916, 0.4797070222854614, 0.5235885754299164, 0.6666484070396423, 0.5880852006912232, 0.47340559052467346, 0.6254756129837036, 0.558291533241272, 0.5440644855308533, 0.560938609085083, 0.5401667181968689, 0.7751417042732239, 0.600517382068634, 0.5507582465744019, 0.5224009158706665, 0.6430349178695679, 0.5000030417251586, 0.4943157803249359, 0.559876114025116, 0.5206498579978943, 0.4684784734535217, 0.5549166851329803, 0.5299840214157104, 0.5529828047752381, 0.48928591846466063, 0.5007693557643891, 0.4766637505722046, 0.4852993103027344, 0.5423551260471344, 0.5539629400634766, 0.4738146502494812, 0.6519482008171081, 0.5296464585494995, 0.5129101769447326, 0.5181727746582031, 0.5267564272212982, 0.4362519080066681, 0.46894978540420534, 0.5299262034225464, 0.6563997418022156, 0.5247973093795777, 0.5018094155025482, 0.5614937986755371, 0.499577211894989, 0.5507646076965332, 0.5107169623756409, 0.4808931051635742, 0.4839380470275879, 0.4757007504749298, 0.49333270359039305, 0.5092339842033387, 0.46814728907585146, 0.5155842344093323, 0.4593089134216309, 0.5038433455133439, 0.48565652669906617, 0.4906182969856262, 0.4753928746795654, 0.5173720743465423, 0.4832147206783295, 0.48374536905288695, 0.4659645278930664, 0.5058171892166138, 0.495892733001709, 0.43904805791854856, 0.4599167072868347, 0.46061240756988525, 0.46061728939056396, 0.45256642459869384, 0.44682694774627685, 0.45980399277687073, 0.46036244896888734, 0.4446504336547852, 0.45641547053337095, 0.4496014758872986, 0.44808739212989807, 0.4380212150096893, 0.4523743890953064, 0.4483520462799072, 0.43972219219207764, 0.4498318808555603, 0.4427395128822327, 0.44266229627132414, 0.44190420981407164, 0.44100101215362547, 0.447216741733551, 0.43689802835464475, 0.43478747034072873, 0.43540094310760497, 0.43863728043556216, 0.43078851943969726, 0.4361747253513336, 0.4324694058609009, 0.43388379932403565, 0.4332809908390045, 0.4334468923377991, 0.42950780173301695, 0.42864004475593565, 0.43057035345077516, 0.4274860317897797, 0.4312501430606842, 0.43110426800727847, 0.4301257569503784, 0.4293438516139984, 0.42917567519187927, 0.43183779952049256, 0.42817570869445803, 0.4301721441078186, 0.42712184247016904, 0.4336481524467468, 0.4305367309188843, 0.426312005572319, 0.42976499336242674, 0.428797401638031, 0.4395636076927185], 'train_acc1es': [31.639999995117186, 49.13599998413086, 58.619999990234376, 65.42000001953124, 69.45599998535157, 72.69599999511719, 75.6719999975586, 77.752, 78.87999998779297, 79.82799998046875, 81.01999997314454, 81.97199999511719, 82.63200001220703, 83.26799998779296, 83.75600000976563, 84.05600001708984, 84.6919999975586, 85.31600000488281, 85.548, 86.12400001708984, 86.1679999975586, 86.27200001220703, 87.09999998535156, 86.90400000488282, 87.23599999267579, 87.55599999267578, 87.7559999951172, 87.67199997314454, 88.23200000244141, 88.05200001464844, 88.23999998291016, 88.25999997070312, 88.86399999267579, 89.03199998779297, 89.39199999511719, 89.01599998046875, 89.20800000244141, 89.64799998779297, 89.61200000732421, 89.67999999023438, 89.99599999023438, 89.88000000488282, 90.1680000024414, 90.27199999023438, 90.49599998535156, 90.352, 90.78799999511719, 90.66799998779297, 90.95599999267579, 91.07199999023437, 91.01599998779297, 91.06399997802734, 90.83599999511719, 91.43599997558594, 91.21599998779297, 91.592, 91.83599999511719, 91.63199998046875, 91.76799998779296, 91.7, 92.19199998046875, 92.24800001953125, 92.33200001953125, 92.55599999755859, 92.38799998046875, 91.93200000244141, 92.72799999511719, 92.38800000488281, 92.63999999023437, 92.88399998535156, 93.05599997314454, 92.85999998291015, 93.12399998291015, 93.20000001953125, 93.11999998046875, 93.54399997802734, 93.56799998779297, 93.65199997070313, 93.84399997802734, 93.34399997070312, 94.06799997558593, 93.76400001953125, 94.04799998779296, 93.54399998779297, 94.30799998046875, 94.27599999023437, 94.11199998291016, 94.30800000976562, 94.71199998291016, 94.59999997802734, 94.73199997558594, 94.74400001953126, 94.63200001953125, 94.60000001708984, 95.06000001220703, 95.27599997314454, 95.03999997070312, 95.31599997802735, 95.15199997802735, 95.18799998046875, 95.42400000976562, 95.55600001220704, 95.73999998046875, 95.66399997070313, 95.58000001953125, 96.08799997558594, 95.55199997314453, 96.28399997070312, 96.14399997070312, 96.34399997802734, 96.24400001708985, 96.06400001464844, 96.42800000976563, 96.55200000976562, 96.58000001708984, 96.80800001220703, 96.88400001708985, 96.93200001464844, 97.17600000976563, 97.00000000732422, 97.19600001708984, 97.10000001708984, 97.15600001708984, 97.43600001708984, 97.28000000976563, 97.60400000976563, 97.48800001953126, 97.72800000732421, 97.76400001708984, 97.7640000024414, 97.75999997314453, 97.89600000732422, 98.28400000732422, 98.10800000976562, 98.35600000732421, 98.37600001953125, 98.42400000976562, 98.30400000732422, 98.64000001708985, 98.63600001708984, 98.81200000976563, 98.78000000976563, 98.73200000244141, 98.83200000732423, 98.95600000732422, 99.04800000488281, 98.99200000732422, 99.11200000732421, 99.15600000732422, 99.3200000024414, 99.31200000244141, 99.34000000488281, 99.49600000488282, 99.476, 99.51200000244141, 99.6480000024414, 99.62, 99.64000000244141, 99.664, 99.748, 99.736, 99.692, 99.848, 99.8680000024414, 99.836, 99.7720000024414, 99.872, 99.86800000488282, 99.908, 99.916, 99.936, 99.928, 99.912, 99.932, 99.944, 99.9480000024414, 99.932, 99.944, 99.948, 99.964, 99.952, 99.968, 99.972, 99.976, 99.968, 99.972, 99.98, 99.968, 99.976, 99.988, 99.98, 99.98, 99.972, 99.984, 99.976, 99.988, 99.992, 99.988, 99.968, 99.984], 'eval_acc1es': [26.91200000061035, 52.24799998413086, 47.99599999145508, 57.268, 51.835999997558595, 63.44000000366211, 68.55199997802734, 66.74399998413087, 75.4239999975586, 73.58399997558594, 76.42400001708984, 73.51599999511718, 70.94400000488281, 74.62399999267578, 76.93600001220703, 76.13600000732421, 78.68799998779296, 77.63999997802735, 74.91199997558594, 76.91599999267578, 72.41599998779297, 73.55600000732422, 73.77600000976562, 76.59599998291016, 77.01599998779297, 80.28799997558593, 74.10799999267579, 80.35199997314453, 80.75199999511719, 78.31199998535156, 81.43599997558594, 75.24400001953126, 82.22000000976563, 79.16799998291016, 82.41199997802734, 75.35199998291016, 77.58799999023438, 79.53999999267577, 78.99999998779298, 82.27200001708984, 77.9079999951172, 80.82399998535156, 82.82400000244141, 79.67999998535156, 80.86399997070312, 78.31599998535157, 80.52799997802734, 81.5199999975586, 80.93599999023438, 76.10400000732422, 83.388, 79.38399998046874, 83.64000001220703, 79.02399997802735, 81.49199998779297, 83.65600000488281, 79.96799999267579, 82.55600000488282, 83.46399997314452, 82.69999999023437, 81.84799998291015, 83.27200000732422, 84.17200001708984, 74.26000000732422, 83.29199997558594, 83.32000001464844, 81.46399998291015, 80.30399998779296, 84.37599997802734, 84.69999997070312, 83.64399997558594, 80.53600000976563, 83.78799997070313, 83.49600001953125, 82.33999997802735, 80.73199997558594, 83.72000001220704, 84.58399999267579, 84.42400001708984, 82.79999998535156, 82.02800001464844, 82.33199997558594, 80.94799997070312, 83.75200000732421, 82.70399998291016, 82.61600000976563, 86.08799997314453, 85.7080000048828, 85.07999998535156, 82.09200001708984, 83.16000000976562, 85.99599998779297, 83.25599997558594, 83.98000001953125, 84.78800000244141, 84.27200001708984, 85.00400001220703, 80.20000001464844, 82.99600001220703, 84.26800000732422, 85.26800001953124, 83.00400001220703, 85.73600000732422, 85.956, 84.53599997314453, 85.96000000488282, 86.54800000488281, 85.3280000024414, 85.52400000732422, 85.25200001220703, 86.60799999267579, 86.4719999975586, 86.716, 86.78399999267579, 85.83599999511719, 85.26800001953124, 86.81600000976563, 83.75599997070313, 86.0199999975586, 86.63599999267578, 86.38399999023437, 85.85599999267578, 88.40800000488281, 87.84000001464844, 86.29600001464844, 84.72800001464844, 87.0200000024414, 87.41999999755859, 85.83600000244141, 87.27199998779297, 86.632, 86.90399999511719, 88.01999999023438, 87.83599999755859, 88.07199998535157, 87.49199998046875, 87.60800000976562, 88.43999998779297, 87.70799999755859, 88.46000001464844, 88.10799997314453, 88.44799998535156, 88.29599997314453, 88.5239999951172, 87.75600000732422, 88.46, 88.60400000976563, 89.14799997070313, 88.14400001464844, 88.6479999975586, 89.69999999511718, 89.28000000488281, 89.49199999023438, 89.41599999023437, 89.60799998535157, 89.672, 89.79199997802735, 90.35999999023437, 90.2120000024414, 90.05199998535156, 90.13999998779298, 90.21199997070312, 90.48799998535156, 90.30799999023438, 90.32399999755859, 90.56399997558594, 90.30799999023438, 90.48000000976562, 90.51200001953126, 90.60399998779297, 90.73599997558594, 90.56799997802734, 90.72399997802735, 90.79999997802734, 90.67999999511719, 90.75999998046875, 90.94800000488281, 90.88799997802734, 90.93599998779297, 90.99199997314453, 90.97999998291016, 91.04799998535157, 91.06399998779297, 91.00399998046875, 91.11599997314453, 91.05199997802734, 91.1319999975586, 91.08399999023437, 91.088, 91.13999998046874, 91.09999999267578, 91.15999999511719, 91.11999997070312, 91.07199999511718, 91.15599997314453, 91.06799997802734, 91.09599999267579, 91.11599997802735, 91.17199998779297, 91.09599997558594, 90.87], 'cost_info': {'flops': 86.42625, 'params': 0.615386, 'latency': 0.018924427659888016, 'train_time': 12.369429608186087}}}\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 140 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 141 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 142 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 143 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 144 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 145 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 146 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 147 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 148 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 149 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 150 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 151 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 152 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 153 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 154 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 155 done. Train accuracy (top1, top5): 99.98400, 0.00000, Validation accuracy: 90.87000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 156 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 157 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 158 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:41:51 nl.defaults.trainer]: \u001b[0mEpoch 159 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 160, Anytime results: {'cifar10-valid': {'train_losses': [1.7590535233306885, 1.253890926475525, 1.0173324681854248, 0.8952319294929504, 0.7952679707145691, 0.7178717103004456, 0.6540075481510162, 0.6164532872009277, 0.572741891040802, 0.548687156944275, 0.5163005020904541, 0.49724343339920046, 0.48159374879837036, 0.4561509205055237, 0.443195352268219, 0.4340423945045471, 0.42289381216049193, 0.41247099397659304, 0.39859255592346193, 0.3847310581111908, 0.38570620378494264, 0.37401672600746155, 0.3553198397731781, 0.3622623147201538, 0.3582136388874054, 0.3426778517913818, 0.3393143599510193, 0.3353525933170319, 0.32946492588043214, 0.32799605854034425, 0.30711939200401306, 0.31443987482070923, 0.29605085428237915, 0.3057236696243286, 0.299252791185379, 0.3045342484951019, 0.28540553546905517, 0.27714631313323973, 0.2860210057640076, 0.27758472826004027, 0.2751334485149384, 0.26273797079086303, 0.26635597363471986, 0.2583936934185028, 0.2504289067745209, 0.2571247984790802, 0.2488475520849228, 0.2591000265407562, 0.2396266671705246, 0.23583861820220947, 0.2443368377685547, 0.23495931948661805, 0.23316353723526, 0.23000634630203248, 0.22449093638420106, 0.230427729139328, 0.22687479774475097, 0.22383548442840576, 0.22023301138877868, 0.2111498861026764, 0.20154631452560426, 0.21522830079078675, 0.20816100081443786, 0.2104341633796692, 0.1928897766113281, 0.1901931211566925, 0.19497794156074524, 0.19451545385837554, 0.19739277705669403, 0.18464830538749694, 0.187786444940567, 0.18601446922779083, 0.18209740275382996, 0.17458926858425142, 0.16948218180179597, 0.16775451046466827, 0.17570694140434265, 0.16952608935832977, 0.17369938548088074, 0.16247910106658936, 0.1627458212828636, 0.16151025188922882, 0.15988791759967805, 0.1544168821144104, 0.15413788839817047, 0.14873431820869445, 0.15047903293132783, 0.13837620630741118, 0.13758508543014528, 0.1455353747177124, 0.13287999488830565, 0.1373406744813919, 0.1347745600104332, 0.12774127123355866, 0.13236764445304872, 0.12718506742477417, 0.11845562703609466, 0.1156723401927948, 0.12139670521736146, 0.10730862700462342, 0.11740849154949189, 0.11019445963382721, 0.10556069979667664, 0.11198545998573303, 0.10079805026531219, 0.10490601120710373, 0.10149237629413604, 0.10136236079692841, 0.09250159616708756, 0.09566022252321243, 0.0911461717748642, 0.08540090807914734, 0.09579277135372162, 0.08916804823875427, 0.09255917760848999, 0.07867627663850785, 0.07134008258342743, 0.08396878028392792, 0.07685135874509812, 0.07420728881120682, 0.06795920423746109, 0.06948971684217453, 0.06733604598283768, 0.06122644077420235, 0.06650294776082039, 0.057012573330402376, 0.060703191540241244, 0.054785590641498565, 0.05117028720617294, 0.05034041869878769, 0.04757830910682678, 0.04828040234744549, 0.045970427957177165, 0.045760795257687566, 0.03953713648200035, 0.0377427965760231, 0.034650936419963835, 0.035798342687487605, 0.03309906951904297, 0.02996272998392582, 0.03508355941772461, 0.034724568047523496, 0.02920751726269722, 0.027419547743201256, 0.02265329301893711, 0.02150156823515892, 0.019416718893051146, 0.01684682356029749, 0.01919744865655899, 0.018470285133123397, 0.016949400667250158, 0.01513799466431141, 0.010710979192256928, 0.01234762650847435, 0.011636868097782135, 0.008262324912846088, 0.011411549041569232, 0.009078186836093665, 0.00747751551643014, 0.007217947504818439, 0.006073016881048679, 0.005204014120101929, 0.004744348908513785, 0.005281159439757466, 0.0037428918078541754, 0.003990445042029023, 0.0032846535781025886, 0.002816763821095228, 0.002901866187006235, 0.0025125133319199087, 0.002670208959877491, 0.002374543457403779, 0.0024884719659015535, 0.0024357157714664937, 0.0023475417947769165, 0.001997560367770493, 0.001984234646856785, 0.0021810284607112406, 0.001947038307376206, 0.0019969634805619718, 0.0019084248165786267, 0.00186372192427516, 0.0017302948284894227, 0.0018017550373077393, 0.0019776157954335214, 0.0018646478464454412, 0.0018066564371809364, 0.001502024546265602, 0.0017685006425529719, 0.001842838658541441, 0.0015407691003009676, 0.001938104105219245, 0.0015206571384519339, 0.0017707992356270552, 0.0015470346927642822, 0.0016294343948736786, 0.001581941422894597, 0.001855633354075253, 0.0015289916707202792, 0.0016320508097857236], 'eval_losses': [1.718411280593872, 1.2312516049575806, 1.1771704190444947, 1.3515655767059327, 0.9660426469421387, 0.9768166934967041, 0.9477648666381836, 1.237151806716919, 0.8955654866218566, 0.8810761741638183, 1.1881437857437134, 0.6852427861976623, 0.7852780195808411, 0.8770121252059937, 0.7973773103713989, 0.8103014721870422, 0.7476748447799683, 0.5877156407356262, 0.7928605024147034, 0.6822840277099609, 0.8421295105361939, 0.6406542447090149, 0.6899153922271728, 0.6677686989212036, 0.7989537047386169, 0.537646218471527, 0.6323223986625671, 0.7069718066978454, 0.980925947933197, 0.563901815700531, 0.7904056953048706, 0.7018899290084839, 0.9543996141242981, 0.6080814392280579, 0.6694716435623169, 0.6495321411514282, 0.5114869263458252, 0.7610300964164733, 0.7171964052009583, 0.5167922888088227, 0.5790614115715027, 0.759347915687561, 0.7309397786712647, 0.6184041437339782, 0.6511862775421142, 0.5763752061271668, 0.9758571516418457, 0.5302456571006775, 0.6012292710876465, 0.6005046747207642, 0.5406344582462311, 0.5212373646736145, 0.5723845916557312, 0.6747938611221314, 0.6448297795677185, 0.5414019553470611, 0.7262362331771851, 0.6604537596893311, 0.5754243794441223, 0.564960521068573, 0.6663493443489075, 0.6161240928077698, 0.6480882473754883, 0.6144952356338501, 0.6219606181716919, 0.5387650080490113, 0.6493202836227417, 0.6850091210556031, 0.5413768151283264, 0.5957857847976684, 0.5893074762535095, 0.5994222440719604, 0.5819091687965393, 0.5725137980270386, 0.6574975749397278, 0.4879689152336121, 0.8543747742462158, 0.5379905627632141, 0.5868096947097778, 0.5206522608280182, 0.5081658699226379, 0.5016767095565796, 0.6269804829025268, 0.5580487533760071, 0.7764566044998169, 0.5908050514411927, 0.5507814199638367, 0.615683196849823, 0.611512891292572, 0.6357141060256958, 0.7251284727287293, 0.5542829897212982, 0.5522480236816406, 0.556539073600769, 0.5384656166648865, 0.56949960439682, 0.5328687156677246, 0.7511683869934082, 0.547317732887268, 0.8191163311195373, 0.5636814766693116, 0.551606686000824, 0.581864392490387, 0.5142400267028808, 0.4914838037109375, 0.47061038381576537, 0.522464946269989, 0.5068567314338684, 0.5471167008781433, 0.5239724260139466, 0.4962406744003296, 0.6039029055213928, 0.5729658924293518, 0.6061009523391724, 0.5914560165977478, 0.5664147783851623, 0.5788380528068543, 0.6206599761772156, 0.4765826042175293, 0.46161720874786377, 0.6857886463928222, 0.5256627183914184, 0.6297357405090332, 0.5730468150138855, 0.45317377544403076, 0.5630033840370178, 0.5060999738502503, 0.4899347022438049, 0.4959884552001953, 0.4792864659690857, 0.5316450408744812, 0.6718994200706482, 0.470799847202301, 0.46742451177597044, 0.5001911766719818, 0.45956219264984133, 0.48940943477630616, 0.4401911287498474, 0.5173593873596192, 0.546613443660736, 0.5232481408309937, 0.45160889861106873, 0.46665762320518495, 0.48406548444747927, 0.44636263323783876, 0.47672241513252256, 0.47575879492759704, 0.459971777048111, 0.4658477996826172, 0.4535137093162537, 0.46346793446540835, 0.47640953466415403, 0.4543912881088257, 0.4318882328224182, 0.4447598114967346, 0.43818012475013735, 0.4530714146232605, 0.4412050086593628, 0.43256380767822267, 0.44799672149658204, 0.42579119641304014, 0.4064728831958771, 0.4370550115966797, 0.41313723978042605, 0.4075158442115784, 0.4159571482372284, 0.42473165824890136, 0.4289327929115295, 0.40728045385360717, 0.40247478660583497, 0.40966445984840394, 0.4042880867958069, 0.41219870920181273, 0.4037690533065796, 0.40438278610229494, 0.4028751260662079, 0.4037297201061249, 0.40001165477752687, 0.4003750887584686, 0.4007567466545105, 0.4061801832866669, 0.404340021276474, 0.41039950972557065, 0.40144869119644166, 0.40113924109458926, 0.39871796589851377, 0.39888700468063354, 0.40453189883232116, 0.4007547133541107, 0.40015139886856077, 0.3993334723567963, 0.3967307278823853, 0.3991465282154083, 0.3987165054512024, 0.3997709494686127, 0.3998419119691849, 0.3986040371370316, 0.39738791829109193, 0.3982571998500824, 0.4002548829460144, 0.4101720919370651], 'train_acc1es': [33.47999999267578, 54.255999985351565, 63.25199998779297, 67.72400001220703, 71.896, 74.91599998291015, 77.14000001708985, 78.57599998535156, 80.28399997314453, 80.88399997314453, 82.21199998779296, 82.49999997314453, 83.56800001220704, 84.03999997070312, 84.6359999975586, 85.08399997802735, 85.22800001464844, 85.66000000732421, 86.27999998535157, 86.65599999267579, 86.53600001220703, 87.048, 87.84799997314452, 87.53600000732422, 87.3800000024414, 88.18000000488281, 88.17599999755859, 88.04400000976563, 88.55199999023438, 88.57599999023438, 89.31599998535157, 89.17599999267578, 89.7, 89.18399999755859, 89.51199999755859, 89.4719999975586, 90.17999998779297, 90.40400001708984, 90.01200000488281, 90.25600000488281, 90.44399998779296, 91.13999998779298, 90.66400000244141, 91.11199999267578, 91.19999998779296, 90.99599997802734, 91.42399998046875, 90.81199998535156, 91.49599998535156, 91.79599998291016, 91.45999997558594, 91.81599997314453, 91.91199998779297, 91.99199999023438, 92.10799998291016, 91.91999999511718, 92.09199997314452, 92.19599998291015, 92.3199999975586, 92.64399999511718, 93.00799998046875, 92.43999999023437, 92.67199997802734, 92.79199998779296, 93.23599997558594, 93.39199997070313, 93.26399997802734, 93.38399997802735, 93.21999997558594, 93.5119999951172, 93.30799997558594, 93.55199997314453, 93.63199997314453, 93.91199997802734, 94.10000001953125, 94.22399997314453, 93.97999997070312, 93.99600001953125, 93.97199998779297, 94.53199998291015, 94.29600000488281, 94.31999998046875, 94.36399997558594, 94.63199999511718, 94.60800001953125, 94.98400001953125, 94.53999997558594, 95.32799997558594, 95.27999997802735, 94.77600001953125, 95.46800001953125, 95.24799998046875, 95.20800001708984, 95.57599997558594, 95.48799997070313, 95.55600001953125, 95.94400001953125, 96.04399997558593, 95.91999997314453, 96.34799997070313, 95.94000001708984, 96.28800000976563, 96.44400000976563, 96.13600001708984, 96.51999997070313, 96.51600000976562, 96.59199997558594, 96.40800001953124, 96.90400001220704, 96.75600001220702, 96.97600001220704, 97.13199997314453, 96.82000000976562, 97.10000001708984, 96.91999997314453, 97.34000000732422, 97.67200000976563, 97.20800001464843, 97.39200000488282, 97.50000001220702, 97.69600001220704, 97.57600000732423, 97.75600000732422, 97.97200000732421, 97.75200000976562, 98.08800000732423, 98.01200001220703, 98.14400001464844, 98.30800000976562, 98.38000000732421, 98.46400001464843, 98.516, 98.4360000024414, 98.5040000024414, 98.7280000024414, 98.78000000976563, 98.92800000488282, 98.9480000024414, 98.97200000732421, 99.05600000244141, 98.89600001464844, 98.8680000024414, 99.14000000488281, 99.16000000244141, 99.30000000488282, 99.34000000976563, 99.43200000488281, 99.54, 99.45200001464843, 99.42400000488281, 99.532, 99.58000000488282, 99.736, 99.68400000244141, 99.70400000488281, 99.81600000244141, 99.672, 99.768, 99.836, 99.81200000244141, 99.84800000244141, 99.908, 99.892, 99.888, 99.944, 99.928, 99.948, 99.96, 99.956, 99.968, 99.968, 99.96, 99.956, 99.976, 99.9680000024414, 99.972, 99.9800000024414, 99.976, 99.992, 99.976, 99.98, 99.988, 99.984, 99.992, 99.972, 99.98, 99.984, 99.996, 99.992, 99.976, 99.996, 99.984, 99.992, 99.98, 99.996, 99.988, 99.992, 99.976, 99.992, 99.992], 'eval_acc1es': [38.17200000854492, 58.16, 59.15600000366211, 54.183999990234376, 67.09600001220703, 67.65199997802735, 70.45199998535156, 64.27599997802734, 71.28000001220703, 72.01999999267578, 65.11999999267579, 77.35600001953125, 74.75999999511718, 73.39200000488282, 74.77600000976562, 74.48399999023438, 77.07599999511719, 80.66400001953124, 76.07599999511719, 78.21599998779297, 75.02800000488281, 79.12799998291015, 78.78800000244141, 79.09599998046875, 75.56800000244141, 82.77199997558594, 79.58800001953125, 79.27999998046874, 71.47999997558594, 81.69599999023437, 77.0400000024414, 78.01999997314454, 73.476, 81.29999998535156, 79.07599999267578, 79.38799999267579, 83.85200001220703, 78.15999999511719, 79.44399997802735, 83.38400000732422, 82.64799998291015, 77.68799998535157, 79.18799997070313, 81.67999998046875, 80.71200001464844, 82.45199997070313, 75.0920000048828, 83.16000001708984, 82.10400000732422, 81.58400001708985, 83.56800000732422, 84.01599997070312, 82.22800001953125, 80.63999997314453, 81.64400001953125, 82.8, 79.20799998535156, 80.10799998046875, 82.49999997314453, 83.21999998046876, 80.63599998779297, 82.18799998046875, 81.13599998535156, 82.10000001708984, 81.43999999023437, 84.01999998046875, 81.64799998046875, 80.27199999023438, 84.64400001708984, 83.09199998291015, 83.75600000976563, 82.81999998291016, 83.54000000976562, 83.81599997802735, 82.03999997314453, 85.46399997802735, 77.03999998535156, 84.38799997070312, 83.67199997070313, 85.2000000024414, 85.25200001464843, 85.28800001220704, 82.95600001464844, 83.90399997558593, 79.99999997558594, 84.20400001708984, 84.49599997802734, 83.19200000732422, 83.15999997314454, 82.77200000732422, 81.15199998046874, 85.02400000488281, 84.84800001953126, 84.98000000488281, 85.19199997314453, 83.84800000244141, 85.12399997070312, 80.78400001953125, 85.44000000244141, 81.02799998291016, 85.07600001220703, 84.86400000976562, 84.38400000976563, 86.4279999975586, 86.45600001464844, 87.032, 86.15600000488281, 86.3680000024414, 85.67199997070313, 85.89999997802734, 86.82800001708985, 84.61999999023438, 84.93200000244141, 84.58400001220703, 85.43600001220703, 85.6360000024414, 85.94400001220703, 84.39200000488282, 87.58399999511718, 87.93600001464844, 84.01200000976563, 87.4560000024414, 84.49200001464844, 86.50000001464844, 88.22800000732421, 86.36399998046875, 87.19200000976562, 87.80400000732422, 88.04399999511719, 88.05599999267578, 87.2519999975586, 84.34399999267578, 88.35599999511719, 88.46, 88.29599999511719, 88.88, 88.45599999511718, 89.14000000488281, 87.91200000976562, 87.30799998535156, 87.76400000976562, 89.00399998535157, 88.79999999023437, 89.03599998291016, 89.52399999755859, 88.9599999975586, 89.20399998779297, 89.45199999267578, 89.31200000976563, 89.62799998046874, 89.35999998291015, 89.76399998046875, 89.8320000024414, 90.22799998535156, 89.99199999023438, 90.19999998779296, 89.86799999023438, 90.25600000244141, 90.39999999511718, 90.29199998291016, 90.59199998291015, 90.97199998535156, 90.48399998291016, 91.0080000024414, 91.09599997802735, 90.93199999023437, 90.80399997802735, 90.94799998535156, 91.22399998535157, 91.21199997558594, 91.16799997802734, 91.18799999267578, 91.17599998046875, 91.26399999023438, 91.36399999023438, 91.32399997802735, 91.28399998291016, 91.33999998046875, 91.41999998535157, 91.41599998291015, 91.34399998535156, 91.28799998779297, 91.28399997802734, 91.37599998535157, 91.30799997558594, 91.41199999023438, 91.37199998046874, 91.35999998535156, 91.42799998046875, 91.37199999267578, 91.39199998535156, 91.37599997802734, 91.42399998291016, 91.41999998535157, 91.3959999951172, 91.39600001464844, 91.42399997070312, 91.44799998779297, 91.44799997802734, 91.34799999755859, 91.27], 'cost_info': {'flops': 117.88353, 'params': 0.830426, 'latency': 0.019024136819337543, 'train_time': 12.783856292565666}}}\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 160 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 161 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 162 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 163 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 164 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 165 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 166 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 167 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 168 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 169 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 170 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 171 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 172 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 173 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 174 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 175 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 176 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 177 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 178 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:42:43 nl.defaults.trainer]: \u001b[0mEpoch 179 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 180, Anytime results: {'cifar10-valid': {'train_losses': [1.7590535233306885, 1.253890926475525, 1.0173324681854248, 0.8952319294929504, 0.7952679707145691, 0.7178717103004456, 0.6540075481510162, 0.6164532872009277, 0.572741891040802, 0.548687156944275, 0.5163005020904541, 0.49724343339920046, 0.48159374879837036, 0.4561509205055237, 0.443195352268219, 0.4340423945045471, 0.42289381216049193, 0.41247099397659304, 0.39859255592346193, 0.3847310581111908, 0.38570620378494264, 0.37401672600746155, 0.3553198397731781, 0.3622623147201538, 0.3582136388874054, 0.3426778517913818, 0.3393143599510193, 0.3353525933170319, 0.32946492588043214, 0.32799605854034425, 0.30711939200401306, 0.31443987482070923, 0.29605085428237915, 0.3057236696243286, 0.299252791185379, 0.3045342484951019, 0.28540553546905517, 0.27714631313323973, 0.2860210057640076, 0.27758472826004027, 0.2751334485149384, 0.26273797079086303, 0.26635597363471986, 0.2583936934185028, 0.2504289067745209, 0.2571247984790802, 0.2488475520849228, 0.2591000265407562, 0.2396266671705246, 0.23583861820220947, 0.2443368377685547, 0.23495931948661805, 0.23316353723526, 0.23000634630203248, 0.22449093638420106, 0.230427729139328, 0.22687479774475097, 0.22383548442840576, 0.22023301138877868, 0.2111498861026764, 0.20154631452560426, 0.21522830079078675, 0.20816100081443786, 0.2104341633796692, 0.1928897766113281, 0.1901931211566925, 0.19497794156074524, 0.19451545385837554, 0.19739277705669403, 0.18464830538749694, 0.187786444940567, 0.18601446922779083, 0.18209740275382996, 0.17458926858425142, 0.16948218180179597, 0.16775451046466827, 0.17570694140434265, 0.16952608935832977, 0.17369938548088074, 0.16247910106658936, 0.1627458212828636, 0.16151025188922882, 0.15988791759967805, 0.1544168821144104, 0.15413788839817047, 0.14873431820869445, 0.15047903293132783, 0.13837620630741118, 0.13758508543014528, 0.1455353747177124, 0.13287999488830565, 0.1373406744813919, 0.1347745600104332, 0.12774127123355866, 0.13236764445304872, 0.12718506742477417, 0.11845562703609466, 0.1156723401927948, 0.12139670521736146, 0.10730862700462342, 0.11740849154949189, 0.11019445963382721, 0.10556069979667664, 0.11198545998573303, 0.10079805026531219, 0.10490601120710373, 0.10149237629413604, 0.10136236079692841, 0.09250159616708756, 0.09566022252321243, 0.0911461717748642, 0.08540090807914734, 0.09579277135372162, 0.08916804823875427, 0.09255917760848999, 0.07867627663850785, 0.07134008258342743, 0.08396878028392792, 0.07685135874509812, 0.07420728881120682, 0.06795920423746109, 0.06948971684217453, 0.06733604598283768, 0.06122644077420235, 0.06650294776082039, 0.057012573330402376, 0.060703191540241244, 0.054785590641498565, 0.05117028720617294, 0.05034041869878769, 0.04757830910682678, 0.04828040234744549, 0.045970427957177165, 0.045760795257687566, 0.03953713648200035, 0.0377427965760231, 0.034650936419963835, 0.035798342687487605, 0.03309906951904297, 0.02996272998392582, 0.03508355941772461, 0.034724568047523496, 0.02920751726269722, 0.027419547743201256, 0.02265329301893711, 0.02150156823515892, 0.019416718893051146, 0.01684682356029749, 0.01919744865655899, 0.018470285133123397, 0.016949400667250158, 0.01513799466431141, 0.010710979192256928, 0.01234762650847435, 0.011636868097782135, 0.008262324912846088, 0.011411549041569232, 0.009078186836093665, 0.00747751551643014, 0.007217947504818439, 0.006073016881048679, 0.005204014120101929, 0.004744348908513785, 0.005281159439757466, 0.0037428918078541754, 0.003990445042029023, 0.0032846535781025886, 0.002816763821095228, 0.002901866187006235, 0.0025125133319199087, 0.002670208959877491, 0.002374543457403779, 0.0024884719659015535, 0.0024357157714664937, 0.0023475417947769165, 0.001997560367770493, 0.001984234646856785, 0.0021810284607112406, 0.001947038307376206, 0.0019969634805619718, 0.0019084248165786267, 0.00186372192427516, 0.0017302948284894227, 0.0018017550373077393, 0.0019776157954335214, 0.0018646478464454412, 0.0018066564371809364, 0.001502024546265602, 0.0017685006425529719, 0.001842838658541441, 0.0015407691003009676, 0.001938104105219245, 0.0015206571384519339, 0.0017707992356270552, 0.0015470346927642822, 0.0016294343948736786, 0.001581941422894597, 0.001855633354075253, 0.0015289916707202792, 0.0016320508097857236], 'eval_losses': [1.718411280593872, 1.2312516049575806, 1.1771704190444947, 1.3515655767059327, 0.9660426469421387, 0.9768166934967041, 0.9477648666381836, 1.237151806716919, 0.8955654866218566, 0.8810761741638183, 1.1881437857437134, 0.6852427861976623, 0.7852780195808411, 0.8770121252059937, 0.7973773103713989, 0.8103014721870422, 0.7476748447799683, 0.5877156407356262, 0.7928605024147034, 0.6822840277099609, 0.8421295105361939, 0.6406542447090149, 0.6899153922271728, 0.6677686989212036, 0.7989537047386169, 0.537646218471527, 0.6323223986625671, 0.7069718066978454, 0.980925947933197, 0.563901815700531, 0.7904056953048706, 0.7018899290084839, 0.9543996141242981, 0.6080814392280579, 0.6694716435623169, 0.6495321411514282, 0.5114869263458252, 0.7610300964164733, 0.7171964052009583, 0.5167922888088227, 0.5790614115715027, 0.759347915687561, 0.7309397786712647, 0.6184041437339782, 0.6511862775421142, 0.5763752061271668, 0.9758571516418457, 0.5302456571006775, 0.6012292710876465, 0.6005046747207642, 0.5406344582462311, 0.5212373646736145, 0.5723845916557312, 0.6747938611221314, 0.6448297795677185, 0.5414019553470611, 0.7262362331771851, 0.6604537596893311, 0.5754243794441223, 0.564960521068573, 0.6663493443489075, 0.6161240928077698, 0.6480882473754883, 0.6144952356338501, 0.6219606181716919, 0.5387650080490113, 0.6493202836227417, 0.6850091210556031, 0.5413768151283264, 0.5957857847976684, 0.5893074762535095, 0.5994222440719604, 0.5819091687965393, 0.5725137980270386, 0.6574975749397278, 0.4879689152336121, 0.8543747742462158, 0.5379905627632141, 0.5868096947097778, 0.5206522608280182, 0.5081658699226379, 0.5016767095565796, 0.6269804829025268, 0.5580487533760071, 0.7764566044998169, 0.5908050514411927, 0.5507814199638367, 0.615683196849823, 0.611512891292572, 0.6357141060256958, 0.7251284727287293, 0.5542829897212982, 0.5522480236816406, 0.556539073600769, 0.5384656166648865, 0.56949960439682, 0.5328687156677246, 0.7511683869934082, 0.547317732887268, 0.8191163311195373, 0.5636814766693116, 0.551606686000824, 0.581864392490387, 0.5142400267028808, 0.4914838037109375, 0.47061038381576537, 0.522464946269989, 0.5068567314338684, 0.5471167008781433, 0.5239724260139466, 0.4962406744003296, 0.6039029055213928, 0.5729658924293518, 0.6061009523391724, 0.5914560165977478, 0.5664147783851623, 0.5788380528068543, 0.6206599761772156, 0.4765826042175293, 0.46161720874786377, 0.6857886463928222, 0.5256627183914184, 0.6297357405090332, 0.5730468150138855, 0.45317377544403076, 0.5630033840370178, 0.5060999738502503, 0.4899347022438049, 0.4959884552001953, 0.4792864659690857, 0.5316450408744812, 0.6718994200706482, 0.470799847202301, 0.46742451177597044, 0.5001911766719818, 0.45956219264984133, 0.48940943477630616, 0.4401911287498474, 0.5173593873596192, 0.546613443660736, 0.5232481408309937, 0.45160889861106873, 0.46665762320518495, 0.48406548444747927, 0.44636263323783876, 0.47672241513252256, 0.47575879492759704, 0.459971777048111, 0.4658477996826172, 0.4535137093162537, 0.46346793446540835, 0.47640953466415403, 0.4543912881088257, 0.4318882328224182, 0.4447598114967346, 0.43818012475013735, 0.4530714146232605, 0.4412050086593628, 0.43256380767822267, 0.44799672149658204, 0.42579119641304014, 0.4064728831958771, 0.4370550115966797, 0.41313723978042605, 0.4075158442115784, 0.4159571482372284, 0.42473165824890136, 0.4289327929115295, 0.40728045385360717, 0.40247478660583497, 0.40966445984840394, 0.4042880867958069, 0.41219870920181273, 0.4037690533065796, 0.40438278610229494, 0.4028751260662079, 0.4037297201061249, 0.40001165477752687, 0.4003750887584686, 0.4007567466545105, 0.4061801832866669, 0.404340021276474, 0.41039950972557065, 0.40144869119644166, 0.40113924109458926, 0.39871796589851377, 0.39888700468063354, 0.40453189883232116, 0.4007547133541107, 0.40015139886856077, 0.3993334723567963, 0.3967307278823853, 0.3991465282154083, 0.3987165054512024, 0.3997709494686127, 0.3998419119691849, 0.3986040371370316, 0.39738791829109193, 0.3982571998500824, 0.4002548829460144, 0.4101720919370651], 'train_acc1es': [33.47999999267578, 54.255999985351565, 63.25199998779297, 67.72400001220703, 71.896, 74.91599998291015, 77.14000001708985, 78.57599998535156, 80.28399997314453, 80.88399997314453, 82.21199998779296, 82.49999997314453, 83.56800001220704, 84.03999997070312, 84.6359999975586, 85.08399997802735, 85.22800001464844, 85.66000000732421, 86.27999998535157, 86.65599999267579, 86.53600001220703, 87.048, 87.84799997314452, 87.53600000732422, 87.3800000024414, 88.18000000488281, 88.17599999755859, 88.04400000976563, 88.55199999023438, 88.57599999023438, 89.31599998535157, 89.17599999267578, 89.7, 89.18399999755859, 89.51199999755859, 89.4719999975586, 90.17999998779297, 90.40400001708984, 90.01200000488281, 90.25600000488281, 90.44399998779296, 91.13999998779298, 90.66400000244141, 91.11199999267578, 91.19999998779296, 90.99599997802734, 91.42399998046875, 90.81199998535156, 91.49599998535156, 91.79599998291016, 91.45999997558594, 91.81599997314453, 91.91199998779297, 91.99199999023438, 92.10799998291016, 91.91999999511718, 92.09199997314452, 92.19599998291015, 92.3199999975586, 92.64399999511718, 93.00799998046875, 92.43999999023437, 92.67199997802734, 92.79199998779296, 93.23599997558594, 93.39199997070313, 93.26399997802734, 93.38399997802735, 93.21999997558594, 93.5119999951172, 93.30799997558594, 93.55199997314453, 93.63199997314453, 93.91199997802734, 94.10000001953125, 94.22399997314453, 93.97999997070312, 93.99600001953125, 93.97199998779297, 94.53199998291015, 94.29600000488281, 94.31999998046875, 94.36399997558594, 94.63199999511718, 94.60800001953125, 94.98400001953125, 94.53999997558594, 95.32799997558594, 95.27999997802735, 94.77600001953125, 95.46800001953125, 95.24799998046875, 95.20800001708984, 95.57599997558594, 95.48799997070313, 95.55600001953125, 95.94400001953125, 96.04399997558593, 95.91999997314453, 96.34799997070313, 95.94000001708984, 96.28800000976563, 96.44400000976563, 96.13600001708984, 96.51999997070313, 96.51600000976562, 96.59199997558594, 96.40800001953124, 96.90400001220704, 96.75600001220702, 96.97600001220704, 97.13199997314453, 96.82000000976562, 97.10000001708984, 96.91999997314453, 97.34000000732422, 97.67200000976563, 97.20800001464843, 97.39200000488282, 97.50000001220702, 97.69600001220704, 97.57600000732423, 97.75600000732422, 97.97200000732421, 97.75200000976562, 98.08800000732423, 98.01200001220703, 98.14400001464844, 98.30800000976562, 98.38000000732421, 98.46400001464843, 98.516, 98.4360000024414, 98.5040000024414, 98.7280000024414, 98.78000000976563, 98.92800000488282, 98.9480000024414, 98.97200000732421, 99.05600000244141, 98.89600001464844, 98.8680000024414, 99.14000000488281, 99.16000000244141, 99.30000000488282, 99.34000000976563, 99.43200000488281, 99.54, 99.45200001464843, 99.42400000488281, 99.532, 99.58000000488282, 99.736, 99.68400000244141, 99.70400000488281, 99.81600000244141, 99.672, 99.768, 99.836, 99.81200000244141, 99.84800000244141, 99.908, 99.892, 99.888, 99.944, 99.928, 99.948, 99.96, 99.956, 99.968, 99.968, 99.96, 99.956, 99.976, 99.9680000024414, 99.972, 99.9800000024414, 99.976, 99.992, 99.976, 99.98, 99.988, 99.984, 99.992, 99.972, 99.98, 99.984, 99.996, 99.992, 99.976, 99.996, 99.984, 99.992, 99.98, 99.996, 99.988, 99.992, 99.976, 99.992, 99.992], 'eval_acc1es': [38.17200000854492, 58.16, 59.15600000366211, 54.183999990234376, 67.09600001220703, 67.65199997802735, 70.45199998535156, 64.27599997802734, 71.28000001220703, 72.01999999267578, 65.11999999267579, 77.35600001953125, 74.75999999511718, 73.39200000488282, 74.77600000976562, 74.48399999023438, 77.07599999511719, 80.66400001953124, 76.07599999511719, 78.21599998779297, 75.02800000488281, 79.12799998291015, 78.78800000244141, 79.09599998046875, 75.56800000244141, 82.77199997558594, 79.58800001953125, 79.27999998046874, 71.47999997558594, 81.69599999023437, 77.0400000024414, 78.01999997314454, 73.476, 81.29999998535156, 79.07599999267578, 79.38799999267579, 83.85200001220703, 78.15999999511719, 79.44399997802735, 83.38400000732422, 82.64799998291015, 77.68799998535157, 79.18799997070313, 81.67999998046875, 80.71200001464844, 82.45199997070313, 75.0920000048828, 83.16000001708984, 82.10400000732422, 81.58400001708985, 83.56800000732422, 84.01599997070312, 82.22800001953125, 80.63999997314453, 81.64400001953125, 82.8, 79.20799998535156, 80.10799998046875, 82.49999997314453, 83.21999998046876, 80.63599998779297, 82.18799998046875, 81.13599998535156, 82.10000001708984, 81.43999999023437, 84.01999998046875, 81.64799998046875, 80.27199999023438, 84.64400001708984, 83.09199998291015, 83.75600000976563, 82.81999998291016, 83.54000000976562, 83.81599997802735, 82.03999997314453, 85.46399997802735, 77.03999998535156, 84.38799997070312, 83.67199997070313, 85.2000000024414, 85.25200001464843, 85.28800001220704, 82.95600001464844, 83.90399997558593, 79.99999997558594, 84.20400001708984, 84.49599997802734, 83.19200000732422, 83.15999997314454, 82.77200000732422, 81.15199998046874, 85.02400000488281, 84.84800001953126, 84.98000000488281, 85.19199997314453, 83.84800000244141, 85.12399997070312, 80.78400001953125, 85.44000000244141, 81.02799998291016, 85.07600001220703, 84.86400000976562, 84.38400000976563, 86.4279999975586, 86.45600001464844, 87.032, 86.15600000488281, 86.3680000024414, 85.67199997070313, 85.89999997802734, 86.82800001708985, 84.61999999023438, 84.93200000244141, 84.58400001220703, 85.43600001220703, 85.6360000024414, 85.94400001220703, 84.39200000488282, 87.58399999511718, 87.93600001464844, 84.01200000976563, 87.4560000024414, 84.49200001464844, 86.50000001464844, 88.22800000732421, 86.36399998046875, 87.19200000976562, 87.80400000732422, 88.04399999511719, 88.05599999267578, 87.2519999975586, 84.34399999267578, 88.35599999511719, 88.46, 88.29599999511719, 88.88, 88.45599999511718, 89.14000000488281, 87.91200000976562, 87.30799998535156, 87.76400000976562, 89.00399998535157, 88.79999999023437, 89.03599998291016, 89.52399999755859, 88.9599999975586, 89.20399998779297, 89.45199999267578, 89.31200000976563, 89.62799998046874, 89.35999998291015, 89.76399998046875, 89.8320000024414, 90.22799998535156, 89.99199999023438, 90.19999998779296, 89.86799999023438, 90.25600000244141, 90.39999999511718, 90.29199998291016, 90.59199998291015, 90.97199998535156, 90.48399998291016, 91.0080000024414, 91.09599997802735, 90.93199999023437, 90.80399997802735, 90.94799998535156, 91.22399998535157, 91.21199997558594, 91.16799997802734, 91.18799999267578, 91.17599998046875, 91.26399999023438, 91.36399999023438, 91.32399997802735, 91.28399998291016, 91.33999998046875, 91.41999998535157, 91.41599998291015, 91.34399998535156, 91.28799998779297, 91.28399997802734, 91.37599998535157, 91.30799997558594, 91.41199999023438, 91.37199998046874, 91.35999998535156, 91.42799998046875, 91.37199999267578, 91.39199998535156, 91.37599997802734, 91.42399998291016, 91.41999998535157, 91.3959999951172, 91.39600001464844, 91.42399997070312, 91.44799998779297, 91.44799997802734, 91.34799999755859, 91.27], 'cost_info': {'flops': 117.88353, 'params': 0.830426, 'latency': 0.019024136819337543, 'train_time': 12.783856292565666}}}\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 180 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 181 done. Train accuracy (top1, top5): 99.99200, 0.00000, Validation accuracy: 91.27000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 182 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 183 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 184 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 185 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 186 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 187 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 188 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 189 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 190 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 191 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 192 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 193 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 194 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:36 nl.defaults.trainer]: \u001b[0mEpoch 195 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:37 nl.defaults.trainer]: \u001b[0mEpoch 196 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:37 nl.defaults.trainer]: \u001b[0mEpoch 197 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:37 nl.defaults.trainer]: \u001b[0mEpoch 198 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:43:37 nl.defaults.trainer]: \u001b[0mEpoch 199 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:44:26 nl.defaults.trainer]: \u001b[0mEpoch 200, Anytime results: {'cifar10-valid': {'train_losses': [1.797979532775879, 1.2527252103996276, 1.0138580317115784, 0.8822913989257812, 0.7803608722114563, 0.7023457984924316, 0.6497955482292175, 0.6059390458106995, 0.5677761807537078, 0.538056489944458, 0.515950230770111, 0.4948751167488098, 0.4747195296764374, 0.4572546643924713, 0.445253247756958, 0.4359080542373657, 0.4239110640716553, 0.41368696506500247, 0.3971407129478455, 0.38833855127334593, 0.3788480834960937, 0.3740516341018677, 0.35861263020515444, 0.3550860090827942, 0.35471325862884523, 0.3511313292884827, 0.3420170811271667, 0.33029187686920164, 0.32096393228530884, 0.3264443295955658, 0.3209636632442474, 0.31464752191543577, 0.3025444029521942, 0.29950268094062804, 0.2968454804801941, 0.30367620081901553, 0.2844067573404312, 0.28439875590324404, 0.2781640834140778, 0.2739880220317841, 0.26975711678504943, 0.26009569576740266, 0.26850710664749144, 0.2599183919286728, 0.2559084771347046, 0.25671464601039884, 0.25152616675376893, 0.24927711655139922, 0.247728226518631, 0.24402085838317872, 0.24527329946517945, 0.2376989866876602, 0.23035390013694762, 0.2327466607093811, 0.22429453383922576, 0.2272956440448761, 0.22197500553131103, 0.21436945312976838, 0.21928964067459106, 0.21290034994125367, 0.20822054827213288, 0.21389376505851745, 0.20563746623039245, 0.2099708962535858, 0.19158048898220062, 0.19615204340457917, 0.1982648743581772, 0.1887348501777649, 0.19475696102142334, 0.1842686238336563, 0.18677605671405792, 0.18652738688468934, 0.18188076397895814, 0.18016700853824616, 0.17823464753627777, 0.18016266384124757, 0.16617573895454407, 0.1770302580022812, 0.17052061563491822, 0.15902811944961548, 0.16233001423358917, 0.16556088306903838, 0.15680421692848207, 0.1498578377342224, 0.15635097947120666, 0.15310042744636534, 0.15306200007438658, 0.14491507052898406, 0.1416260453414917, 0.13550126110076904, 0.1392497732591629, 0.13626620844841003, 0.13300940950632095, 0.13275603595256805, 0.12830855484008788, 0.12408610872745514, 0.12531209909915925, 0.12207098999977112, 0.1216279049706459, 0.10974599875926971, 0.11079829895496368, 0.11904660460948945, 0.10809563687324523, 0.11965358115673065, 0.11427250968933106, 0.10849766419887542, 0.10218072737693787, 0.10716040850162506, 0.10477651658535003, 0.09131185996413231, 0.09049850377559662, 0.09137351614952087, 0.0909367332983017, 0.08757329261779785, 0.0899801014661789, 0.08972211226701736, 0.08128207237005233, 0.08392260439395904, 0.07897669915676117, 0.07467384212732316, 0.07569570093631744, 0.0694864012169838, 0.0675577897644043, 0.06855287613153457, 0.0652096102821827, 0.06380558840870858, 0.06269203025877476, 0.056387432240247726, 0.05073259930610657, 0.05295789412975311, 0.06122023828983307, 0.05983238134384155, 0.050557514559030535, 0.04516359554290771, 0.04152287001490593, 0.04919338520169258, 0.037906546899080275, 0.03719876957416535, 0.03342186244606972, 0.03439499699473381, 0.03459258997559547, 0.03468540014445782, 0.028545279636383057, 0.03216642561376095, 0.02676758377045393, 0.025878876812458037, 0.0214473418533802, 0.021104339045286177, 0.021747494243383406, 0.021283978564739226, 0.019705448406785727, 0.018253158379793168, 0.015280498052239418, 0.0137871942422539, 0.014443003076314926, 0.01408235429942608, 0.013874327067136764, 0.01428306491613388, 0.012863019816875458, 0.010711087912917137, 0.007742220239043236, 0.006511413640901446, 0.006719038946032524, 0.006903528813645244, 0.004742787101864814, 0.004861924066767096, 0.005476148186177015, 0.0038102409364283085, 0.0039400346457958224, 0.003776025571450591, 0.004068971053361892, 0.002876078786998987, 0.0030355332847684623, 0.0035315019605308773, 0.002837982722520828, 0.002136290045157075, 0.0019352131270617247, 0.0021824218651652337, 0.002028700380474329, 0.0019801752346754074, 0.0021660784274339677, 0.0022002970218658446, 0.0019479305266216398, 0.002038802414163947, 0.0019461702918633819, 0.001907505464591086, 0.0021021232601627707, 0.0016369401945173741, 0.0018257959835976361, 0.0019210409358888865, 0.001416360531039536, 0.0015833961294218898, 0.0017988794137910008, 0.0015769814006984233, 0.001505851459875703, 0.0018100922302156687, 0.0014608621790260076, 0.0016108034229651094, 0.0015840492541342973, 0.0013324481489509345], 'eval_losses': [1.6272298514175414, 1.719287733230591, 1.7449889614105225, 1.133109687538147, 1.1186404991149903, 1.0821128437423706, 0.847026729850769, 1.5927908081817628, 0.8209507646751404, 0.7648674670219422, 1.0775786195755004, 0.6779091291427612, 0.6390487702178955, 0.7489264928436279, 0.6666688264083862, 1.0245877558135987, 1.1595384635925292, 0.723676893119812, 0.7669336923980713, 0.6112452599334717, 0.9660843383407592, 0.7343378405952453, 0.840818124294281, 1.2604200606918334, 0.6063524735832214, 1.159623742980957, 0.6039365092849731, 0.8497507237052917, 0.628081222114563, 0.6216542652893067, 0.5560605820655823, 0.5865489265823364, 0.9597786441802979, 0.6361585730934143, 0.9626845142745971, 0.844418583946228, 0.6500097342872619, 0.7736053534698486, 0.5939313138771057, 0.5072878143882752, 0.6224685645675659, 0.8204889801216125, 0.5511082135486602, 0.5362294416618347, 0.570758188419342, 0.6172440949440002, 0.9451023908996582, 0.47864262647628786, 0.610565881061554, 0.7115218802642822, 0.547065057926178, 0.5347714776134491, 0.5567891032409668, 0.5078570296478272, 0.5192969712829589, 0.6586684846878051, 0.6104187334823609, 0.583992243309021, 0.571166090927124, 0.729368978061676, 0.5097968811225891, 0.597749605178833, 0.5448352932357788, 0.5565177823829651, 0.6815717866516113, 0.5223795333480835, 0.5291338024044037, 0.5593303778266907, 0.6371515368461609, 0.5649146770095825, 0.7654560852050781, 0.6053906892967225, 0.8099864686775208, 0.5623643120193481, 0.6302320753669739, 0.7100821681594849, 0.5042611715888977, 0.5859966699981689, 0.4900874222660065, 0.5865842864894867, 0.5524932344436646, 0.6036392141723633, 0.5771377402496338, 0.635603153705597, 0.6008246605110168, 0.78836101770401, 0.5175824388122559, 0.639802907295227, 0.5585134193229675, 0.5268317921829223, 0.5819013167953491, 0.5606769778060913, 0.5718329856300354, 0.5630345753669739, 0.5855106465911866, 0.4912681079673767, 0.54175859998703, 0.514786814107895, 0.4591868642425537, 0.5052623636817932, 0.5783377849388123, 0.5009782519340515, 0.5888236622619629, 0.762264783744812, 0.7242392131233215, 0.49246752378463743, 0.554996236963272, 0.5442889282417297, 0.4409437468338013, 0.5605955778503418, 0.5315693290710449, 0.5794152967357635, 0.5857491951942444, 0.5708944032287597, 0.5043705623722077, 0.5632711613273621, 0.5163035422515869, 0.4966876087188721, 0.4505663089752197, 0.4704933899116516, 0.45981528732299803, 0.6531034126091003, 0.5183848677921296, 0.5909099923610688, 0.5152843837165832, 0.49619828419685363, 0.5475378018951416, 0.5393404815101623, 0.7201345665931702, 0.4824238876056671, 0.5215795503044128, 0.5685945818328857, 0.5089179008483887, 0.47145085259437564, 0.5472192948913575, 0.4900347399139404, 0.540964811782837, 0.46170505146026614, 0.5063307063484191, 0.5666370886611939, 0.48203581071853635, 0.44972750431060793, 0.5232554189109803, 0.4906134189224243, 0.5257716849899292, 0.45284362602233885, 0.4711797005844116, 0.48627261313438414, 0.4987119895553589, 0.466983223361969, 0.49265243516921997, 0.4703731024837494, 0.463229135723114, 0.460639780960083, 0.47536511048316954, 0.4933408259010315, 0.5230341455554962, 0.4691208839035034, 0.4683770147895813, 0.4554304603385925, 0.4363482038497925, 0.4507359668636322, 0.47246342094421384, 0.44265450010299684, 0.44240144773483275, 0.4374107486915588, 0.45024260966300966, 0.4394589510059357, 0.4438844661808014, 0.4459243761634827, 0.4445250177764893, 0.4392674104118347, 0.43809965566635134, 0.4435059818077087, 0.44061508752822875, 0.43598945977211, 0.4353007004642487, 0.4364056324005127, 0.436138900680542, 0.44131933745384216, 0.4382879079723358, 0.43560168815612793, 0.4378226725196838, 0.43351163749694827, 0.4295745631122589, 0.43166758422851564, 0.43342907007217407, 0.43806649894714356, 0.433157393579483, 0.4312484454727173, 0.43233252582550047, 0.43136490835189817, 0.432343833770752, 0.430613657617569, 0.43042267800331113, 0.43180035969734193, 0.4328012317943573, 0.4323063223934174, 0.43098210398674014, 0.4329616625976562, 0.4390562599182129], 'train_acc1es': [31.436000007324218, 54.619999978027344, 63.41599999755859, 68.73600000976562, 72.56400001464844, 75.38399997558594, 77.32399997802735, 78.93999998535156, 80.21200001464844, 81.58399997802735, 81.92799998779297, 83.02400001708985, 83.64800000732421, 84.40800001464844, 84.43200001464844, 85.00000001220702, 85.3720000048828, 85.50800000732421, 86.34399998779297, 86.40399999267578, 86.84399997558593, 87.0279999975586, 87.53600001464844, 87.66000001464843, 87.70000000976563, 87.84400001220703, 88.05599999755859, 88.73599999511718, 88.77600001464843, 88.49999999267578, 88.82799998779296, 89.2200000048828, 89.372, 89.53999999511718, 89.37600000732422, 89.46799999267579, 90.10399998046876, 90.20799999755859, 90.36000000976563, 90.48000000732422, 90.54399999267578, 90.90399998535156, 90.71999999511719, 91.02800001220703, 91.02399998535157, 91.15599997802734, 91.33599998535156, 91.33599997314452, 91.49999998291015, 91.70799999023437, 91.43199999267578, 91.72799997802734, 91.91199997558594, 91.84799998291015, 92.27599997314454, 92.17199997558593, 92.34399998291016, 92.71599999511719, 92.35199998535157, 92.41599999267578, 92.86399998535157, 92.66399997558594, 92.75200001953125, 92.65999998535156, 93.37599997314453, 93.35599997314453, 92.90800001953124, 93.71599997070312, 93.26000001464844, 93.56799997070313, 93.47999997314453, 93.38400001708985, 93.77999997070313, 93.69199999267578, 93.78799997314454, 93.85599998291016, 94.29999998046875, 93.79199998535157, 94.16799997558594, 94.54799997314453, 94.36799997070312, 94.17199998046875, 94.60800001708985, 94.97599998535156, 94.51999997070313, 94.65999998291015, 94.74400001708985, 94.99599998291016, 95.05200001708984, 95.31999997070312, 95.31599997314453, 95.27199997314453, 95.34000001953125, 95.43199997558594, 95.58400001464844, 95.79199997070313, 95.67600001708985, 95.85600001220703, 95.71600001708984, 96.41200001708984, 96.24000001220703, 95.87200001464844, 96.32400001708984, 95.77999997558594, 96.18800001464844, 96.30400001708985, 96.56000001220703, 96.37599998291016, 96.45200001953125, 96.98000000488281, 96.87600001708985, 96.98800001953126, 96.92400001220703, 97.13999997314453, 96.82400001953125, 96.90800001464844, 97.28000001708985, 97.16800001708984, 97.24400001220702, 97.56000001220703, 97.44000001464843, 97.62000000732422, 97.75200000976562, 97.74800000976562, 97.74800000488281, 97.88400000488281, 97.9240000024414, 98.13200000976562, 98.37200000732422, 98.27200001220703, 98.06800001220704, 97.94800001220703, 98.26000000488281, 98.4960000024414, 98.64800000488282, 98.3640000024414, 98.78400000488281, 98.8600000048828, 98.9880000048828, 98.89200001220703, 98.84000000732422, 98.90800000244141, 99.13200000732422, 98.9960000024414, 99.184, 99.1800000024414, 99.32000000732423, 99.38400000244141, 99.34400000488282, 99.31600000488281, 99.364, 99.45200000732422, 99.53200000488282, 99.588, 99.6080000024414, 99.54800000244141, 99.58400000732422, 99.548, 99.64000000244141, 99.70800000244141, 99.836, 99.86, 99.82400000244141, 99.836, 99.9000000024414, 99.908, 99.88, 99.92, 99.92800000244141, 99.928, 99.94, 99.948, 99.944, 99.928, 99.94400000244141, 99.98, 99.984, 99.98, 99.976, 99.97600000244141, 99.968, 99.952, 99.98, 99.976, 99.98, 99.976, 99.968, 99.992, 99.976, 99.984, 99.996, 99.992, 99.968, 99.98, 99.992, 99.976, 99.988, 99.992, 99.988, 100.0], 'eval_acc1es': [38.51600000610352, 49.27200000366211, 46.76799999389648, 60.871999985351565, 63.103999985351564, 65.66000000244141, 71.21999998535156, 55.620000003662106, 73.15200000732422, 73.65600001953125, 66.81600000732422, 77.7039999975586, 78.96399999267578, 76.18799997802735, 78.75599999267578, 69.17599997558594, 66.54799998046875, 75.86799998779297, 76.66399998046874, 80.01199997314453, 72.9839999975586, 77.1320000024414, 75.52400000488281, 67.74399998535156, 80.58799998046875, 69.08399997558594, 81.54400000976563, 76.53600000488281, 80.61999998046875, 80.57199999267579, 82.13999997558594, 82.08000000488282, 73.69200001464844, 80.06399999511719, 73.90400000976562, 74.86000001953126, 81.06400001220703, 77.45999999023438, 81.50399998046875, 83.48000000488281, 81.73199997802735, 76.72800000732421, 83.20400000488281, 83.36799998779297, 82.13999997070313, 81.19999999267579, 74.2359999975586, 84.84400001220703, 81.61200001464844, 78.72799998291016, 83.35999999511719, 83.88000001220703, 82.88799998046875, 84.40000000732422, 84.30400001464844, 81.15199997070313, 81.75999997314453, 82.65599998046875, 83.17599997314453, 79.41599997558593, 84.47199997314453, 82.31199997802734, 83.25999998046875, 83.25199997314454, 80.66799999267577, 84.57999997558593, 84.7160000024414, 83.77599997070313, 81.75999998046875, 82.80399997558594, 80.15999997558593, 82.90400001464843, 79.35199998779296, 84.03600000976563, 82.00800001953125, 80.91199998291016, 85.54800000732422, 83.41199998535156, 85.76799998779296, 83.61600000244141, 84.38800001464844, 82.76800001953124, 84.40799997802735, 82.62799997070313, 83.02000001708984, 80.77599997070313, 85.40000001220703, 82.55599997802734, 84.42800001464843, 85.06400001464844, 83.55999997802735, 84.60399999511719, 84.22799997802734, 85.36800001220703, 84.58000001953125, 86.468, 85.51200000488281, 86.06799998535156, 87.348, 85.9119999975586, 84.84000001708985, 86.84799999755859, 84.62800000244141, 80.93599997802734, 81.90400000732421, 86.95600000488281, 85.02800000976562, 85.33600001220704, 87.64400001708984, 86.00000001953126, 86.12399999511719, 85.54399999023437, 85.30000000976563, 85.85199999023438, 87.0399999975586, 85.51200001220703, 86.54800001708985, 87.27199998779297, 87.98799999267578, 87.65600000732422, 88.41599997802734, 84.17999997314453, 86.33200000488281, 85.904, 87.26400001220703, 87.84399997558593, 86.94800001953125, 86.77200000488281, 84.48000001464844, 88.31199998535156, 87.18800000976563, 86.44400000244141, 88.12399999023438, 88.84799999023437, 87.70399998535156, 88.54000000732422, 87.72399997070312, 89.07599999511719, 88.33199997070312, 87.39599998291015, 88.49999999267578, 89.39199998535156, 88.23199999511719, 88.49599999267578, 88.39199999511719, 89.4359999975586, 89.1680000024414, 89.19999998779296, 89.05600001220704, 89.65199998046874, 89.05199999267577, 89.77199998779297, 89.8559999975586, 89.94000000488282, 89.86799999023438, 89.69599999023437, 88.88399998779298, 89.9599999975586, 90.06799998779297, 90.39999998046875, 90.82799999511718, 90.72799997802734, 90.46800001953125, 90.89999998046875, 90.96799999267579, 91.09999998046875, 90.77199998291016, 90.99599999023438, 91.02799998779297, 91.06799999267578, 91.05999999023437, 91.08399998291016, 91.18399998535156, 91.03599998046874, 91.21599998535156, 91.22399998779296, 91.29199997802735, 91.23999998046875, 91.27599997314454, 91.24399998291015, 91.31599998291016, 91.33199999023438, 91.36399998291016, 91.41600000488282, 91.39600001953124, 91.40399998535156, 91.37599997314453, 91.3919999975586, 91.41599998535156, 91.42, 91.47599999267578, 91.49199999023438, 91.47599998046876, 91.47999998291016, 91.51599999267579, 91.45200001953125, 91.48399997558593, 91.48799998535156, 91.46399999023437, 91.46399999267578, 91.33], 'cost_info': {'flops': 117.88353, 'params': 0.830426, 'latency': 0.01909610158518741, 'train_time': 11.704105277856192}}}\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 200 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 201 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 202 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 203 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 204 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 205 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 206 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 207 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 208 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 209 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 210 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 211 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 212 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 213 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 214 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 215 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 216 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 217 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 218 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:44:27 nl.defaults.trainer]: \u001b[0mEpoch 219 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 220, Anytime results: {'cifar10-valid': {'train_losses': [1.797979532775879, 1.2527252103996276, 1.0138580317115784, 0.8822913989257812, 0.7803608722114563, 0.7023457984924316, 0.6497955482292175, 0.6059390458106995, 0.5677761807537078, 0.538056489944458, 0.515950230770111, 0.4948751167488098, 0.4747195296764374, 0.4572546643924713, 0.445253247756958, 0.4359080542373657, 0.4239110640716553, 0.41368696506500247, 0.3971407129478455, 0.38833855127334593, 0.3788480834960937, 0.3740516341018677, 0.35861263020515444, 0.3550860090827942, 0.35471325862884523, 0.3511313292884827, 0.3420170811271667, 0.33029187686920164, 0.32096393228530884, 0.3264443295955658, 0.3209636632442474, 0.31464752191543577, 0.3025444029521942, 0.29950268094062804, 0.2968454804801941, 0.30367620081901553, 0.2844067573404312, 0.28439875590324404, 0.2781640834140778, 0.2739880220317841, 0.26975711678504943, 0.26009569576740266, 0.26850710664749144, 0.2599183919286728, 0.2559084771347046, 0.25671464601039884, 0.25152616675376893, 0.24927711655139922, 0.247728226518631, 0.24402085838317872, 0.24527329946517945, 0.2376989866876602, 0.23035390013694762, 0.2327466607093811, 0.22429453383922576, 0.2272956440448761, 0.22197500553131103, 0.21436945312976838, 0.21928964067459106, 0.21290034994125367, 0.20822054827213288, 0.21389376505851745, 0.20563746623039245, 0.2099708962535858, 0.19158048898220062, 0.19615204340457917, 0.1982648743581772, 0.1887348501777649, 0.19475696102142334, 0.1842686238336563, 0.18677605671405792, 0.18652738688468934, 0.18188076397895814, 0.18016700853824616, 0.17823464753627777, 0.18016266384124757, 0.16617573895454407, 0.1770302580022812, 0.17052061563491822, 0.15902811944961548, 0.16233001423358917, 0.16556088306903838, 0.15680421692848207, 0.1498578377342224, 0.15635097947120666, 0.15310042744636534, 0.15306200007438658, 0.14491507052898406, 0.1416260453414917, 0.13550126110076904, 0.1392497732591629, 0.13626620844841003, 0.13300940950632095, 0.13275603595256805, 0.12830855484008788, 0.12408610872745514, 0.12531209909915925, 0.12207098999977112, 0.1216279049706459, 0.10974599875926971, 0.11079829895496368, 0.11904660460948945, 0.10809563687324523, 0.11965358115673065, 0.11427250968933106, 0.10849766419887542, 0.10218072737693787, 0.10716040850162506, 0.10477651658535003, 0.09131185996413231, 0.09049850377559662, 0.09137351614952087, 0.0909367332983017, 0.08757329261779785, 0.0899801014661789, 0.08972211226701736, 0.08128207237005233, 0.08392260439395904, 0.07897669915676117, 0.07467384212732316, 0.07569570093631744, 0.0694864012169838, 0.0675577897644043, 0.06855287613153457, 0.0652096102821827, 0.06380558840870858, 0.06269203025877476, 0.056387432240247726, 0.05073259930610657, 0.05295789412975311, 0.06122023828983307, 0.05983238134384155, 0.050557514559030535, 0.04516359554290771, 0.04152287001490593, 0.04919338520169258, 0.037906546899080275, 0.03719876957416535, 0.03342186244606972, 0.03439499699473381, 0.03459258997559547, 0.03468540014445782, 0.028545279636383057, 0.03216642561376095, 0.02676758377045393, 0.025878876812458037, 0.0214473418533802, 0.021104339045286177, 0.021747494243383406, 0.021283978564739226, 0.019705448406785727, 0.018253158379793168, 0.015280498052239418, 0.0137871942422539, 0.014443003076314926, 0.01408235429942608, 0.013874327067136764, 0.01428306491613388, 0.012863019816875458, 0.010711087912917137, 0.007742220239043236, 0.006511413640901446, 0.006719038946032524, 0.006903528813645244, 0.004742787101864814, 0.004861924066767096, 0.005476148186177015, 0.0038102409364283085, 0.0039400346457958224, 0.003776025571450591, 0.004068971053361892, 0.002876078786998987, 0.0030355332847684623, 0.0035315019605308773, 0.002837982722520828, 0.002136290045157075, 0.0019352131270617247, 0.0021824218651652337, 0.002028700380474329, 0.0019801752346754074, 0.0021660784274339677, 0.0022002970218658446, 0.0019479305266216398, 0.002038802414163947, 0.0019461702918633819, 0.001907505464591086, 0.0021021232601627707, 0.0016369401945173741, 0.0018257959835976361, 0.0019210409358888865, 0.001416360531039536, 0.0015833961294218898, 0.0017988794137910008, 0.0015769814006984233, 0.001505851459875703, 0.0018100922302156687, 0.0014608621790260076, 0.0016108034229651094, 0.0015840492541342973, 0.0013324481489509345], 'eval_losses': [1.6272298514175414, 1.719287733230591, 1.7449889614105225, 1.133109687538147, 1.1186404991149903, 1.0821128437423706, 0.847026729850769, 1.5927908081817628, 0.8209507646751404, 0.7648674670219422, 1.0775786195755004, 0.6779091291427612, 0.6390487702178955, 0.7489264928436279, 0.6666688264083862, 1.0245877558135987, 1.1595384635925292, 0.723676893119812, 0.7669336923980713, 0.6112452599334717, 0.9660843383407592, 0.7343378405952453, 0.840818124294281, 1.2604200606918334, 0.6063524735832214, 1.159623742980957, 0.6039365092849731, 0.8497507237052917, 0.628081222114563, 0.6216542652893067, 0.5560605820655823, 0.5865489265823364, 0.9597786441802979, 0.6361585730934143, 0.9626845142745971, 0.844418583946228, 0.6500097342872619, 0.7736053534698486, 0.5939313138771057, 0.5072878143882752, 0.6224685645675659, 0.8204889801216125, 0.5511082135486602, 0.5362294416618347, 0.570758188419342, 0.6172440949440002, 0.9451023908996582, 0.47864262647628786, 0.610565881061554, 0.7115218802642822, 0.547065057926178, 0.5347714776134491, 0.5567891032409668, 0.5078570296478272, 0.5192969712829589, 0.6586684846878051, 0.6104187334823609, 0.583992243309021, 0.571166090927124, 0.729368978061676, 0.5097968811225891, 0.597749605178833, 0.5448352932357788, 0.5565177823829651, 0.6815717866516113, 0.5223795333480835, 0.5291338024044037, 0.5593303778266907, 0.6371515368461609, 0.5649146770095825, 0.7654560852050781, 0.6053906892967225, 0.8099864686775208, 0.5623643120193481, 0.6302320753669739, 0.7100821681594849, 0.5042611715888977, 0.5859966699981689, 0.4900874222660065, 0.5865842864894867, 0.5524932344436646, 0.6036392141723633, 0.5771377402496338, 0.635603153705597, 0.6008246605110168, 0.78836101770401, 0.5175824388122559, 0.639802907295227, 0.5585134193229675, 0.5268317921829223, 0.5819013167953491, 0.5606769778060913, 0.5718329856300354, 0.5630345753669739, 0.5855106465911866, 0.4912681079673767, 0.54175859998703, 0.514786814107895, 0.4591868642425537, 0.5052623636817932, 0.5783377849388123, 0.5009782519340515, 0.5888236622619629, 0.762264783744812, 0.7242392131233215, 0.49246752378463743, 0.554996236963272, 0.5442889282417297, 0.4409437468338013, 0.5605955778503418, 0.5315693290710449, 0.5794152967357635, 0.5857491951942444, 0.5708944032287597, 0.5043705623722077, 0.5632711613273621, 0.5163035422515869, 0.4966876087188721, 0.4505663089752197, 0.4704933899116516, 0.45981528732299803, 0.6531034126091003, 0.5183848677921296, 0.5909099923610688, 0.5152843837165832, 0.49619828419685363, 0.5475378018951416, 0.5393404815101623, 0.7201345665931702, 0.4824238876056671, 0.5215795503044128, 0.5685945818328857, 0.5089179008483887, 0.47145085259437564, 0.5472192948913575, 0.4900347399139404, 0.540964811782837, 0.46170505146026614, 0.5063307063484191, 0.5666370886611939, 0.48203581071853635, 0.44972750431060793, 0.5232554189109803, 0.4906134189224243, 0.5257716849899292, 0.45284362602233885, 0.4711797005844116, 0.48627261313438414, 0.4987119895553589, 0.466983223361969, 0.49265243516921997, 0.4703731024837494, 0.463229135723114, 0.460639780960083, 0.47536511048316954, 0.4933408259010315, 0.5230341455554962, 0.4691208839035034, 0.4683770147895813, 0.4554304603385925, 0.4363482038497925, 0.4507359668636322, 0.47246342094421384, 0.44265450010299684, 0.44240144773483275, 0.4374107486915588, 0.45024260966300966, 0.4394589510059357, 0.4438844661808014, 0.4459243761634827, 0.4445250177764893, 0.4392674104118347, 0.43809965566635134, 0.4435059818077087, 0.44061508752822875, 0.43598945977211, 0.4353007004642487, 0.4364056324005127, 0.436138900680542, 0.44131933745384216, 0.4382879079723358, 0.43560168815612793, 0.4378226725196838, 0.43351163749694827, 0.4295745631122589, 0.43166758422851564, 0.43342907007217407, 0.43806649894714356, 0.433157393579483, 0.4312484454727173, 0.43233252582550047, 0.43136490835189817, 0.432343833770752, 0.430613657617569, 0.43042267800331113, 0.43180035969734193, 0.4328012317943573, 0.4323063223934174, 0.43098210398674014, 0.4329616625976562, 0.4390562599182129], 'train_acc1es': [31.436000007324218, 54.619999978027344, 63.41599999755859, 68.73600000976562, 72.56400001464844, 75.38399997558594, 77.32399997802735, 78.93999998535156, 80.21200001464844, 81.58399997802735, 81.92799998779297, 83.02400001708985, 83.64800000732421, 84.40800001464844, 84.43200001464844, 85.00000001220702, 85.3720000048828, 85.50800000732421, 86.34399998779297, 86.40399999267578, 86.84399997558593, 87.0279999975586, 87.53600001464844, 87.66000001464843, 87.70000000976563, 87.84400001220703, 88.05599999755859, 88.73599999511718, 88.77600001464843, 88.49999999267578, 88.82799998779296, 89.2200000048828, 89.372, 89.53999999511718, 89.37600000732422, 89.46799999267579, 90.10399998046876, 90.20799999755859, 90.36000000976563, 90.48000000732422, 90.54399999267578, 90.90399998535156, 90.71999999511719, 91.02800001220703, 91.02399998535157, 91.15599997802734, 91.33599998535156, 91.33599997314452, 91.49999998291015, 91.70799999023437, 91.43199999267578, 91.72799997802734, 91.91199997558594, 91.84799998291015, 92.27599997314454, 92.17199997558593, 92.34399998291016, 92.71599999511719, 92.35199998535157, 92.41599999267578, 92.86399998535157, 92.66399997558594, 92.75200001953125, 92.65999998535156, 93.37599997314453, 93.35599997314453, 92.90800001953124, 93.71599997070312, 93.26000001464844, 93.56799997070313, 93.47999997314453, 93.38400001708985, 93.77999997070313, 93.69199999267578, 93.78799997314454, 93.85599998291016, 94.29999998046875, 93.79199998535157, 94.16799997558594, 94.54799997314453, 94.36799997070312, 94.17199998046875, 94.60800001708985, 94.97599998535156, 94.51999997070313, 94.65999998291015, 94.74400001708985, 94.99599998291016, 95.05200001708984, 95.31999997070312, 95.31599997314453, 95.27199997314453, 95.34000001953125, 95.43199997558594, 95.58400001464844, 95.79199997070313, 95.67600001708985, 95.85600001220703, 95.71600001708984, 96.41200001708984, 96.24000001220703, 95.87200001464844, 96.32400001708984, 95.77999997558594, 96.18800001464844, 96.30400001708985, 96.56000001220703, 96.37599998291016, 96.45200001953125, 96.98000000488281, 96.87600001708985, 96.98800001953126, 96.92400001220703, 97.13999997314453, 96.82400001953125, 96.90800001464844, 97.28000001708985, 97.16800001708984, 97.24400001220702, 97.56000001220703, 97.44000001464843, 97.62000000732422, 97.75200000976562, 97.74800000976562, 97.74800000488281, 97.88400000488281, 97.9240000024414, 98.13200000976562, 98.37200000732422, 98.27200001220703, 98.06800001220704, 97.94800001220703, 98.26000000488281, 98.4960000024414, 98.64800000488282, 98.3640000024414, 98.78400000488281, 98.8600000048828, 98.9880000048828, 98.89200001220703, 98.84000000732422, 98.90800000244141, 99.13200000732422, 98.9960000024414, 99.184, 99.1800000024414, 99.32000000732423, 99.38400000244141, 99.34400000488282, 99.31600000488281, 99.364, 99.45200000732422, 99.53200000488282, 99.588, 99.6080000024414, 99.54800000244141, 99.58400000732422, 99.548, 99.64000000244141, 99.70800000244141, 99.836, 99.86, 99.82400000244141, 99.836, 99.9000000024414, 99.908, 99.88, 99.92, 99.92800000244141, 99.928, 99.94, 99.948, 99.944, 99.928, 99.94400000244141, 99.98, 99.984, 99.98, 99.976, 99.97600000244141, 99.968, 99.952, 99.98, 99.976, 99.98, 99.976, 99.968, 99.992, 99.976, 99.984, 99.996, 99.992, 99.968, 99.98, 99.992, 99.976, 99.988, 99.992, 99.988, 100.0], 'eval_acc1es': [38.51600000610352, 49.27200000366211, 46.76799999389648, 60.871999985351565, 63.103999985351564, 65.66000000244141, 71.21999998535156, 55.620000003662106, 73.15200000732422, 73.65600001953125, 66.81600000732422, 77.7039999975586, 78.96399999267578, 76.18799997802735, 78.75599999267578, 69.17599997558594, 66.54799998046875, 75.86799998779297, 76.66399998046874, 80.01199997314453, 72.9839999975586, 77.1320000024414, 75.52400000488281, 67.74399998535156, 80.58799998046875, 69.08399997558594, 81.54400000976563, 76.53600000488281, 80.61999998046875, 80.57199999267579, 82.13999997558594, 82.08000000488282, 73.69200001464844, 80.06399999511719, 73.90400000976562, 74.86000001953126, 81.06400001220703, 77.45999999023438, 81.50399998046875, 83.48000000488281, 81.73199997802735, 76.72800000732421, 83.20400000488281, 83.36799998779297, 82.13999997070313, 81.19999999267579, 74.2359999975586, 84.84400001220703, 81.61200001464844, 78.72799998291016, 83.35999999511719, 83.88000001220703, 82.88799998046875, 84.40000000732422, 84.30400001464844, 81.15199997070313, 81.75999997314453, 82.65599998046875, 83.17599997314453, 79.41599997558593, 84.47199997314453, 82.31199997802734, 83.25999998046875, 83.25199997314454, 80.66799999267577, 84.57999997558593, 84.7160000024414, 83.77599997070313, 81.75999998046875, 82.80399997558594, 80.15999997558593, 82.90400001464843, 79.35199998779296, 84.03600000976563, 82.00800001953125, 80.91199998291016, 85.54800000732422, 83.41199998535156, 85.76799998779296, 83.61600000244141, 84.38800001464844, 82.76800001953124, 84.40799997802735, 82.62799997070313, 83.02000001708984, 80.77599997070313, 85.40000001220703, 82.55599997802734, 84.42800001464843, 85.06400001464844, 83.55999997802735, 84.60399999511719, 84.22799997802734, 85.36800001220703, 84.58000001953125, 86.468, 85.51200000488281, 86.06799998535156, 87.348, 85.9119999975586, 84.84000001708985, 86.84799999755859, 84.62800000244141, 80.93599997802734, 81.90400000732421, 86.95600000488281, 85.02800000976562, 85.33600001220704, 87.64400001708984, 86.00000001953126, 86.12399999511719, 85.54399999023437, 85.30000000976563, 85.85199999023438, 87.0399999975586, 85.51200001220703, 86.54800001708985, 87.27199998779297, 87.98799999267578, 87.65600000732422, 88.41599997802734, 84.17999997314453, 86.33200000488281, 85.904, 87.26400001220703, 87.84399997558593, 86.94800001953125, 86.77200000488281, 84.48000001464844, 88.31199998535156, 87.18800000976563, 86.44400000244141, 88.12399999023438, 88.84799999023437, 87.70399998535156, 88.54000000732422, 87.72399997070312, 89.07599999511719, 88.33199997070312, 87.39599998291015, 88.49999999267578, 89.39199998535156, 88.23199999511719, 88.49599999267578, 88.39199999511719, 89.4359999975586, 89.1680000024414, 89.19999998779296, 89.05600001220704, 89.65199998046874, 89.05199999267577, 89.77199998779297, 89.8559999975586, 89.94000000488282, 89.86799999023438, 89.69599999023437, 88.88399998779298, 89.9599999975586, 90.06799998779297, 90.39999998046875, 90.82799999511718, 90.72799997802734, 90.46800001953125, 90.89999998046875, 90.96799999267579, 91.09999998046875, 90.77199998291016, 90.99599999023438, 91.02799998779297, 91.06799999267578, 91.05999999023437, 91.08399998291016, 91.18399998535156, 91.03599998046874, 91.21599998535156, 91.22399998779296, 91.29199997802735, 91.23999998046875, 91.27599997314454, 91.24399998291015, 91.31599998291016, 91.33199999023438, 91.36399998291016, 91.41600000488282, 91.39600001953124, 91.40399998535156, 91.37599997314453, 91.3919999975586, 91.41599998535156, 91.42, 91.47599999267578, 91.49199999023438, 91.47599998046876, 91.47999998291016, 91.51599999267579, 91.45200001953125, 91.48399997558593, 91.48799998535156, 91.46399999023437, 91.46399999267578, 91.33], 'cost_info': {'flops': 117.88353, 'params': 0.830426, 'latency': 0.01909610158518741, 'train_time': 11.704105277856192}}}\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 220 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 221 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 222 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 223 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 224 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 225 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 226 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 227 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 228 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 229 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 230 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 231 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 232 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 233 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 234 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 235 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 236 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 237 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 238 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:45:23 nl.defaults.trainer]: \u001b[0mEpoch 239 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 240, Anytime results: {'cifar10-valid': {'train_losses': [1.797979532775879, 1.2527252103996276, 1.0138580317115784, 0.8822913989257812, 0.7803608722114563, 0.7023457984924316, 0.6497955482292175, 0.6059390458106995, 0.5677761807537078, 0.538056489944458, 0.515950230770111, 0.4948751167488098, 0.4747195296764374, 0.4572546643924713, 0.445253247756958, 0.4359080542373657, 0.4239110640716553, 0.41368696506500247, 0.3971407129478455, 0.38833855127334593, 0.3788480834960937, 0.3740516341018677, 0.35861263020515444, 0.3550860090827942, 0.35471325862884523, 0.3511313292884827, 0.3420170811271667, 0.33029187686920164, 0.32096393228530884, 0.3264443295955658, 0.3209636632442474, 0.31464752191543577, 0.3025444029521942, 0.29950268094062804, 0.2968454804801941, 0.30367620081901553, 0.2844067573404312, 0.28439875590324404, 0.2781640834140778, 0.2739880220317841, 0.26975711678504943, 0.26009569576740266, 0.26850710664749144, 0.2599183919286728, 0.2559084771347046, 0.25671464601039884, 0.25152616675376893, 0.24927711655139922, 0.247728226518631, 0.24402085838317872, 0.24527329946517945, 0.2376989866876602, 0.23035390013694762, 0.2327466607093811, 0.22429453383922576, 0.2272956440448761, 0.22197500553131103, 0.21436945312976838, 0.21928964067459106, 0.21290034994125367, 0.20822054827213288, 0.21389376505851745, 0.20563746623039245, 0.2099708962535858, 0.19158048898220062, 0.19615204340457917, 0.1982648743581772, 0.1887348501777649, 0.19475696102142334, 0.1842686238336563, 0.18677605671405792, 0.18652738688468934, 0.18188076397895814, 0.18016700853824616, 0.17823464753627777, 0.18016266384124757, 0.16617573895454407, 0.1770302580022812, 0.17052061563491822, 0.15902811944961548, 0.16233001423358917, 0.16556088306903838, 0.15680421692848207, 0.1498578377342224, 0.15635097947120666, 0.15310042744636534, 0.15306200007438658, 0.14491507052898406, 0.1416260453414917, 0.13550126110076904, 0.1392497732591629, 0.13626620844841003, 0.13300940950632095, 0.13275603595256805, 0.12830855484008788, 0.12408610872745514, 0.12531209909915925, 0.12207098999977112, 0.1216279049706459, 0.10974599875926971, 0.11079829895496368, 0.11904660460948945, 0.10809563687324523, 0.11965358115673065, 0.11427250968933106, 0.10849766419887542, 0.10218072737693787, 0.10716040850162506, 0.10477651658535003, 0.09131185996413231, 0.09049850377559662, 0.09137351614952087, 0.0909367332983017, 0.08757329261779785, 0.0899801014661789, 0.08972211226701736, 0.08128207237005233, 0.08392260439395904, 0.07897669915676117, 0.07467384212732316, 0.07569570093631744, 0.0694864012169838, 0.0675577897644043, 0.06855287613153457, 0.0652096102821827, 0.06380558840870858, 0.06269203025877476, 0.056387432240247726, 0.05073259930610657, 0.05295789412975311, 0.06122023828983307, 0.05983238134384155, 0.050557514559030535, 0.04516359554290771, 0.04152287001490593, 0.04919338520169258, 0.037906546899080275, 0.03719876957416535, 0.03342186244606972, 0.03439499699473381, 0.03459258997559547, 0.03468540014445782, 0.028545279636383057, 0.03216642561376095, 0.02676758377045393, 0.025878876812458037, 0.0214473418533802, 0.021104339045286177, 0.021747494243383406, 0.021283978564739226, 0.019705448406785727, 0.018253158379793168, 0.015280498052239418, 0.0137871942422539, 0.014443003076314926, 0.01408235429942608, 0.013874327067136764, 0.01428306491613388, 0.012863019816875458, 0.010711087912917137, 0.007742220239043236, 0.006511413640901446, 0.006719038946032524, 0.006903528813645244, 0.004742787101864814, 0.004861924066767096, 0.005476148186177015, 0.0038102409364283085, 0.0039400346457958224, 0.003776025571450591, 0.004068971053361892, 0.002876078786998987, 0.0030355332847684623, 0.0035315019605308773, 0.002837982722520828, 0.002136290045157075, 0.0019352131270617247, 0.0021824218651652337, 0.002028700380474329, 0.0019801752346754074, 0.0021660784274339677, 0.0022002970218658446, 0.0019479305266216398, 0.002038802414163947, 0.0019461702918633819, 0.001907505464591086, 0.0021021232601627707, 0.0016369401945173741, 0.0018257959835976361, 0.0019210409358888865, 0.001416360531039536, 0.0015833961294218898, 0.0017988794137910008, 0.0015769814006984233, 0.001505851459875703, 0.0018100922302156687, 0.0014608621790260076, 0.0016108034229651094, 0.0015840492541342973, 0.0013324481489509345], 'eval_losses': [1.6272298514175414, 1.719287733230591, 1.7449889614105225, 1.133109687538147, 1.1186404991149903, 1.0821128437423706, 0.847026729850769, 1.5927908081817628, 0.8209507646751404, 0.7648674670219422, 1.0775786195755004, 0.6779091291427612, 0.6390487702178955, 0.7489264928436279, 0.6666688264083862, 1.0245877558135987, 1.1595384635925292, 0.723676893119812, 0.7669336923980713, 0.6112452599334717, 0.9660843383407592, 0.7343378405952453, 0.840818124294281, 1.2604200606918334, 0.6063524735832214, 1.159623742980957, 0.6039365092849731, 0.8497507237052917, 0.628081222114563, 0.6216542652893067, 0.5560605820655823, 0.5865489265823364, 0.9597786441802979, 0.6361585730934143, 0.9626845142745971, 0.844418583946228, 0.6500097342872619, 0.7736053534698486, 0.5939313138771057, 0.5072878143882752, 0.6224685645675659, 0.8204889801216125, 0.5511082135486602, 0.5362294416618347, 0.570758188419342, 0.6172440949440002, 0.9451023908996582, 0.47864262647628786, 0.610565881061554, 0.7115218802642822, 0.547065057926178, 0.5347714776134491, 0.5567891032409668, 0.5078570296478272, 0.5192969712829589, 0.6586684846878051, 0.6104187334823609, 0.583992243309021, 0.571166090927124, 0.729368978061676, 0.5097968811225891, 0.597749605178833, 0.5448352932357788, 0.5565177823829651, 0.6815717866516113, 0.5223795333480835, 0.5291338024044037, 0.5593303778266907, 0.6371515368461609, 0.5649146770095825, 0.7654560852050781, 0.6053906892967225, 0.8099864686775208, 0.5623643120193481, 0.6302320753669739, 0.7100821681594849, 0.5042611715888977, 0.5859966699981689, 0.4900874222660065, 0.5865842864894867, 0.5524932344436646, 0.6036392141723633, 0.5771377402496338, 0.635603153705597, 0.6008246605110168, 0.78836101770401, 0.5175824388122559, 0.639802907295227, 0.5585134193229675, 0.5268317921829223, 0.5819013167953491, 0.5606769778060913, 0.5718329856300354, 0.5630345753669739, 0.5855106465911866, 0.4912681079673767, 0.54175859998703, 0.514786814107895, 0.4591868642425537, 0.5052623636817932, 0.5783377849388123, 0.5009782519340515, 0.5888236622619629, 0.762264783744812, 0.7242392131233215, 0.49246752378463743, 0.554996236963272, 0.5442889282417297, 0.4409437468338013, 0.5605955778503418, 0.5315693290710449, 0.5794152967357635, 0.5857491951942444, 0.5708944032287597, 0.5043705623722077, 0.5632711613273621, 0.5163035422515869, 0.4966876087188721, 0.4505663089752197, 0.4704933899116516, 0.45981528732299803, 0.6531034126091003, 0.5183848677921296, 0.5909099923610688, 0.5152843837165832, 0.49619828419685363, 0.5475378018951416, 0.5393404815101623, 0.7201345665931702, 0.4824238876056671, 0.5215795503044128, 0.5685945818328857, 0.5089179008483887, 0.47145085259437564, 0.5472192948913575, 0.4900347399139404, 0.540964811782837, 0.46170505146026614, 0.5063307063484191, 0.5666370886611939, 0.48203581071853635, 0.44972750431060793, 0.5232554189109803, 0.4906134189224243, 0.5257716849899292, 0.45284362602233885, 0.4711797005844116, 0.48627261313438414, 0.4987119895553589, 0.466983223361969, 0.49265243516921997, 0.4703731024837494, 0.463229135723114, 0.460639780960083, 0.47536511048316954, 0.4933408259010315, 0.5230341455554962, 0.4691208839035034, 0.4683770147895813, 0.4554304603385925, 0.4363482038497925, 0.4507359668636322, 0.47246342094421384, 0.44265450010299684, 0.44240144773483275, 0.4374107486915588, 0.45024260966300966, 0.4394589510059357, 0.4438844661808014, 0.4459243761634827, 0.4445250177764893, 0.4392674104118347, 0.43809965566635134, 0.4435059818077087, 0.44061508752822875, 0.43598945977211, 0.4353007004642487, 0.4364056324005127, 0.436138900680542, 0.44131933745384216, 0.4382879079723358, 0.43560168815612793, 0.4378226725196838, 0.43351163749694827, 0.4295745631122589, 0.43166758422851564, 0.43342907007217407, 0.43806649894714356, 0.433157393579483, 0.4312484454727173, 0.43233252582550047, 0.43136490835189817, 0.432343833770752, 0.430613657617569, 0.43042267800331113, 0.43180035969734193, 0.4328012317943573, 0.4323063223934174, 0.43098210398674014, 0.4329616625976562, 0.4390562599182129], 'train_acc1es': [31.436000007324218, 54.619999978027344, 63.41599999755859, 68.73600000976562, 72.56400001464844, 75.38399997558594, 77.32399997802735, 78.93999998535156, 80.21200001464844, 81.58399997802735, 81.92799998779297, 83.02400001708985, 83.64800000732421, 84.40800001464844, 84.43200001464844, 85.00000001220702, 85.3720000048828, 85.50800000732421, 86.34399998779297, 86.40399999267578, 86.84399997558593, 87.0279999975586, 87.53600001464844, 87.66000001464843, 87.70000000976563, 87.84400001220703, 88.05599999755859, 88.73599999511718, 88.77600001464843, 88.49999999267578, 88.82799998779296, 89.2200000048828, 89.372, 89.53999999511718, 89.37600000732422, 89.46799999267579, 90.10399998046876, 90.20799999755859, 90.36000000976563, 90.48000000732422, 90.54399999267578, 90.90399998535156, 90.71999999511719, 91.02800001220703, 91.02399998535157, 91.15599997802734, 91.33599998535156, 91.33599997314452, 91.49999998291015, 91.70799999023437, 91.43199999267578, 91.72799997802734, 91.91199997558594, 91.84799998291015, 92.27599997314454, 92.17199997558593, 92.34399998291016, 92.71599999511719, 92.35199998535157, 92.41599999267578, 92.86399998535157, 92.66399997558594, 92.75200001953125, 92.65999998535156, 93.37599997314453, 93.35599997314453, 92.90800001953124, 93.71599997070312, 93.26000001464844, 93.56799997070313, 93.47999997314453, 93.38400001708985, 93.77999997070313, 93.69199999267578, 93.78799997314454, 93.85599998291016, 94.29999998046875, 93.79199998535157, 94.16799997558594, 94.54799997314453, 94.36799997070312, 94.17199998046875, 94.60800001708985, 94.97599998535156, 94.51999997070313, 94.65999998291015, 94.74400001708985, 94.99599998291016, 95.05200001708984, 95.31999997070312, 95.31599997314453, 95.27199997314453, 95.34000001953125, 95.43199997558594, 95.58400001464844, 95.79199997070313, 95.67600001708985, 95.85600001220703, 95.71600001708984, 96.41200001708984, 96.24000001220703, 95.87200001464844, 96.32400001708984, 95.77999997558594, 96.18800001464844, 96.30400001708985, 96.56000001220703, 96.37599998291016, 96.45200001953125, 96.98000000488281, 96.87600001708985, 96.98800001953126, 96.92400001220703, 97.13999997314453, 96.82400001953125, 96.90800001464844, 97.28000001708985, 97.16800001708984, 97.24400001220702, 97.56000001220703, 97.44000001464843, 97.62000000732422, 97.75200000976562, 97.74800000976562, 97.74800000488281, 97.88400000488281, 97.9240000024414, 98.13200000976562, 98.37200000732422, 98.27200001220703, 98.06800001220704, 97.94800001220703, 98.26000000488281, 98.4960000024414, 98.64800000488282, 98.3640000024414, 98.78400000488281, 98.8600000048828, 98.9880000048828, 98.89200001220703, 98.84000000732422, 98.90800000244141, 99.13200000732422, 98.9960000024414, 99.184, 99.1800000024414, 99.32000000732423, 99.38400000244141, 99.34400000488282, 99.31600000488281, 99.364, 99.45200000732422, 99.53200000488282, 99.588, 99.6080000024414, 99.54800000244141, 99.58400000732422, 99.548, 99.64000000244141, 99.70800000244141, 99.836, 99.86, 99.82400000244141, 99.836, 99.9000000024414, 99.908, 99.88, 99.92, 99.92800000244141, 99.928, 99.94, 99.948, 99.944, 99.928, 99.94400000244141, 99.98, 99.984, 99.98, 99.976, 99.97600000244141, 99.968, 99.952, 99.98, 99.976, 99.98, 99.976, 99.968, 99.992, 99.976, 99.984, 99.996, 99.992, 99.968, 99.98, 99.992, 99.976, 99.988, 99.992, 99.988, 100.0], 'eval_acc1es': [38.51600000610352, 49.27200000366211, 46.76799999389648, 60.871999985351565, 63.103999985351564, 65.66000000244141, 71.21999998535156, 55.620000003662106, 73.15200000732422, 73.65600001953125, 66.81600000732422, 77.7039999975586, 78.96399999267578, 76.18799997802735, 78.75599999267578, 69.17599997558594, 66.54799998046875, 75.86799998779297, 76.66399998046874, 80.01199997314453, 72.9839999975586, 77.1320000024414, 75.52400000488281, 67.74399998535156, 80.58799998046875, 69.08399997558594, 81.54400000976563, 76.53600000488281, 80.61999998046875, 80.57199999267579, 82.13999997558594, 82.08000000488282, 73.69200001464844, 80.06399999511719, 73.90400000976562, 74.86000001953126, 81.06400001220703, 77.45999999023438, 81.50399998046875, 83.48000000488281, 81.73199997802735, 76.72800000732421, 83.20400000488281, 83.36799998779297, 82.13999997070313, 81.19999999267579, 74.2359999975586, 84.84400001220703, 81.61200001464844, 78.72799998291016, 83.35999999511719, 83.88000001220703, 82.88799998046875, 84.40000000732422, 84.30400001464844, 81.15199997070313, 81.75999997314453, 82.65599998046875, 83.17599997314453, 79.41599997558593, 84.47199997314453, 82.31199997802734, 83.25999998046875, 83.25199997314454, 80.66799999267577, 84.57999997558593, 84.7160000024414, 83.77599997070313, 81.75999998046875, 82.80399997558594, 80.15999997558593, 82.90400001464843, 79.35199998779296, 84.03600000976563, 82.00800001953125, 80.91199998291016, 85.54800000732422, 83.41199998535156, 85.76799998779296, 83.61600000244141, 84.38800001464844, 82.76800001953124, 84.40799997802735, 82.62799997070313, 83.02000001708984, 80.77599997070313, 85.40000001220703, 82.55599997802734, 84.42800001464843, 85.06400001464844, 83.55999997802735, 84.60399999511719, 84.22799997802734, 85.36800001220703, 84.58000001953125, 86.468, 85.51200000488281, 86.06799998535156, 87.348, 85.9119999975586, 84.84000001708985, 86.84799999755859, 84.62800000244141, 80.93599997802734, 81.90400000732421, 86.95600000488281, 85.02800000976562, 85.33600001220704, 87.64400001708984, 86.00000001953126, 86.12399999511719, 85.54399999023437, 85.30000000976563, 85.85199999023438, 87.0399999975586, 85.51200001220703, 86.54800001708985, 87.27199998779297, 87.98799999267578, 87.65600000732422, 88.41599997802734, 84.17999997314453, 86.33200000488281, 85.904, 87.26400001220703, 87.84399997558593, 86.94800001953125, 86.77200000488281, 84.48000001464844, 88.31199998535156, 87.18800000976563, 86.44400000244141, 88.12399999023438, 88.84799999023437, 87.70399998535156, 88.54000000732422, 87.72399997070312, 89.07599999511719, 88.33199997070312, 87.39599998291015, 88.49999999267578, 89.39199998535156, 88.23199999511719, 88.49599999267578, 88.39199999511719, 89.4359999975586, 89.1680000024414, 89.19999998779296, 89.05600001220704, 89.65199998046874, 89.05199999267577, 89.77199998779297, 89.8559999975586, 89.94000000488282, 89.86799999023438, 89.69599999023437, 88.88399998779298, 89.9599999975586, 90.06799998779297, 90.39999998046875, 90.82799999511718, 90.72799997802734, 90.46800001953125, 90.89999998046875, 90.96799999267579, 91.09999998046875, 90.77199998291016, 90.99599999023438, 91.02799998779297, 91.06799999267578, 91.05999999023437, 91.08399998291016, 91.18399998535156, 91.03599998046874, 91.21599998535156, 91.22399998779296, 91.29199997802735, 91.23999998046875, 91.27599997314454, 91.24399998291015, 91.31599998291016, 91.33199999023438, 91.36399998291016, 91.41600000488282, 91.39600001953124, 91.40399998535156, 91.37599997314453, 91.3919999975586, 91.41599998535156, 91.42, 91.47599999267578, 91.49199999023438, 91.47599998046876, 91.47999998291016, 91.51599999267579, 91.45200001953125, 91.48399997558593, 91.48799998535156, 91.46399999023437, 91.46399999267578, 91.33], 'cost_info': {'flops': 117.88353, 'params': 0.830426, 'latency': 0.01909610158518741, 'train_time': 11.704105277856192}}}\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 240 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 241 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 242 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 243 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 244 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 245 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 246 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 247 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 248 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 249 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 250 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 251 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 252 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 253 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 254 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 255 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 256 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 257 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 258 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:46:19 nl.defaults.trainer]: \u001b[0mEpoch 259 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 260, Anytime results: {'cifar10-valid': {'train_losses': [1.797979532775879, 1.2527252103996276, 1.0138580317115784, 0.8822913989257812, 0.7803608722114563, 0.7023457984924316, 0.6497955482292175, 0.6059390458106995, 0.5677761807537078, 0.538056489944458, 0.515950230770111, 0.4948751167488098, 0.4747195296764374, 0.4572546643924713, 0.445253247756958, 0.4359080542373657, 0.4239110640716553, 0.41368696506500247, 0.3971407129478455, 0.38833855127334593, 0.3788480834960937, 0.3740516341018677, 0.35861263020515444, 0.3550860090827942, 0.35471325862884523, 0.3511313292884827, 0.3420170811271667, 0.33029187686920164, 0.32096393228530884, 0.3264443295955658, 0.3209636632442474, 0.31464752191543577, 0.3025444029521942, 0.29950268094062804, 0.2968454804801941, 0.30367620081901553, 0.2844067573404312, 0.28439875590324404, 0.2781640834140778, 0.2739880220317841, 0.26975711678504943, 0.26009569576740266, 0.26850710664749144, 0.2599183919286728, 0.2559084771347046, 0.25671464601039884, 0.25152616675376893, 0.24927711655139922, 0.247728226518631, 0.24402085838317872, 0.24527329946517945, 0.2376989866876602, 0.23035390013694762, 0.2327466607093811, 0.22429453383922576, 0.2272956440448761, 0.22197500553131103, 0.21436945312976838, 0.21928964067459106, 0.21290034994125367, 0.20822054827213288, 0.21389376505851745, 0.20563746623039245, 0.2099708962535858, 0.19158048898220062, 0.19615204340457917, 0.1982648743581772, 0.1887348501777649, 0.19475696102142334, 0.1842686238336563, 0.18677605671405792, 0.18652738688468934, 0.18188076397895814, 0.18016700853824616, 0.17823464753627777, 0.18016266384124757, 0.16617573895454407, 0.1770302580022812, 0.17052061563491822, 0.15902811944961548, 0.16233001423358917, 0.16556088306903838, 0.15680421692848207, 0.1498578377342224, 0.15635097947120666, 0.15310042744636534, 0.15306200007438658, 0.14491507052898406, 0.1416260453414917, 0.13550126110076904, 0.1392497732591629, 0.13626620844841003, 0.13300940950632095, 0.13275603595256805, 0.12830855484008788, 0.12408610872745514, 0.12531209909915925, 0.12207098999977112, 0.1216279049706459, 0.10974599875926971, 0.11079829895496368, 0.11904660460948945, 0.10809563687324523, 0.11965358115673065, 0.11427250968933106, 0.10849766419887542, 0.10218072737693787, 0.10716040850162506, 0.10477651658535003, 0.09131185996413231, 0.09049850377559662, 0.09137351614952087, 0.0909367332983017, 0.08757329261779785, 0.0899801014661789, 0.08972211226701736, 0.08128207237005233, 0.08392260439395904, 0.07897669915676117, 0.07467384212732316, 0.07569570093631744, 0.0694864012169838, 0.0675577897644043, 0.06855287613153457, 0.0652096102821827, 0.06380558840870858, 0.06269203025877476, 0.056387432240247726, 0.05073259930610657, 0.05295789412975311, 0.06122023828983307, 0.05983238134384155, 0.050557514559030535, 0.04516359554290771, 0.04152287001490593, 0.04919338520169258, 0.037906546899080275, 0.03719876957416535, 0.03342186244606972, 0.03439499699473381, 0.03459258997559547, 0.03468540014445782, 0.028545279636383057, 0.03216642561376095, 0.02676758377045393, 0.025878876812458037, 0.0214473418533802, 0.021104339045286177, 0.021747494243383406, 0.021283978564739226, 0.019705448406785727, 0.018253158379793168, 0.015280498052239418, 0.0137871942422539, 0.014443003076314926, 0.01408235429942608, 0.013874327067136764, 0.01428306491613388, 0.012863019816875458, 0.010711087912917137, 0.007742220239043236, 0.006511413640901446, 0.006719038946032524, 0.006903528813645244, 0.004742787101864814, 0.004861924066767096, 0.005476148186177015, 0.0038102409364283085, 0.0039400346457958224, 0.003776025571450591, 0.004068971053361892, 0.002876078786998987, 0.0030355332847684623, 0.0035315019605308773, 0.002837982722520828, 0.002136290045157075, 0.0019352131270617247, 0.0021824218651652337, 0.002028700380474329, 0.0019801752346754074, 0.0021660784274339677, 0.0022002970218658446, 0.0019479305266216398, 0.002038802414163947, 0.0019461702918633819, 0.001907505464591086, 0.0021021232601627707, 0.0016369401945173741, 0.0018257959835976361, 0.0019210409358888865, 0.001416360531039536, 0.0015833961294218898, 0.0017988794137910008, 0.0015769814006984233, 0.001505851459875703, 0.0018100922302156687, 0.0014608621790260076, 0.0016108034229651094, 0.0015840492541342973, 0.0013324481489509345], 'eval_losses': [1.6272298514175414, 1.719287733230591, 1.7449889614105225, 1.133109687538147, 1.1186404991149903, 1.0821128437423706, 0.847026729850769, 1.5927908081817628, 0.8209507646751404, 0.7648674670219422, 1.0775786195755004, 0.6779091291427612, 0.6390487702178955, 0.7489264928436279, 0.6666688264083862, 1.0245877558135987, 1.1595384635925292, 0.723676893119812, 0.7669336923980713, 0.6112452599334717, 0.9660843383407592, 0.7343378405952453, 0.840818124294281, 1.2604200606918334, 0.6063524735832214, 1.159623742980957, 0.6039365092849731, 0.8497507237052917, 0.628081222114563, 0.6216542652893067, 0.5560605820655823, 0.5865489265823364, 0.9597786441802979, 0.6361585730934143, 0.9626845142745971, 0.844418583946228, 0.6500097342872619, 0.7736053534698486, 0.5939313138771057, 0.5072878143882752, 0.6224685645675659, 0.8204889801216125, 0.5511082135486602, 0.5362294416618347, 0.570758188419342, 0.6172440949440002, 0.9451023908996582, 0.47864262647628786, 0.610565881061554, 0.7115218802642822, 0.547065057926178, 0.5347714776134491, 0.5567891032409668, 0.5078570296478272, 0.5192969712829589, 0.6586684846878051, 0.6104187334823609, 0.583992243309021, 0.571166090927124, 0.729368978061676, 0.5097968811225891, 0.597749605178833, 0.5448352932357788, 0.5565177823829651, 0.6815717866516113, 0.5223795333480835, 0.5291338024044037, 0.5593303778266907, 0.6371515368461609, 0.5649146770095825, 0.7654560852050781, 0.6053906892967225, 0.8099864686775208, 0.5623643120193481, 0.6302320753669739, 0.7100821681594849, 0.5042611715888977, 0.5859966699981689, 0.4900874222660065, 0.5865842864894867, 0.5524932344436646, 0.6036392141723633, 0.5771377402496338, 0.635603153705597, 0.6008246605110168, 0.78836101770401, 0.5175824388122559, 0.639802907295227, 0.5585134193229675, 0.5268317921829223, 0.5819013167953491, 0.5606769778060913, 0.5718329856300354, 0.5630345753669739, 0.5855106465911866, 0.4912681079673767, 0.54175859998703, 0.514786814107895, 0.4591868642425537, 0.5052623636817932, 0.5783377849388123, 0.5009782519340515, 0.5888236622619629, 0.762264783744812, 0.7242392131233215, 0.49246752378463743, 0.554996236963272, 0.5442889282417297, 0.4409437468338013, 0.5605955778503418, 0.5315693290710449, 0.5794152967357635, 0.5857491951942444, 0.5708944032287597, 0.5043705623722077, 0.5632711613273621, 0.5163035422515869, 0.4966876087188721, 0.4505663089752197, 0.4704933899116516, 0.45981528732299803, 0.6531034126091003, 0.5183848677921296, 0.5909099923610688, 0.5152843837165832, 0.49619828419685363, 0.5475378018951416, 0.5393404815101623, 0.7201345665931702, 0.4824238876056671, 0.5215795503044128, 0.5685945818328857, 0.5089179008483887, 0.47145085259437564, 0.5472192948913575, 0.4900347399139404, 0.540964811782837, 0.46170505146026614, 0.5063307063484191, 0.5666370886611939, 0.48203581071853635, 0.44972750431060793, 0.5232554189109803, 0.4906134189224243, 0.5257716849899292, 0.45284362602233885, 0.4711797005844116, 0.48627261313438414, 0.4987119895553589, 0.466983223361969, 0.49265243516921997, 0.4703731024837494, 0.463229135723114, 0.460639780960083, 0.47536511048316954, 0.4933408259010315, 0.5230341455554962, 0.4691208839035034, 0.4683770147895813, 0.4554304603385925, 0.4363482038497925, 0.4507359668636322, 0.47246342094421384, 0.44265450010299684, 0.44240144773483275, 0.4374107486915588, 0.45024260966300966, 0.4394589510059357, 0.4438844661808014, 0.4459243761634827, 0.4445250177764893, 0.4392674104118347, 0.43809965566635134, 0.4435059818077087, 0.44061508752822875, 0.43598945977211, 0.4353007004642487, 0.4364056324005127, 0.436138900680542, 0.44131933745384216, 0.4382879079723358, 0.43560168815612793, 0.4378226725196838, 0.43351163749694827, 0.4295745631122589, 0.43166758422851564, 0.43342907007217407, 0.43806649894714356, 0.433157393579483, 0.4312484454727173, 0.43233252582550047, 0.43136490835189817, 0.432343833770752, 0.430613657617569, 0.43042267800331113, 0.43180035969734193, 0.4328012317943573, 0.4323063223934174, 0.43098210398674014, 0.4329616625976562, 0.4390562599182129], 'train_acc1es': [31.436000007324218, 54.619999978027344, 63.41599999755859, 68.73600000976562, 72.56400001464844, 75.38399997558594, 77.32399997802735, 78.93999998535156, 80.21200001464844, 81.58399997802735, 81.92799998779297, 83.02400001708985, 83.64800000732421, 84.40800001464844, 84.43200001464844, 85.00000001220702, 85.3720000048828, 85.50800000732421, 86.34399998779297, 86.40399999267578, 86.84399997558593, 87.0279999975586, 87.53600001464844, 87.66000001464843, 87.70000000976563, 87.84400001220703, 88.05599999755859, 88.73599999511718, 88.77600001464843, 88.49999999267578, 88.82799998779296, 89.2200000048828, 89.372, 89.53999999511718, 89.37600000732422, 89.46799999267579, 90.10399998046876, 90.20799999755859, 90.36000000976563, 90.48000000732422, 90.54399999267578, 90.90399998535156, 90.71999999511719, 91.02800001220703, 91.02399998535157, 91.15599997802734, 91.33599998535156, 91.33599997314452, 91.49999998291015, 91.70799999023437, 91.43199999267578, 91.72799997802734, 91.91199997558594, 91.84799998291015, 92.27599997314454, 92.17199997558593, 92.34399998291016, 92.71599999511719, 92.35199998535157, 92.41599999267578, 92.86399998535157, 92.66399997558594, 92.75200001953125, 92.65999998535156, 93.37599997314453, 93.35599997314453, 92.90800001953124, 93.71599997070312, 93.26000001464844, 93.56799997070313, 93.47999997314453, 93.38400001708985, 93.77999997070313, 93.69199999267578, 93.78799997314454, 93.85599998291016, 94.29999998046875, 93.79199998535157, 94.16799997558594, 94.54799997314453, 94.36799997070312, 94.17199998046875, 94.60800001708985, 94.97599998535156, 94.51999997070313, 94.65999998291015, 94.74400001708985, 94.99599998291016, 95.05200001708984, 95.31999997070312, 95.31599997314453, 95.27199997314453, 95.34000001953125, 95.43199997558594, 95.58400001464844, 95.79199997070313, 95.67600001708985, 95.85600001220703, 95.71600001708984, 96.41200001708984, 96.24000001220703, 95.87200001464844, 96.32400001708984, 95.77999997558594, 96.18800001464844, 96.30400001708985, 96.56000001220703, 96.37599998291016, 96.45200001953125, 96.98000000488281, 96.87600001708985, 96.98800001953126, 96.92400001220703, 97.13999997314453, 96.82400001953125, 96.90800001464844, 97.28000001708985, 97.16800001708984, 97.24400001220702, 97.56000001220703, 97.44000001464843, 97.62000000732422, 97.75200000976562, 97.74800000976562, 97.74800000488281, 97.88400000488281, 97.9240000024414, 98.13200000976562, 98.37200000732422, 98.27200001220703, 98.06800001220704, 97.94800001220703, 98.26000000488281, 98.4960000024414, 98.64800000488282, 98.3640000024414, 98.78400000488281, 98.8600000048828, 98.9880000048828, 98.89200001220703, 98.84000000732422, 98.90800000244141, 99.13200000732422, 98.9960000024414, 99.184, 99.1800000024414, 99.32000000732423, 99.38400000244141, 99.34400000488282, 99.31600000488281, 99.364, 99.45200000732422, 99.53200000488282, 99.588, 99.6080000024414, 99.54800000244141, 99.58400000732422, 99.548, 99.64000000244141, 99.70800000244141, 99.836, 99.86, 99.82400000244141, 99.836, 99.9000000024414, 99.908, 99.88, 99.92, 99.92800000244141, 99.928, 99.94, 99.948, 99.944, 99.928, 99.94400000244141, 99.98, 99.984, 99.98, 99.976, 99.97600000244141, 99.968, 99.952, 99.98, 99.976, 99.98, 99.976, 99.968, 99.992, 99.976, 99.984, 99.996, 99.992, 99.968, 99.98, 99.992, 99.976, 99.988, 99.992, 99.988, 100.0], 'eval_acc1es': [38.51600000610352, 49.27200000366211, 46.76799999389648, 60.871999985351565, 63.103999985351564, 65.66000000244141, 71.21999998535156, 55.620000003662106, 73.15200000732422, 73.65600001953125, 66.81600000732422, 77.7039999975586, 78.96399999267578, 76.18799997802735, 78.75599999267578, 69.17599997558594, 66.54799998046875, 75.86799998779297, 76.66399998046874, 80.01199997314453, 72.9839999975586, 77.1320000024414, 75.52400000488281, 67.74399998535156, 80.58799998046875, 69.08399997558594, 81.54400000976563, 76.53600000488281, 80.61999998046875, 80.57199999267579, 82.13999997558594, 82.08000000488282, 73.69200001464844, 80.06399999511719, 73.90400000976562, 74.86000001953126, 81.06400001220703, 77.45999999023438, 81.50399998046875, 83.48000000488281, 81.73199997802735, 76.72800000732421, 83.20400000488281, 83.36799998779297, 82.13999997070313, 81.19999999267579, 74.2359999975586, 84.84400001220703, 81.61200001464844, 78.72799998291016, 83.35999999511719, 83.88000001220703, 82.88799998046875, 84.40000000732422, 84.30400001464844, 81.15199997070313, 81.75999997314453, 82.65599998046875, 83.17599997314453, 79.41599997558593, 84.47199997314453, 82.31199997802734, 83.25999998046875, 83.25199997314454, 80.66799999267577, 84.57999997558593, 84.7160000024414, 83.77599997070313, 81.75999998046875, 82.80399997558594, 80.15999997558593, 82.90400001464843, 79.35199998779296, 84.03600000976563, 82.00800001953125, 80.91199998291016, 85.54800000732422, 83.41199998535156, 85.76799998779296, 83.61600000244141, 84.38800001464844, 82.76800001953124, 84.40799997802735, 82.62799997070313, 83.02000001708984, 80.77599997070313, 85.40000001220703, 82.55599997802734, 84.42800001464843, 85.06400001464844, 83.55999997802735, 84.60399999511719, 84.22799997802734, 85.36800001220703, 84.58000001953125, 86.468, 85.51200000488281, 86.06799998535156, 87.348, 85.9119999975586, 84.84000001708985, 86.84799999755859, 84.62800000244141, 80.93599997802734, 81.90400000732421, 86.95600000488281, 85.02800000976562, 85.33600001220704, 87.64400001708984, 86.00000001953126, 86.12399999511719, 85.54399999023437, 85.30000000976563, 85.85199999023438, 87.0399999975586, 85.51200001220703, 86.54800001708985, 87.27199998779297, 87.98799999267578, 87.65600000732422, 88.41599997802734, 84.17999997314453, 86.33200000488281, 85.904, 87.26400001220703, 87.84399997558593, 86.94800001953125, 86.77200000488281, 84.48000001464844, 88.31199998535156, 87.18800000976563, 86.44400000244141, 88.12399999023438, 88.84799999023437, 87.70399998535156, 88.54000000732422, 87.72399997070312, 89.07599999511719, 88.33199997070312, 87.39599998291015, 88.49999999267578, 89.39199998535156, 88.23199999511719, 88.49599999267578, 88.39199999511719, 89.4359999975586, 89.1680000024414, 89.19999998779296, 89.05600001220704, 89.65199998046874, 89.05199999267577, 89.77199998779297, 89.8559999975586, 89.94000000488282, 89.86799999023438, 89.69599999023437, 88.88399998779298, 89.9599999975586, 90.06799998779297, 90.39999998046875, 90.82799999511718, 90.72799997802734, 90.46800001953125, 90.89999998046875, 90.96799999267579, 91.09999998046875, 90.77199998291016, 90.99599999023438, 91.02799998779297, 91.06799999267578, 91.05999999023437, 91.08399998291016, 91.18399998535156, 91.03599998046874, 91.21599998535156, 91.22399998779296, 91.29199997802735, 91.23999998046875, 91.27599997314454, 91.24399998291015, 91.31599998291016, 91.33199999023438, 91.36399998291016, 91.41600000488282, 91.39600001953124, 91.40399998535156, 91.37599997314453, 91.3919999975586, 91.41599998535156, 91.42, 91.47599999267578, 91.49199999023438, 91.47599998046876, 91.47999998291016, 91.51599999267579, 91.45200001953125, 91.48399997558593, 91.48799998535156, 91.46399999023437, 91.46399999267578, 91.33], 'cost_info': {'flops': 117.88353, 'params': 0.830426, 'latency': 0.01909610158518741, 'train_time': 11.704105277856192}}}\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 260 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 261 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 262 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 263 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 264 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 265 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 266 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 267 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 268 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 269 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 270 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 271 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 272 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 273 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 274 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 275 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 276 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 277 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:12 nl.defaults.trainer]: \u001b[0mEpoch 278 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:47:13 nl.defaults.trainer]: \u001b[0mEpoch 279 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","Finished fitting GP\n","Finished fitting GP\n","Finished fitting GP\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 280, Anytime results: {'cifar10-valid': {'train_losses': [1.797979532775879, 1.2527252103996276, 1.0138580317115784, 0.8822913989257812, 0.7803608722114563, 0.7023457984924316, 0.6497955482292175, 0.6059390458106995, 0.5677761807537078, 0.538056489944458, 0.515950230770111, 0.4948751167488098, 0.4747195296764374, 0.4572546643924713, 0.445253247756958, 0.4359080542373657, 0.4239110640716553, 0.41368696506500247, 0.3971407129478455, 0.38833855127334593, 0.3788480834960937, 0.3740516341018677, 0.35861263020515444, 0.3550860090827942, 0.35471325862884523, 0.3511313292884827, 0.3420170811271667, 0.33029187686920164, 0.32096393228530884, 0.3264443295955658, 0.3209636632442474, 0.31464752191543577, 0.3025444029521942, 0.29950268094062804, 0.2968454804801941, 0.30367620081901553, 0.2844067573404312, 0.28439875590324404, 0.2781640834140778, 0.2739880220317841, 0.26975711678504943, 0.26009569576740266, 0.26850710664749144, 0.2599183919286728, 0.2559084771347046, 0.25671464601039884, 0.25152616675376893, 0.24927711655139922, 0.247728226518631, 0.24402085838317872, 0.24527329946517945, 0.2376989866876602, 0.23035390013694762, 0.2327466607093811, 0.22429453383922576, 0.2272956440448761, 0.22197500553131103, 0.21436945312976838, 0.21928964067459106, 0.21290034994125367, 0.20822054827213288, 0.21389376505851745, 0.20563746623039245, 0.2099708962535858, 0.19158048898220062, 0.19615204340457917, 0.1982648743581772, 0.1887348501777649, 0.19475696102142334, 0.1842686238336563, 0.18677605671405792, 0.18652738688468934, 0.18188076397895814, 0.18016700853824616, 0.17823464753627777, 0.18016266384124757, 0.16617573895454407, 0.1770302580022812, 0.17052061563491822, 0.15902811944961548, 0.16233001423358917, 0.16556088306903838, 0.15680421692848207, 0.1498578377342224, 0.15635097947120666, 0.15310042744636534, 0.15306200007438658, 0.14491507052898406, 0.1416260453414917, 0.13550126110076904, 0.1392497732591629, 0.13626620844841003, 0.13300940950632095, 0.13275603595256805, 0.12830855484008788, 0.12408610872745514, 0.12531209909915925, 0.12207098999977112, 0.1216279049706459, 0.10974599875926971, 0.11079829895496368, 0.11904660460948945, 0.10809563687324523, 0.11965358115673065, 0.11427250968933106, 0.10849766419887542, 0.10218072737693787, 0.10716040850162506, 0.10477651658535003, 0.09131185996413231, 0.09049850377559662, 0.09137351614952087, 0.0909367332983017, 0.08757329261779785, 0.0899801014661789, 0.08972211226701736, 0.08128207237005233, 0.08392260439395904, 0.07897669915676117, 0.07467384212732316, 0.07569570093631744, 0.0694864012169838, 0.0675577897644043, 0.06855287613153457, 0.0652096102821827, 0.06380558840870858, 0.06269203025877476, 0.056387432240247726, 0.05073259930610657, 0.05295789412975311, 0.06122023828983307, 0.05983238134384155, 0.050557514559030535, 0.04516359554290771, 0.04152287001490593, 0.04919338520169258, 0.037906546899080275, 0.03719876957416535, 0.03342186244606972, 0.03439499699473381, 0.03459258997559547, 0.03468540014445782, 0.028545279636383057, 0.03216642561376095, 0.02676758377045393, 0.025878876812458037, 0.0214473418533802, 0.021104339045286177, 0.021747494243383406, 0.021283978564739226, 0.019705448406785727, 0.018253158379793168, 0.015280498052239418, 0.0137871942422539, 0.014443003076314926, 0.01408235429942608, 0.013874327067136764, 0.01428306491613388, 0.012863019816875458, 0.010711087912917137, 0.007742220239043236, 0.006511413640901446, 0.006719038946032524, 0.006903528813645244, 0.004742787101864814, 0.004861924066767096, 0.005476148186177015, 0.0038102409364283085, 0.0039400346457958224, 0.003776025571450591, 0.004068971053361892, 0.002876078786998987, 0.0030355332847684623, 0.0035315019605308773, 0.002837982722520828, 0.002136290045157075, 0.0019352131270617247, 0.0021824218651652337, 0.002028700380474329, 0.0019801752346754074, 0.0021660784274339677, 0.0022002970218658446, 0.0019479305266216398, 0.002038802414163947, 0.0019461702918633819, 0.001907505464591086, 0.0021021232601627707, 0.0016369401945173741, 0.0018257959835976361, 0.0019210409358888865, 0.001416360531039536, 0.0015833961294218898, 0.0017988794137910008, 0.0015769814006984233, 0.001505851459875703, 0.0018100922302156687, 0.0014608621790260076, 0.0016108034229651094, 0.0015840492541342973, 0.0013324481489509345], 'eval_losses': [1.6272298514175414, 1.719287733230591, 1.7449889614105225, 1.133109687538147, 1.1186404991149903, 1.0821128437423706, 0.847026729850769, 1.5927908081817628, 0.8209507646751404, 0.7648674670219422, 1.0775786195755004, 0.6779091291427612, 0.6390487702178955, 0.7489264928436279, 0.6666688264083862, 1.0245877558135987, 1.1595384635925292, 0.723676893119812, 0.7669336923980713, 0.6112452599334717, 0.9660843383407592, 0.7343378405952453, 0.840818124294281, 1.2604200606918334, 0.6063524735832214, 1.159623742980957, 0.6039365092849731, 0.8497507237052917, 0.628081222114563, 0.6216542652893067, 0.5560605820655823, 0.5865489265823364, 0.9597786441802979, 0.6361585730934143, 0.9626845142745971, 0.844418583946228, 0.6500097342872619, 0.7736053534698486, 0.5939313138771057, 0.5072878143882752, 0.6224685645675659, 0.8204889801216125, 0.5511082135486602, 0.5362294416618347, 0.570758188419342, 0.6172440949440002, 0.9451023908996582, 0.47864262647628786, 0.610565881061554, 0.7115218802642822, 0.547065057926178, 0.5347714776134491, 0.5567891032409668, 0.5078570296478272, 0.5192969712829589, 0.6586684846878051, 0.6104187334823609, 0.583992243309021, 0.571166090927124, 0.729368978061676, 0.5097968811225891, 0.597749605178833, 0.5448352932357788, 0.5565177823829651, 0.6815717866516113, 0.5223795333480835, 0.5291338024044037, 0.5593303778266907, 0.6371515368461609, 0.5649146770095825, 0.7654560852050781, 0.6053906892967225, 0.8099864686775208, 0.5623643120193481, 0.6302320753669739, 0.7100821681594849, 0.5042611715888977, 0.5859966699981689, 0.4900874222660065, 0.5865842864894867, 0.5524932344436646, 0.6036392141723633, 0.5771377402496338, 0.635603153705597, 0.6008246605110168, 0.78836101770401, 0.5175824388122559, 0.639802907295227, 0.5585134193229675, 0.5268317921829223, 0.5819013167953491, 0.5606769778060913, 0.5718329856300354, 0.5630345753669739, 0.5855106465911866, 0.4912681079673767, 0.54175859998703, 0.514786814107895, 0.4591868642425537, 0.5052623636817932, 0.5783377849388123, 0.5009782519340515, 0.5888236622619629, 0.762264783744812, 0.7242392131233215, 0.49246752378463743, 0.554996236963272, 0.5442889282417297, 0.4409437468338013, 0.5605955778503418, 0.5315693290710449, 0.5794152967357635, 0.5857491951942444, 0.5708944032287597, 0.5043705623722077, 0.5632711613273621, 0.5163035422515869, 0.4966876087188721, 0.4505663089752197, 0.4704933899116516, 0.45981528732299803, 0.6531034126091003, 0.5183848677921296, 0.5909099923610688, 0.5152843837165832, 0.49619828419685363, 0.5475378018951416, 0.5393404815101623, 0.7201345665931702, 0.4824238876056671, 0.5215795503044128, 0.5685945818328857, 0.5089179008483887, 0.47145085259437564, 0.5472192948913575, 0.4900347399139404, 0.540964811782837, 0.46170505146026614, 0.5063307063484191, 0.5666370886611939, 0.48203581071853635, 0.44972750431060793, 0.5232554189109803, 0.4906134189224243, 0.5257716849899292, 0.45284362602233885, 0.4711797005844116, 0.48627261313438414, 0.4987119895553589, 0.466983223361969, 0.49265243516921997, 0.4703731024837494, 0.463229135723114, 0.460639780960083, 0.47536511048316954, 0.4933408259010315, 0.5230341455554962, 0.4691208839035034, 0.4683770147895813, 0.4554304603385925, 0.4363482038497925, 0.4507359668636322, 0.47246342094421384, 0.44265450010299684, 0.44240144773483275, 0.4374107486915588, 0.45024260966300966, 0.4394589510059357, 0.4438844661808014, 0.4459243761634827, 0.4445250177764893, 0.4392674104118347, 0.43809965566635134, 0.4435059818077087, 0.44061508752822875, 0.43598945977211, 0.4353007004642487, 0.4364056324005127, 0.436138900680542, 0.44131933745384216, 0.4382879079723358, 0.43560168815612793, 0.4378226725196838, 0.43351163749694827, 0.4295745631122589, 0.43166758422851564, 0.43342907007217407, 0.43806649894714356, 0.433157393579483, 0.4312484454727173, 0.43233252582550047, 0.43136490835189817, 0.432343833770752, 0.430613657617569, 0.43042267800331113, 0.43180035969734193, 0.4328012317943573, 0.4323063223934174, 0.43098210398674014, 0.4329616625976562, 0.4390562599182129], 'train_acc1es': [31.436000007324218, 54.619999978027344, 63.41599999755859, 68.73600000976562, 72.56400001464844, 75.38399997558594, 77.32399997802735, 78.93999998535156, 80.21200001464844, 81.58399997802735, 81.92799998779297, 83.02400001708985, 83.64800000732421, 84.40800001464844, 84.43200001464844, 85.00000001220702, 85.3720000048828, 85.50800000732421, 86.34399998779297, 86.40399999267578, 86.84399997558593, 87.0279999975586, 87.53600001464844, 87.66000001464843, 87.70000000976563, 87.84400001220703, 88.05599999755859, 88.73599999511718, 88.77600001464843, 88.49999999267578, 88.82799998779296, 89.2200000048828, 89.372, 89.53999999511718, 89.37600000732422, 89.46799999267579, 90.10399998046876, 90.20799999755859, 90.36000000976563, 90.48000000732422, 90.54399999267578, 90.90399998535156, 90.71999999511719, 91.02800001220703, 91.02399998535157, 91.15599997802734, 91.33599998535156, 91.33599997314452, 91.49999998291015, 91.70799999023437, 91.43199999267578, 91.72799997802734, 91.91199997558594, 91.84799998291015, 92.27599997314454, 92.17199997558593, 92.34399998291016, 92.71599999511719, 92.35199998535157, 92.41599999267578, 92.86399998535157, 92.66399997558594, 92.75200001953125, 92.65999998535156, 93.37599997314453, 93.35599997314453, 92.90800001953124, 93.71599997070312, 93.26000001464844, 93.56799997070313, 93.47999997314453, 93.38400001708985, 93.77999997070313, 93.69199999267578, 93.78799997314454, 93.85599998291016, 94.29999998046875, 93.79199998535157, 94.16799997558594, 94.54799997314453, 94.36799997070312, 94.17199998046875, 94.60800001708985, 94.97599998535156, 94.51999997070313, 94.65999998291015, 94.74400001708985, 94.99599998291016, 95.05200001708984, 95.31999997070312, 95.31599997314453, 95.27199997314453, 95.34000001953125, 95.43199997558594, 95.58400001464844, 95.79199997070313, 95.67600001708985, 95.85600001220703, 95.71600001708984, 96.41200001708984, 96.24000001220703, 95.87200001464844, 96.32400001708984, 95.77999997558594, 96.18800001464844, 96.30400001708985, 96.56000001220703, 96.37599998291016, 96.45200001953125, 96.98000000488281, 96.87600001708985, 96.98800001953126, 96.92400001220703, 97.13999997314453, 96.82400001953125, 96.90800001464844, 97.28000001708985, 97.16800001708984, 97.24400001220702, 97.56000001220703, 97.44000001464843, 97.62000000732422, 97.75200000976562, 97.74800000976562, 97.74800000488281, 97.88400000488281, 97.9240000024414, 98.13200000976562, 98.37200000732422, 98.27200001220703, 98.06800001220704, 97.94800001220703, 98.26000000488281, 98.4960000024414, 98.64800000488282, 98.3640000024414, 98.78400000488281, 98.8600000048828, 98.9880000048828, 98.89200001220703, 98.84000000732422, 98.90800000244141, 99.13200000732422, 98.9960000024414, 99.184, 99.1800000024414, 99.32000000732423, 99.38400000244141, 99.34400000488282, 99.31600000488281, 99.364, 99.45200000732422, 99.53200000488282, 99.588, 99.6080000024414, 99.54800000244141, 99.58400000732422, 99.548, 99.64000000244141, 99.70800000244141, 99.836, 99.86, 99.82400000244141, 99.836, 99.9000000024414, 99.908, 99.88, 99.92, 99.92800000244141, 99.928, 99.94, 99.948, 99.944, 99.928, 99.94400000244141, 99.98, 99.984, 99.98, 99.976, 99.97600000244141, 99.968, 99.952, 99.98, 99.976, 99.98, 99.976, 99.968, 99.992, 99.976, 99.984, 99.996, 99.992, 99.968, 99.98, 99.992, 99.976, 99.988, 99.992, 99.988, 100.0], 'eval_acc1es': [38.51600000610352, 49.27200000366211, 46.76799999389648, 60.871999985351565, 63.103999985351564, 65.66000000244141, 71.21999998535156, 55.620000003662106, 73.15200000732422, 73.65600001953125, 66.81600000732422, 77.7039999975586, 78.96399999267578, 76.18799997802735, 78.75599999267578, 69.17599997558594, 66.54799998046875, 75.86799998779297, 76.66399998046874, 80.01199997314453, 72.9839999975586, 77.1320000024414, 75.52400000488281, 67.74399998535156, 80.58799998046875, 69.08399997558594, 81.54400000976563, 76.53600000488281, 80.61999998046875, 80.57199999267579, 82.13999997558594, 82.08000000488282, 73.69200001464844, 80.06399999511719, 73.90400000976562, 74.86000001953126, 81.06400001220703, 77.45999999023438, 81.50399998046875, 83.48000000488281, 81.73199997802735, 76.72800000732421, 83.20400000488281, 83.36799998779297, 82.13999997070313, 81.19999999267579, 74.2359999975586, 84.84400001220703, 81.61200001464844, 78.72799998291016, 83.35999999511719, 83.88000001220703, 82.88799998046875, 84.40000000732422, 84.30400001464844, 81.15199997070313, 81.75999997314453, 82.65599998046875, 83.17599997314453, 79.41599997558593, 84.47199997314453, 82.31199997802734, 83.25999998046875, 83.25199997314454, 80.66799999267577, 84.57999997558593, 84.7160000024414, 83.77599997070313, 81.75999998046875, 82.80399997558594, 80.15999997558593, 82.90400001464843, 79.35199998779296, 84.03600000976563, 82.00800001953125, 80.91199998291016, 85.54800000732422, 83.41199998535156, 85.76799998779296, 83.61600000244141, 84.38800001464844, 82.76800001953124, 84.40799997802735, 82.62799997070313, 83.02000001708984, 80.77599997070313, 85.40000001220703, 82.55599997802734, 84.42800001464843, 85.06400001464844, 83.55999997802735, 84.60399999511719, 84.22799997802734, 85.36800001220703, 84.58000001953125, 86.468, 85.51200000488281, 86.06799998535156, 87.348, 85.9119999975586, 84.84000001708985, 86.84799999755859, 84.62800000244141, 80.93599997802734, 81.90400000732421, 86.95600000488281, 85.02800000976562, 85.33600001220704, 87.64400001708984, 86.00000001953126, 86.12399999511719, 85.54399999023437, 85.30000000976563, 85.85199999023438, 87.0399999975586, 85.51200001220703, 86.54800001708985, 87.27199998779297, 87.98799999267578, 87.65600000732422, 88.41599997802734, 84.17999997314453, 86.33200000488281, 85.904, 87.26400001220703, 87.84399997558593, 86.94800001953125, 86.77200000488281, 84.48000001464844, 88.31199998535156, 87.18800000976563, 86.44400000244141, 88.12399999023438, 88.84799999023437, 87.70399998535156, 88.54000000732422, 87.72399997070312, 89.07599999511719, 88.33199997070312, 87.39599998291015, 88.49999999267578, 89.39199998535156, 88.23199999511719, 88.49599999267578, 88.39199999511719, 89.4359999975586, 89.1680000024414, 89.19999998779296, 89.05600001220704, 89.65199998046874, 89.05199999267577, 89.77199998779297, 89.8559999975586, 89.94000000488282, 89.86799999023438, 89.69599999023437, 88.88399998779298, 89.9599999975586, 90.06799998779297, 90.39999998046875, 90.82799999511718, 90.72799997802734, 90.46800001953125, 90.89999998046875, 90.96799999267579, 91.09999998046875, 90.77199998291016, 90.99599999023438, 91.02799998779297, 91.06799999267578, 91.05999999023437, 91.08399998291016, 91.18399998535156, 91.03599998046874, 91.21599998535156, 91.22399998779296, 91.29199997802735, 91.23999998046875, 91.27599997314454, 91.24399998291015, 91.31599998291016, 91.33199999023438, 91.36399998291016, 91.41600000488282, 91.39600001953124, 91.40399998535156, 91.37599997314453, 91.3919999975586, 91.41599998535156, 91.42, 91.47599999267578, 91.49199999023438, 91.47599998046876, 91.47999998291016, 91.51599999267579, 91.45200001953125, 91.48399997558593, 91.48799998535156, 91.46399999023437, 91.46399999267578, 91.33], 'cost_info': {'flops': 117.88353, 'params': 0.830426, 'latency': 0.01909610158518741, 'train_time': 11.704105277856192}}}\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 280 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 281 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 282 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 283 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 284 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 285 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 286 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 287 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 288 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 289 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 290 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 291 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 292 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 293 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 294 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 295 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 296 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 297 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:06 nl.defaults.trainer]: \u001b[0mEpoch 298 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:07 nl.defaults.trainer]: \u001b[0mEpoch 299 done. Train accuracy (top1, top5): 100.00000, 0.00000, Validation accuracy: 91.33000, 0.00000\n","\u001b[32m[05/23 16:48:07 nl.defaults.trainer]: \u001b[0mTraining finished\n","\u001b[32m[05/23 16:48:07 nl.defaults.trainer]: \u001b[0mStart evaluation\n","\u001b[32m[05/23 16:48:07 nl.defaults.trainer]: \u001b[0mloading model from file ./docs/bananas_run_0/cifar10/nas_predictors/nasbench201/gp/0/search/model_final.pth\n","\u001b[32m[05/23 16:48:07 nl.defaults.trainer]: \u001b[0mFinal architecture:\n","Graph makrograph-0.8444219, scope None, 20 nodes\n","\u001b[32m[05/23 16:48:07 nl.defaults.trainer]: \u001b[0mQueried results (Metric.TEST_ACCURACY): 91.33\n"]}],"source":["run_optimizer()"]},{"cell_type":"markdown","metadata":{"id":"M44GktE2tIGz"},"source":["# TASK: Implement a Regularized Evolution version that uses the performance predictors as surrogate models during the search"]},{"cell_type":"markdown","metadata":{"id":"u4_tFUrPtIGz"},"source":["The Regularized Evolution (RE) code that we ran above uses the true validation performance as queried from NAS-Bench-201. Using the tabular benchmark this is certainly cheap since we are only simulating the true run. However, in real world scenarios these tabular entries are not available so we have to train every sampled/mutated architecture from scratch. This is the most expensive step in black-box optimization for NAS.\n","\n","The NAS performance predictors can drastically accelerate the search by utilizing the performance as predicted by the surrogate model (performance predictor). In this exercise you will have to implement a RE version that utilizes the performance predictors to estimate the performance of the sampled architectures instead of querying that from the tabular benchmark. Sample the very first architectures in the population and query those from NB201. Then fit the performance predictor. Afterwards, every 10 iterations query again the performance from NB201 and refit the predictor. In between, however, use the performance returned by the predictor inside RE.\n","\n","HINT: Check how the performance predictors are utilized inside the BANANAS implementation in NASLib."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Ms3adabytIGz","executionInfo":{"status":"ok","timestamp":1653324777273,"user_tz":-120,"elapsed":199,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}}},"outputs":[],"source":["from naslib.search_spaces.core.query_metrics import Metric\n","from naslib.utils.logging import log_every_n_seconds\n","from naslib.predictors.ensemble import Ensemble\n","from naslib.optimizers.discrete.bananas.acquisition_functions import acquisition_function\n","import torch\n","import logging\n","import copy\n","import numpy as np\n","\n","# logger = logging.getLogger(__name__)\n","\n","class RE_predictor(RE):\n","    def __init__(self, config):\n","        # you probably would need to add some more attributes to the __init__ method\n","        super().__init__(config)\n","        self.config = config\n","        self.num_ensemble = config.search.num_ensemble\n","        self.search_space = NB201()\n","        self.ss_type = search_space.get_type()\n","        self.predictor_type = config.search.predictor_type\n","        self.acq_fn_type = config.search.acq_fn_type\n","        self.training_set = []\n","\n","    \n","    def new_epoch(self, epoch):\n","      if epoch < self.population_size:\n","            logger.info(\"Start sampling architectures to fill the population\")\n","            # If there is no scope defined, let's use the search space default one\n","            \n","            model = torch.nn.Module()   # hacky way to get arch and accuracy checkpointable\n","            model.arch = self.search_space.clone()\n","            model.arch.sample_random_architecture(dataset_api=self.dataset_api)        \n","            model.accuracy = model.arch.query(self.performance_metric, \n","                                              self.dataset, \n","                                              dataset_api=self.dataset_api)\n","            self.training_set.append(model)\n","            self.population.append(model)\n","            self._update_history(model)\n","            log_every_n_seconds(logging.INFO, \"Population size {}\".format(len(self.population)))\n","      else:\n","          if epoch % 10 == 0 and self.predictor_type != 'none':\n","              self.xtrain = [m.arch for m in self.training_set]\n","              self.ytrain = [m.accuracy for m in self.training_set]\n","              global ensemble\n","              ensemble = Ensemble(num_ensemble=self.num_ensemble,\n","                                    ss_type=self.ss_type,\n","                                    predictor_type=self.predictor_type, \n","                                    config=self.config)\n","              train_error = ensemble.fit(self.xtrain, self.ytrain)\n","\n","          sample = []\n","          while len(sample) < self.sample_size:\n","                candidate = np.random.choice(list(self.population))\n","                sample.append(candidate)\n","            \n","          parent = max(sample, key=lambda x: x.accuracy)\n","\n","          child = torch.nn.Module()   # hacky way to get arch and accuracy checkpointable\n","          child.arch = self.search_space.clone()\n","          child.arch.mutate(parent.arch, dataset_api=self.dataset_api)\n","          if epoch % 10 == 0 or self.predictor_type == 'none':\n","             child.accuracy = child.arch.query(self.performance_metric, \n","                                                self.dataset, \n","                                                dataset_api=self.dataset_api)\n","             self.training_set.append(child)\n","          else:\n","             acq_fn = acquisition_function(ensemble=ensemble, \n","                                              ytrain=self.ytrain,\n","                                              acq_fn_type=self.acq_fn_type)\n","             child.accuracy = acq_fn(child.arch)\n","                \n","          self.population.append(child)\n","          self._update_history(child)    \n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"YYWoK-1lQc8w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653133040228,"user_tz":-120,"elapsed":15215,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"ad66ee52-4d49-4944-cbad-22704df322e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"ovXkng9xtIGz"},"source":["Now generate the new yaml configuration files using the bash commands as shown above. Just change \"bananas\" to \"re\"."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Me4QTDlFtIGz","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1d0UzO9832Eqi5erTOVPBA7isWuTH-7F_"},"executionInfo":{"status":"ok","timestamp":1653326758131,"user_tz":-120,"elapsed":1010467,"user":{"displayName":"Youssef Nassar","userId":"02091382973454010409"}},"outputId":"5ee6047d-877c-42f2-9585-47d6c190c758"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#TODO: Run the RE_predictor optimizer\n","import os\n","list_of_config_files = []\n","list_of_config_files = [\"/content/drive/MyDrive/NasLib/NASLib/docs/re_run_0/cifar10/configs/nas_predictors/\" + f for f in os.listdir(\"/content/drive/MyDrive/NasLib/NASLib/docs/re_run_0/cifar10/configs/nas_predictors/\")]\n","for config_file in list_of_config_files:\n","   run_optimizer(config_file=config_file, nas_optimizer=RE_predictor)\n"]},{"cell_type":"markdown","metadata":{"id":"ilcKPIPItIGz"},"source":["### Plotting the results"]},{"cell_type":"markdown","metadata":{"id":"hSr7WyNYtIGz"},"source":["The results should have been written to `re_run_0/cifar10/nas_predictors/nasbench201`. Use the other jupyter notebook located in `NASLib/naslib/docs/plot.ipynb` to generate the plots based on these results."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"naslib_tutorial.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}